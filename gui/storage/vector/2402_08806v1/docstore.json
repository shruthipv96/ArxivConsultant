{"docstore/data": {"bd554c5e-9707-4c98-9292-f7ceea512b58": {"__data__": {"id_": "bd554c5e-9707-4c98-9292-f7ceea512b58", "embedding": null, "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5f05c1b5-10b5-495f-aa31-fd82c55019da", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "d5b7184128364bad8ce2a6134d1f4eab8eed31e8a72eee8624a47821f1b06768", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c61fcbd6-7577-4310-9a29-5eb824a2c466", "node_type": "1", "metadata": {}, "hash": "46b82df7050758e4c921c9b2375cee9f8d2b09f89c603b356b929730b9aecbde", "class_name": "RelatedNodeInfo"}}, "text": "Combining Insights From\nMultiple Large Language Models\nImproves Diagnostic Accuracy\nGioele Barabucci\u2020,1, Victor Shia2,3, Eugene Chu4, Benjamin Harack3,5, and Nathan Fu3\n1University of Cologne,2Harvey Mudd College,3The Human Diagnosis Project,\n4Kaiser Permanente,5University of Oxford\nBackground Large language models (LLMs) such as OpenAI\u2019s GPT-4 or Google\u2019s PaLM 2 are\nproposed as viable diagnostic support tools or even spoken of as replacements for \u201ccurbside consults\u201d.\nHowever, even LLMs specifically trained on medical topics may lack sufficient diagnostic accuracy for\nreal-life applications.\nMethods Using collective intelligence methods and a dataset of 200 clinical vignettes of real-life\ncases, we assessed and compared the accuracy of differential diagnoses obtained by asking individual\ncommercial LLMs (OpenAI GPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the\naccuracy of differential diagnoses synthesized by aggregating responses from combinations of the same\nLLMs.\nResults We find that aggregating responses from multiple, various LLMs leads to more accurate\ndifferential diagnoses (average accuracy for 3 LLMs: 75.3%\u00b11.6pp) compared to the differential\ndiagnoses produced by single LLMs (average accuracy for single LLMs: 59.0%\u00b16.1pp).\nDiscussion The use of collective intelligence methods to synthesize differential diagnoses combining\nthe responses of different LLMs achieves two of the necessary steps towards advancing acceptance\nof LLMs as a diagnostic support tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor.\n1 Background\nLargelanguagemodels(LLMs)suchasGPT-4have\nbeen shown to be useful as support tools in various\nhealthcare settings such as during tumor boards [1]\nor as a screening tool to match patient notes to\nbest practice alerts [2]. Their future use and de-\nployment in healthcare is expected to parallel that\nof other AI tools such as automated electrocardio-\ngram (ECG) anomaly detection, i.e., as support\ntools that provide insight to human practitioners\nto better inform their decisions [3].\nIn particular, there is ongoing research into the\napplication of LLMs as summarization tools for\npatient and procedure information [4] or as replace-\nmentfor\u201ccurbsideconsults\u201d, especiallyinsituations\nwhere colleagues may not be available (e.g., re-\nmote locations) or too expensive (e.g., underserved\ngroups) [5, 6].\nNevertheless, the use of LLM-based tools is im-\npaired by their limited acceptance by medical pro-\nfessionals, among other factors [7].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2552, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c61fcbd6-7577-4310-9a29-5eb824a2c466": {"__data__": {"id_": "c61fcbd6-7577-4310-9a29-5eb824a2c466", "embedding": null, "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5f05c1b5-10b5-495f-aa31-fd82c55019da", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "d5b7184128364bad8ce2a6134d1f4eab8eed31e8a72eee8624a47821f1b06768", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd554c5e-9707-4c98-9292-f7ceea512b58", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "d8a0f9c36ec7255dab95b6f92e7ded0e88064ae6201cb4f9824dacfa8c564e84", "class_name": "RelatedNodeInfo"}}, "text": "Their future use and de-\nployment in healthcare is expected to parallel that\nof other AI tools such as automated electrocardio-\ngram (ECG) anomaly detection, i.e., as support\ntools that provide insight to human practitioners\nto better inform their decisions [3].\nIn particular, there is ongoing research into the\napplication of LLMs as summarization tools for\npatient and procedure information [4] or as replace-\nmentfor\u201ccurbsideconsults\u201d, especiallyinsituations\nwhere colleagues may not be available (e.g., re-\nmote locations) or too expensive (e.g., underserved\ngroups) [5, 6].\nNevertheless, the use of LLM-based tools is im-\npaired by their limited acceptance by medical pro-\nfessionals, among other factors [7].\nOne major factor driving this low rate of accep-tance is lack of trust that an LLM can provide cor-\nrect answers, and additionally, one that avoids so\ncalled \u201challucinations\u201d, i.e., verisimilar but fictional\nresponses. This lack of trust can in turn be traced\nback to lack of data on the performance (e.g., cor-\nrectness, accuracy, specificity) of said LLM-based\ntools. Put bluntly, before trusting them, medi-\ncal practitioners want to know: \u201c[Are they] good\nenough?\u201d [5].\nRecent studies on the accuracy of LLMs have been\nshown them to be capable of performing well in cer-\ntain medical contexts, but results seem to also vary\ndepending on the research study or application,\nwhich paints an unclear situation. For instance,\nEriksen et al.[8] report that GPT-4 scores above\n72% of the readers of medical journals in 38 clinical\ncase challenges. On the other hand, Barile et al.\n[9] report that GPT-4 has a diagnostic error rate\nof 83% when confronted with 100 pediatric case\nchallenges published on JAMA and NEJM.\nThis study investigates the use of collective in-\ntelligence methods to synthesize higher-accuracy\ndifferential diagnoses by aggregating differential\n\u2020Corresponding author: gioele.barabucci@uni-koeln.dearXiv:2402.08806v1  [cs.AI]  13 Feb 2024", "mimetype": "text/plain", "start_char_idx": 1837, "end_char_idx": 3809, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f06fbc1-1cf6-43d9-bc5f-515eb6696bc9": {"__data__": {"id_": "7f06fbc1-1cf6-43d9-bc5f-515eb6696bc9", "embedding": null, "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "0457c8bd60dd555beaeca8b6c384251a252579eabb162a0188e457f661028de2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ee7ff544-cd04-46df-a3a0-f3722090c606", "node_type": "1", "metadata": {}, "hash": "af80d0cb8ed4652586618004c7a1ce8e17c742b5c4a8ae848b864ec99cdebf54", "class_name": "RelatedNodeInfo"}}, "text": "diagnoses produced by a set of LLMs (even ones\nwith low accuracy) in response to medical ques-\ntions in the form of case vignettes. Aggregating\nresults from multiple LLMs could be the key to\nachieving high-accuracy responses (and potentially\nwith fewer implausible or \u201challucinated\u201d responses).\nBy employing algorithmic methods for knowledge\naggregation from research on collective intelligence,\nit is possible to create a high-quality response to\na question by aggregating lower-quality responses\nfrom multiple respondents [10]. For instance, past\nstudies in the medical domain show that aggre-\ngating as few as three answers from inexperienced\nrespondents led to high diagnostic accuracy (77%\naccuracy), significantly above the performance of\nindividual human experts (62.5% accuracy) [11].\n2 Methods\nThis study can be summarized as follows: we sam-\npled 200 clinical vignettes of real-life cases from the\nHuman Diagnosis Project (Human Dx) database,\nasked various LLMs to provide differential diag-\nnoses for these cases, aggregated their responses\nusing collective intelligence algorithms, and finally\ncompared the accuracy of the individual LLM re-\nsponses to the accuracy of the aggregated differen-\ntials.\nThe prompts and the Python scripts used to run\nthe study are provided in the supplemental mate-\nrial. The case dataset and the LLM responses are\navailable upon request.\n2.1 Dataset and case selection\nThe data for this study is a set of 200 case vi-\ngnettes, extracted from the Human Dx database of\nclinical cases. Human Dx is a multinational online\nplatform in which physicians and medical students\nsolve teaching cases, as well as offer clinical reason-\ning support to fellow users.\nThe 200 cases have been randomly sampled from\nthe dataset used by Barnett et al.[11], restricting\nthe sampling to text-only vignettes.\nThe correct diagnosis of each case ( ground truth ) is\nknown and has been validated by medical experts\nas part of the Barnett et al.[11] study.\n2.2 Querying of LLMs\nFour general-purpose LLMs were asked to solve\neach case by providing a differential with five\nranked diagnoses. The four LLMs used in this\nstudy are: OpenAI GPT-4, Google PaLM 2 for\ntext (text-bison), Cohere Command, Meta Llama\n2 (llama-2-70b-f).All prompts used to query the LLMs follow the\nsame template: \u201c [CASE TEXT] What is the dif-\nferential (list format of common shorthand non-\nabbreviated diagnoses) for the above case? Re-\nspond with ONLY diagnosis names (one per line)\nuptoamaxof5.\u201d, where [CASE TEXT] isreplaced\nwith the textual description of the case vignette.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2571, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee7ff544-cd04-46df-a3a0-f3722090c606": {"__data__": {"id_": "ee7ff544-cd04-46df-a3a0-f3722090c606", "embedding": null, "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "0457c8bd60dd555beaeca8b6c384251a252579eabb162a0188e457f661028de2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f06fbc1-1cf6-43d9-bc5f-515eb6696bc9", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "f583f311da0c5ba039410ca9e4bfe51d551f7752751e5cf44bb7c88b222053d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2967c7e2-b09e-47fa-b317-e3249dd951d2", "node_type": "1", "metadata": {}, "hash": "caadc332f3344d66f8b80b1fba69a28ea9d86122561b1dafe0ecb066f489be8d", "class_name": "RelatedNodeInfo"}}, "text": "[11] study.\n2.2 Querying of LLMs\nFour general-purpose LLMs were asked to solve\neach case by providing a differential with five\nranked diagnoses. The four LLMs used in this\nstudy are: OpenAI GPT-4, Google PaLM 2 for\ntext (text-bison), Cohere Command, Meta Llama\n2 (llama-2-70b-f).All prompts used to query the LLMs follow the\nsame template: \u201c [CASE TEXT] What is the dif-\nferential (list format of common shorthand non-\nabbreviated diagnoses) for the above case? Re-\nspond with ONLY diagnosis names (one per line)\nuptoamaxof5.\u201d, where [CASE TEXT] isreplaced\nwith the textual description of the case vignette.\nThe actual prompts vary slightly between different\nLLMs because of different query paradigms (e.g.,\nGPT-4 uses a chatparadigm while PaLM 2 uses a\ntext generation paradigm).\nIn order to obtain cleaner differential diagnoses\nfor combining in collectives in the scoring process,\na round of manual prompt engineering has been\ncarried out using less than 5 Human Dx case vi-\ngnettes to help with the format and structure of\nthe response.\nWe are highly confident that the case vignettes\nused in this study are not part of the training\ncorpora of these LLMs. First, because the case\nvignettes are only available to users logged into\nthe Human Dx application and to select research\npartners. Second, because there are contractual\nagreements in place between Human Dx and the\nproviders of the LLMs that forbid the use of data\nincluded in prompts as training material (except\nfor Cohere). Finally, the correct diagnoses were\nnever included in any of the prompts to the various\nLLMs.\n2.3Collective intelligence and response\naggregation\nStarting from the differential diagnoses provided by\nthe single LLMs, 11 synthetic differential diagnoses\nhave been generated by aggregating the single dif-\nferential diagnoses in all possible combinations (6\ntwo-fold combinations, 4 three-fold combinations,\n1 four-fold combination).\nThe aggregation method is a frequency-based,\n1/r-weighted method similar to those used in other\ncollective intelligence studies focused on diagnostic\ntasks via differential diagnoses [11, 12]:\n1.Normalization : All diagnoses in the differ-\nentials are normalized by removing common\nprefixes (e.g., \u201csyndrome\u201d, \u201cdisorder\u201d), stop\nwords (e.g., \u201cby\u201d, \u201cof\u201d, \u201cwith\u201d), and punctua-\ntion signs. In addition, synonyms are merged\ninto preferred terms, following the matching\nestablished by Barnett et al.[11].\n2.Extraction of unique diagnoses : The set of all\nunique normalized diagnoses present across all\ndifferentials is created.", "mimetype": "text/plain", "start_char_idx": 1964, "end_char_idx": 4504, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2967c7e2-b09e-47fa-b317-e3249dd951d2": {"__data__": {"id_": "2967c7e2-b09e-47fa-b317-e3249dd951d2", "embedding": null, "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "0457c8bd60dd555beaeca8b6c384251a252579eabb162a0188e457f661028de2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee7ff544-cd04-46df-a3a0-f3722090c606", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "fe5945cc7b3779df05edc0a913acd60b71c1214863e2d5143fd746949966914e", "class_name": "RelatedNodeInfo"}}, "text": "The aggregation method is a frequency-based,\n1/r-weighted method similar to those used in other\ncollective intelligence studies focused on diagnostic\ntasks via differential diagnoses [11, 12]:\n1.Normalization : All diagnoses in the differ-\nentials are normalized by removing common\nprefixes (e.g., \u201csyndrome\u201d, \u201cdisorder\u201d), stop\nwords (e.g., \u201cby\u201d, \u201cof\u201d, \u201cwith\u201d), and punctua-\ntion signs. In addition, synonyms are merged\ninto preferred terms, following the matching\nestablished by Barnett et al.[11].\n2.Extraction of unique diagnoses : The set of all\nunique normalized diagnoses present across all\ndifferentials is created.\n3.1/rweighting : Inside each differential each di-\nagnosis is given an individual score calculated\nas the inverse of the rank rof the diagnosis\n|2", "mimetype": "text/plain", "start_char_idx": 3882, "end_char_idx": 4651, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "13524a0b-11ec-4ee1-ae08-3661d3c2ec2d": {"__data__": {"id_": "13524a0b-11ec-4ee1-ae08-3661d3c2ec2d", "embedding": null, "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5622aac7-cb06-4429-a785-57c94763b738", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "23e7aeca7c30d07ee8b54ba07418e6c2c9bfe547f4d456c61b9bf8b5bdb1d8eb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "44f0dc74-c065-49f2-8d12-d0ecb6434100", "node_type": "1", "metadata": {}, "hash": "cad5705b58e27645a14f18a44bce8872a8ee2960a1fc2dd83654ba7a5995bf72", "class_name": "RelatedNodeInfo"}}, "text": "in the differential (i.e., the first diagnosis is\ngiven the score 1/1= 1, the second 1/2= 0.5,\nthe third 1/3= 0.33, etc).\n4.Aggregation : Each of the unique diagnoses in\nthe set created in step 2 is given a aggregate\nscorecalculated by adding all the individual\nscores of that diagnosis across all differentials.\n5.Synthesis : A synthetic differential is generated\nby taking the five unique diagnoses with the\nhighest aggregate score and ranking them by\ntheir score in decreasing order.\n2.4 Accuracy measure\nThe accuracy of a solver (either an LLM or a group\nof LLMs) is calculated as the percentage of cor-\nrectly diagnosed cases among all cases.\nFor this study we consider a case to be correctly\ndiagnosed by a solver if the differential provided\nby that solver for that case contains the correct\ndiagnosis among the five highest ranked diagnoses.\nThis so-called TOP-5 matching mirrors similar cor-\nrectness measures used in previous studies [11, 12].\nResults obtained using TOP-1 or TOP-3 matching\nare provided in the supplemental material.\n3 Results\nThe main finding of this study is that the accu-\nracy of differential diagnoses created by aggregat-\ning differential diagnoses from multiple LLMs us-\ning collective intelligence methods (accuracy for 3LLMs: 75.3%\u00b11.6pp) are consistently better than\nthe accuracy of differential diagnoses produced by\nsingle LLMs (average accuracy of single LLMs:\n59.0%\u00b16.1pp).\nThe average accuracy of individual LLMs is\n59.0%\u00b16.1pp, i.e., on average a LLM produces a\nranked differential diagnosis that contains the right\ndiagnosis in 59.0%of the cases. The average accu-\nracy of groups of LLMs increases as the group size\ngrows: the average accuracy for groups of 2 LLMs\nis69.1%\u00b12.6pp, for 3 LLMs is 75.3%\u00b11.6pp, for\n4 LLMs is 78.0%\u00b10.1pp. Figure 1 shows the in-\ndividual and average accuracy of the single LLMs\nand of groups of LLMs.\nThis finding holds true also when the definition\nof correctly diagnosed case is made stricter by\nconsidering only the 3 highest ranked diagnosis in\na differential (TOP-3 matching), as illustrated in\nFigure 2.\nThis trend is also confirmed when the differential\ndiagnosis of the LLM with the highest individual\naccuracy, GPT-4, is excluded from the experiment\n(average accuracy of single LLMs: 54.6%\u00b16.4pp,\nof groups of 2 LLMs: 63.5%\u00b12.3pp, 3 LLMs:\n70.0%\u00b10.1pp).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2333, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "44f0dc74-c065-49f2-8d12-d0ecb6434100": {"__data__": {"id_": "44f0dc74-c065-49f2-8d12-d0ecb6434100", "embedding": null, "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5622aac7-cb06-4429-a785-57c94763b738", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "23e7aeca7c30d07ee8b54ba07418e6c2c9bfe547f4d456c61b9bf8b5bdb1d8eb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13524a0b-11ec-4ee1-ae08-3661d3c2ec2d", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "7c5d34f26442ee6983b20eecc52836bdd2b5419279aa17f21264797da2ee379d", "class_name": "RelatedNodeInfo"}}, "text": "Figure 1 shows the in-\ndividual and average accuracy of the single LLMs\nand of groups of LLMs.\nThis finding holds true also when the definition\nof correctly diagnosed case is made stricter by\nconsidering only the 3 highest ranked diagnosis in\na differential (TOP-3 matching), as illustrated in\nFigure 2.\nThis trend is also confirmed when the differential\ndiagnosis of the LLM with the highest individual\naccuracy, GPT-4, is excluded from the experiment\n(average accuracy of single LLMs: 54.6%\u00b16.4pp,\nof groups of 2 LLMs: 63.5%\u00b12.3pp, 3 LLMs:\n70.0%\u00b10.1pp).\nThe supplemental material provides data on these\nalternative evaluation methods.\n4 Discussion\nThis study demonstrates the feasibility and validity\nof using collective intelligence methods to combine\n 0 20 40 60 80 100\n\u25cb\u25b3\u25a1\u26061 LLM (average)\u25cb\u25a1\u25b3\u25cb\u25b3\u25a1\u2606\u25cb\u2606\u25b3\u2606\u25a12 LLMs (average)\u25b3\u25cb\u25a1\u2606\u25cb\u25a1\u2606\u25b3\u25cb\u2606\u25b3\u25a13 LLMs (average) 4 LLMs (\u2606\u25b3\u25cb\u25a1)% accuracy over 200 casesSingle LLMs\n2 LLMs\n3 LLMs\n4 LLMs\nFigure 1 |Synthetic differential diagnoses aggregated from different LLMs show a greater diagnostic accuracy compared to\ndifferential diagnoses produced by single LLMs. This graph provides a visual representation of the data presented in Table 1.\n\u20dd= Cohere Command, \u25b3= Google PaLM 2, \u25a1= Meta Llama 2, 9= OpenAI GPT-4\n|3", "mimetype": "text/plain", "start_char_idx": 1778, "end_char_idx": 3018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "896307f0-5478-49a7-8374-54ba76656c3b": {"__data__": {"id_": "896307f0-5478-49a7-8374-54ba76656c3b", "embedding": null, "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "83d1e05c-bf71-4b89-a844-e778bff1af40", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "3f72878273f8f61e31a115b94d75005ec1b2dbb8d095a446618033004382e78b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "51840635-24ba-46a9-9cb5-e4e7ab9f4981", "node_type": "1", "metadata": {}, "hash": "8ad72cc47b199e482b0c57962133158ce1e7f59077d02247e2aa6724afb061d4", "class_name": "RelatedNodeInfo"}}, "text": "40 50 60 70 80\n 0  1  2  3  4  5% accuracy over 200 cases\nNumber of LLMs responses contributing to the aggregated di\ufb00erentialTOP-5\nTOP-5 (without GPT-4)\nTOP-3\nTOP-3 (without GPT-4)Figure 2 |Increasing the number of LLMs contributing to a synthetic differential leads to an increase in accuracy also\n(a) when the definition of correctly diagnosed case is made stricter by considering only the 3 highest ranked diagnosis in a\ndifferential (TOP-3 matching) and (b) when the top-performing LLM, GPT-4, is excluded from the experiment.\nlow-accuracy differentials from multiple LLMs into\nsynthetic high-accuracy differentials. The degree\nof increase in accuracy achieved by the method\nemployed in this study is in line with similar results\nin the field of collective intelligence, both in the\nmedical field [11, 12] and outside [10, 13].\nThe mechanism that allows this increase in accu-\nracy is that the presented aggregation method em-\nphasizes plausible diagnoses (likely to be present in\nthe differential returned by multiple LLMs, and so,\nbound to have a higher aggregate score), while min-\nimizing the effects of hallucinated diagnoses (likely\nto be present in only one of the LLMs). This can\nbe seen as an instance of the Anna Karenina prin-\nciple(good answers are common to many LLMs,\nbad answers are local to a specific LLM).\nThis principle is exploited by similar techniquesused in LLM research such as ensemble methods\n[14, 15] or multi-agent debates [16].\nTwo factors differentiate the method employed in\nthis study from these techniques: universality and\nsimplicity. First, this method works despite using\nLLMs with varying querying approaches and tech-\nnical differences, and can thus be easily extended\nto work with any combination of LLMs. Second,\nthe simplicity of this method means that not only\ncan it be easily integrated in existing software ap-\nplications, but could even be performed by medical\npersonnel manually querying separate LLMs and\nsynthesizing the results themselves.\nThe trust of medical practitioners in LLM-based\ntools could be strengthened by the application of\naggregation methods like the one employed in this\nstudy.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2149, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51840635-24ba-46a9-9cb5-e4e7ab9f4981": {"__data__": {"id_": "51840635-24ba-46a9-9cb5-e4e7ab9f4981", "embedding": null, "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "83d1e05c-bf71-4b89-a844-e778bff1af40", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "3f72878273f8f61e31a115b94d75005ec1b2dbb8d095a446618033004382e78b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "896307f0-5478-49a7-8374-54ba76656c3b", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "0974d0efff1abea2953349e2c6e08a9c6e5c31f22507abc233ee932f0d446c38", "class_name": "RelatedNodeInfo"}}, "text": "This principle is exploited by similar techniquesused in LLM research such as ensemble methods\n[14, 15] or multi-agent debates [16].\nTwo factors differentiate the method employed in\nthis study from these techniques: universality and\nsimplicity. First, this method works despite using\nLLMs with varying querying approaches and tech-\nnical differences, and can thus be easily extended\nto work with any combination of LLMs. Second,\nthe simplicity of this method means that not only\ncan it be easily integrated in existing software ap-\nplications, but could even be performed by medical\npersonnel manually querying separate LLMs and\nsynthesizing the results themselves.\nThe trust of medical practitioners in LLM-based\ntools could be strengthened by the application of\naggregation methods like the one employed in this\nstudy. In particular, knowing that multiple sources\nGroup size LLMs in group Accuracy Average accuracy\n1 Cohere Command 39.5%\n59.0%\u00b16.1pp1 Google PaLM 2 66.0%\n1 Meta Llama 2 58.5%\n1 OpenAI GPT-4 72.0%\n2 Cohere Command, Meta Llama 2 58.0%\n69.1%\u00b12.6pp2 Google PaLM 2, Cohere Command 64.5%\n2 Google PaLM 2, Meta Llama 2 68.0%\n2 OpenAI GPT-4, Cohere Command 73.5%\n2 OpenAI GPT-4, Google PaLM 2 77.0%\n2 OpenAI GPT-4, Meta Llama 2 73.5%\n3 Google PaLM 2, Cohere Command, Meta Llama 2 70.0%\n75.3%\u00b11.6pp3 OpenAI GPT-4, Cohere Command, Meta Llama 2 75.5%\n3 OpenAI GPT-4, Google PaLM 2, Cohere Command 79.0%\n3 OpenAI GPT-4, Google PaLM 2, Meta Llama 2 77.0%\n4 Google PaLM 2, Cohere Command, Meta Llama 2, OpenAI GPT-4 78.0% 78 .0%\u00b10.1pp\nTable 1 |Diagnostic accuracy of single LLM and groups of LLMs over the 200 cases present in the dataset. The average\naccuracy is the mean of the accuracy of all groups of a given size.\n|4", "mimetype": "text/plain", "start_char_idx": 1329, "end_char_idx": 3056, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6e0eb59a-b6dd-4a56-9b25-052df479a085": {"__data__": {"id_": "6e0eb59a-b6dd-4a56-9b25-052df479a085", "embedding": null, "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d1cc9071-88d6-476a-b818-f9adb5739027", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "f4b80e13e4f56467a3ad98421a56093ce4caa0b5f9ec866e49fbe43b73593478", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c8610fa5-31b8-40bf-884f-5dae7bdd6be2", "node_type": "1", "metadata": {}, "hash": "81bd30a38fae78ca1377d325176bb49fe4f4bdeca1ff7cf5a7265a2fd97d08e6", "class_name": "RelatedNodeInfo"}}, "text": "contributed would increase clinician confidence in\nthe final differential and lessen the fear of having\nencountered one of the many mistaken answers or\nhallucinations that LLMs are known to produce [5].\nAn additional advantage of the use of knowledge\naggregation methods is preventing vendor lock-\nin, removing the need to engage with a single,\npotentially expensive, or legally problematic LLM\nvendor in order to obtain high-quality diagnostic\ndifferentials. The use of aggregation methods like\nthe one we propose would address these issues\nby enabling the use of multiple cheaper LLMs,\nor alternatively, locally-deployed and fine-tuned\nLLMs. For instance, our results show that the\n3-LLM group without GPT-4 (the top-performing\nLLM) offers a diagnostic accuracy within a couple\nof percentage points of GPT-4 alone.\nWith a clear baseline on diagnostic accuracy and\ntrust, LLM-based tools can become valuable sup-\nport instruments that can speed up diagnosis, re-\nduce diagnostic mistakes and costs, and provide\nadditional consulting services in underserved areas.\nWhile this study shows that aggregating differen-\ntials produced by current LLMs leads to improved\ndiagnostic accuracy, further studies are needed to\nexamine the impact of future LLMs specialized\non medical topics or the use of participatory AI\nmethods (for instance, the synthesis of differentials\naggregating responses from both LLMs and human\npractitioners).\n5 Acknowledgements\nThe authors would like to thank Nikolas Z\u00f6ller of\nthe Max Plank Institute for Human Development\nfor his valuable and constructive feedback.\nThe authors would also like to thank Irving Lin and\nJay Komarneni of the Human Diagnosis Project\nfor their suggested framing and review.\nThis work is supported by the European Union\u2019s\nHorizon Europe Research and Innovation Pro-\ngramme under grant agreement No 101070588\n(HACID: Hybrid Human Artificial Collective Intel-\nligence in Open-Ended Domains).References\n1.Sorin, V., Klang, E., Sklair-Levy, M., Cohen, I., Zippel,\nD. B., Balint Lahat, N., Konen, E. & Barash, Y. Large\nlanguage model (ChatGPT) as a support tool for breast\ntumor board. NPJ Breast Cancer 9,44 (2023).\n2.Savage, T., Wang, J. & Shieh, L. A Large Language Model\nScreening Tool to Target Patients for Best Practice Alerts:\nDevelopment and Validation. JMIR Medical Informatics\n11,e49886 (2023).\n3.Haug, C. J. & Drazen, J. M. Artificial intelligence and\nmachine learning in clinical medicine, 2023. New England\nJournal of Medicine 388,1201\u20131208 (2023).\n4.Patel, S. B. & Lam, K. ChatGPT: the future of dis-\ncharge summaries?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2576, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c8610fa5-31b8-40bf-884f-5dae7bdd6be2": {"__data__": {"id_": "c8610fa5-31b8-40bf-884f-5dae7bdd6be2", "embedding": null, "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d1cc9071-88d6-476a-b818-f9adb5739027", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "f4b80e13e4f56467a3ad98421a56093ce4caa0b5f9ec866e49fbe43b73593478", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6e0eb59a-b6dd-4a56-9b25-052df479a085", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "89639554c17cc5102a7d49e2eb55c785e71cae68d25e18bdef31114eac4c28b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8eaf973-a559-42b4-994a-9d757be0ff63", "node_type": "1", "metadata": {}, "hash": "3f9a53a0adcd471c687724e7a11dd86ac3a386ef4d1362e5020a431f6291d1cf", "class_name": "RelatedNodeInfo"}}, "text": "& Barash, Y. Large\nlanguage model (ChatGPT) as a support tool for breast\ntumor board. NPJ Breast Cancer 9,44 (2023).\n2.Savage, T., Wang, J. & Shieh, L. A Large Language Model\nScreening Tool to Target Patients for Best Practice Alerts:\nDevelopment and Validation. JMIR Medical Informatics\n11,e49886 (2023).\n3.Haug, C. J. & Drazen, J. M. Artificial intelligence and\nmachine learning in clinical medicine, 2023. New England\nJournal of Medicine 388,1201\u20131208 (2023).\n4.Patel, S. B. & Lam, K. ChatGPT: the future of dis-\ncharge summaries? The Lancet Digital Health 5,e107\u2013\ne108 (2023).\n5.Lee, P., Bubeck, S. & Petro, J. Benefits, limits, and risks\nof GPT-4 as an AI chatbot for medicine. New England\nJournal of Medicine 388,1233\u20131239 (2023).\n6.Schwartz, I. S., Link, K. E., Daneshjou, R. & Cort\u00e9s-\nPenfield, N. Black box warning: large language models\nand the future of infectious diseases consultation. Clinical\nInfectious Diseases, ciad633 (2023).\n7.Corr\u00eaa, N. K., Galv\u00e3o, C., Santos, J. W., Del Pino, C.,\nPinto, E. P., Barbosa, C., Massmann, D., Mambrini, R.,\nGalv\u00e3o, L., Terem, E., et al.Worldwide AI ethics: A\nreview of 200 guidelines and recommendations for AI\ngovernance. Patterns 4(2023).\n8.Eriksen, A. V., M\u00f6ller, S. & Ryg, J. Use of GPT-4 to\ndiagnose complex clinical cases. NEJM AI 1,AIp2300031\n(2023).\n9.Barile, J., Margolis, A., Cason, G., Kim, R., Kalash, S.,\nTchaconas, A. & Milanaik, R. Diagnostic Accuracy of a\nLarge Language Model in Pediatric Case Studies. JAMA\npediatrics (2024).\n10.Suran, S., Pattanaik, V. & Draheim, D. Frameworks\nfor collective intelligence: A systematic literature review.\nACM Computing Surveys (CSUR) 53,1\u201336 (2020).\n11.Barnett, M. L., Boddupalli, D., Nundy, S. & Bates, D. W.\nComparative accuracy of diagnosis by collective intel-\nligence of multiple physicians vs individual physicians.\nJAMA network open 2,e190096\u2013e190096 (2019).", "mimetype": "text/plain", "start_char_idx": 2043, "end_char_idx": 3912, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8eaf973-a559-42b4-994a-9d757be0ff63": {"__data__": {"id_": "d8eaf973-a559-42b4-994a-9d757be0ff63", "embedding": null, "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d1cc9071-88d6-476a-b818-f9adb5739027", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "f4b80e13e4f56467a3ad98421a56093ce4caa0b5f9ec866e49fbe43b73593478", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8610fa5-31b8-40bf-884f-5dae7bdd6be2", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}, "hash": "1a04c9d934f6b8fd74cfde9e57c63093aa59aa1af2bfc0798bc22b641d1b5a3b", "class_name": "RelatedNodeInfo"}}, "text": "NEJM AI 1,AIp2300031\n(2023).\n9.Barile, J., Margolis, A., Cason, G., Kim, R., Kalash, S.,\nTchaconas, A. & Milanaik, R. Diagnostic Accuracy of a\nLarge Language Model in Pediatric Case Studies. JAMA\npediatrics (2024).\n10.Suran, S., Pattanaik, V. & Draheim, D. Frameworks\nfor collective intelligence: A systematic literature review.\nACM Computing Surveys (CSUR) 53,1\u201336 (2020).\n11.Barnett, M. L., Boddupalli, D., Nundy, S. & Bates, D. W.\nComparative accuracy of diagnosis by collective intel-\nligence of multiple physicians vs individual physicians.\nJAMA network open 2,e190096\u2013e190096 (2019).\n12.Kurvers, R. H., Nuzzolese, A. G., Russo, A., Barabucci,\nG., Herzog, S. M. & Trianni, V. Automating hybrid col-\nlective intelligence in open-ended medical diagnostics.\nProceedings of the National Academy of Sciences 120,\ne2221473120 (2023).\n13.Klein, N. & Epley, N. Group discussion improves lie detec-\ntion. Proceedings of the National Academy of Sciences\n112,7460\u20137465 (2015).\n14.Jiang, D., Ren, X. & Lin, B. Y. LLM-Blender: Ensembling\nLarge Language Models with Pairwise Ranking and Gen-\nerative Fusion. arXiv preprint arXiv:2306.02561 (2023).\n15.Yang, H., Li, M., Xiao, Y., Zhou, H., Zhang, R. & Fang, Q.\nOne LLM is not Enough: Harnessing the Power of Ensem-\nble Learning for Medical Question Answering. medRxiv,\n2023\u201312 (2023).\n16.Chan, C. -M., Chen, W., Su, Y., Yu, J., Xue, W., Zhang,\nS., Fu, J. & Liu, Z. Chateval: Towards better llm-based\nevaluators through multi-agent debate. arXiv preprint\narXiv:2308.07201 (2023).\n|5", "mimetype": "text/plain", "start_char_idx": 3323, "end_char_idx": 4844, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"bd554c5e-9707-4c98-9292-f7ceea512b58": {"doc_hash": "d8a0f9c36ec7255dab95b6f92e7ded0e88064ae6201cb4f9824dacfa8c564e84", "ref_doc_id": "5f05c1b5-10b5-495f-aa31-fd82c55019da"}, "c61fcbd6-7577-4310-9a29-5eb824a2c466": {"doc_hash": "9d51029f4d6cf51f72318e0a3d89e3246feeb3060690c69606c10245457cf44f", "ref_doc_id": "5f05c1b5-10b5-495f-aa31-fd82c55019da"}, "7f06fbc1-1cf6-43d9-bc5f-515eb6696bc9": {"doc_hash": "f583f311da0c5ba039410ca9e4bfe51d551f7752751e5cf44bb7c88b222053d7", "ref_doc_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f"}, "ee7ff544-cd04-46df-a3a0-f3722090c606": {"doc_hash": "fe5945cc7b3779df05edc0a913acd60b71c1214863e2d5143fd746949966914e", "ref_doc_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f"}, "2967c7e2-b09e-47fa-b317-e3249dd951d2": {"doc_hash": "2764cb3bd0985d8ad7d030d577bbb3f17afccd8f096587b47de479076c1b551f", "ref_doc_id": "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f"}, "13524a0b-11ec-4ee1-ae08-3661d3c2ec2d": {"doc_hash": "7c5d34f26442ee6983b20eecc52836bdd2b5419279aa17f21264797da2ee379d", "ref_doc_id": "5622aac7-cb06-4429-a785-57c94763b738"}, "44f0dc74-c065-49f2-8d12-d0ecb6434100": {"doc_hash": "ad89f0f28fa94085adf0f7c3bf72fb7ffdc630eb583d66ab002b6e373a74e9ba", "ref_doc_id": "5622aac7-cb06-4429-a785-57c94763b738"}, "896307f0-5478-49a7-8374-54ba76656c3b": {"doc_hash": "0974d0efff1abea2953349e2c6e08a9c6e5c31f22507abc233ee932f0d446c38", "ref_doc_id": "83d1e05c-bf71-4b89-a844-e778bff1af40"}, "51840635-24ba-46a9-9cb5-e4e7ab9f4981": {"doc_hash": "d5ed21a0d3d63882b5d8a16ec7bcb2c170825841e8f09321b9601656dc3b2344", "ref_doc_id": "83d1e05c-bf71-4b89-a844-e778bff1af40"}, "6e0eb59a-b6dd-4a56-9b25-052df479a085": {"doc_hash": "89639554c17cc5102a7d49e2eb55c785e71cae68d25e18bdef31114eac4c28b4", "ref_doc_id": "d1cc9071-88d6-476a-b818-f9adb5739027"}, "c8610fa5-31b8-40bf-884f-5dae7bdd6be2": {"doc_hash": "1a04c9d934f6b8fd74cfde9e57c63093aa59aa1af2bfc0798bc22b641d1b5a3b", "ref_doc_id": "d1cc9071-88d6-476a-b818-f9adb5739027"}, "d8eaf973-a559-42b4-994a-9d757be0ff63": {"doc_hash": "c49114b2b88c7411eda86ad7ddf7d7710a3d48352dc9d82c8960238cb2d7ba8c", "ref_doc_id": "d1cc9071-88d6-476a-b818-f9adb5739027"}}, "docstore/ref_doc_info": {"5f05c1b5-10b5-495f-aa31-fd82c55019da": {"node_ids": ["bd554c5e-9707-4c98-9292-f7ceea512b58", "c61fcbd6-7577-4310-9a29-5eb824a2c466"], "metadata": {"page_label": "1", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}}, "92e91bd4-a8c1-4ef9-8c52-9fa4f7b27b4f": {"node_ids": ["7f06fbc1-1cf6-43d9-bc5f-515eb6696bc9", "ee7ff544-cd04-46df-a3a0-f3722090c606", "2967c7e2-b09e-47fa-b317-e3249dd951d2"], "metadata": {"page_label": "2", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}}, "5622aac7-cb06-4429-a785-57c94763b738": {"node_ids": ["13524a0b-11ec-4ee1-ae08-3661d3c2ec2d", "44f0dc74-c065-49f2-8d12-d0ecb6434100"], "metadata": {"page_label": "3", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}}, "83d1e05c-bf71-4b89-a844-e778bff1af40": {"node_ids": ["896307f0-5478-49a7-8374-54ba76656c3b", "51840635-24ba-46a9-9cb5-e4e7ab9f4981"], "metadata": {"page_label": "4", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}}, "d1cc9071-88d6-476a-b818-f9adb5739027": {"node_ids": ["6e0eb59a-b6dd-4a56-9b25-052df479a085", "c8610fa5-31b8-40bf-884f-5dae7bdd6be2", "d8eaf973-a559-42b4-994a-9d757be0ff63"], "metadata": {"page_label": "5", "file_name": "2402_08806v1.pdf", "Title of this paper": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy", "Authors": "Gioele Barabucci, Victor Shia, Eugene Chu, Benjamin Harack, Nathan Fu", "Date published": "02/13/2024", "URL": "http://arxiv.org/abs/2402.08806v1", "summary": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's\nPaLM 2 are proposed as viable diagnostic support tools or even spoken of as\nreplacements for \"curbside consults\". However, even LLMs specifically trained\non medical topics may lack sufficient diagnostic accuracy for real-life\napplications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical\nvignettes of real-life cases, we assessed and compared the accuracy of\ndifferential diagnoses obtained by asking individual commercial LLMs (OpenAI\nGPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of\ndifferential diagnoses synthesized by aggregating responses from combinations\nof the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads\nto more accurate differential diagnoses (average accuracy for 3 LLMs:\n$75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single\nLLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize\ndifferential diagnoses combining the responses of different LLMs achieves two\nof the necessary steps towards advancing acceptance of LLMs as a diagnostic\nsupport tool: (1) demonstrate high diagnostic accuracy and (2) eliminate\ndependence on a single commercial vendor."}}}}