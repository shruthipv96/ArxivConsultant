{"docstore/data": {"75881486-77b2-4239-8b63-75994378a112": {"__data__": {"id_": "75881486-77b2-4239-8b63-75994378a112", "embedding": null, "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cd0addb-54a2-401c-9293-89abce52365c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c5b2f7a56f3ce135a5505fbb509a984af76c7125fea007630ef15f1fce8f6fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f428f706-deda-42ae-902c-bb4f58b4bed8", "node_type": "1", "metadata": {}, "hash": "e82df5d2925e8b29d6011ace6eb26e289b7170956d01aa3733c5dddb8b8018e8", "class_name": "RelatedNodeInfo"}}, "text": "A Survey of Large Language Models on Generative\nGraph Analytics: Query, Learning, and Applications\nWenbo Shang\nDepartment of Computer Science\nHong Kong Baptist University\nHong Kong, China\ncswbshang@comp.hkbu.edu.hkXin Huang\nDepartment of Computer Science\nHong Kong Baptist University\nHong Kong, China\nxinhuang@comp.hkbu.edu.hk\nAbstract \u2014A graph is a fundamental data model to represent\nvarious entities and their complex relationships in society and\nnature, such as social networks, transportation networks, finan-\ncial networks, and biomedical systems. Recently, large language\nmodels (LLMs) have showcased a strong generalization ability\nto handle various NLP and multi-mode tasks to answer users\u2019\narbitrary questions and specific-domain content generation.\nCompared with graph learning models, LLMs enjoy superior\nadvantages in addressing the challenges of generalizing graph\ntasks by eliminating the need for training graph learning models\nand reducing the cost of manual annotation. In this survey, we\nconduct a comprehensive investigation of existing LLM studies\non graph data, which summarizes the relevant graph analytics\ntasks solved by advanced LLM models and points out the\nexisting remaining challenges and future directions. Specifically,\nwe study the key problems of LLM-based generative graph\nanalytics (LLM-GGA) with three categories: LLM-based graph\nquery processing (LLM-GQP), LLM-based graph inference and\nlearning (LLM-GIL), and graph-LLM-based applications. LLM-\nGQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge\ngraph (KG) based augmented retrieval , while LLM-GIL focuses\non learning and reasoning over graphs, including graph learning ,\ngraph-formed reasoning and graph representation . We summarize\nthe useful prompts incorporated into LLM to handle different\ngraph downstream tasks. Moreover, we give a summary of LLM\nmodel evaluation, benchmark datasets/tasks, and a deep pro and\ncons analysis of LLM models. We also explore open problems\nand future directions in this exciting interdisciplinary research\narea of LLMs and graph analytics.\nIndex Terms \u2014Graph, LLMs, GNNs, Prompt, Survey\nI. I NTRODUCTION\nLarge language models (LLMs) possess billions of parame-\nters and have been trained on extensive corpora using training\nstrategies like instruction tuning [1] [2] and Direct Preference\nOptimization(DPO) [3], enabling them to exhibit powerful\nreasoning and semantic representation capabilities, thereby\nadvancing AI intelligence closer to human levels.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2552, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f428f706-deda-42ae-902c-bb4f58b4bed8": {"__data__": {"id_": "f428f706-deda-42ae-902c-bb4f58b4bed8", "embedding": null, "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cd0addb-54a2-401c-9293-89abce52365c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c5b2f7a56f3ce135a5505fbb509a984af76c7125fea007630ef15f1fce8f6fd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75881486-77b2-4239-8b63-75994378a112", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "457b1147c1043aacc758a84c112b6a4765f74ea050e2779a3cd63772cb9b70fb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57cbc7a7-66aa-40cf-ae44-8431c6df11ec", "node_type": "1", "metadata": {}, "hash": "8ba332d0cc8d473463f8f1c798f17d670969baa51b7561f1e74d776c700908dd", "class_name": "RelatedNodeInfo"}}, "text": "We summarize\nthe useful prompts incorporated into LLM to handle different\ngraph downstream tasks. Moreover, we give a summary of LLM\nmodel evaluation, benchmark datasets/tasks, and a deep pro and\ncons analysis of LLM models. We also explore open problems\nand future directions in this exciting interdisciplinary research\narea of LLMs and graph analytics.\nIndex Terms \u2014Graph, LLMs, GNNs, Prompt, Survey\nI. I NTRODUCTION\nLarge language models (LLMs) possess billions of parame-\nters and have been trained on extensive corpora using training\nstrategies like instruction tuning [1] [2] and Direct Preference\nOptimization(DPO) [3], enabling them to exhibit powerful\nreasoning and semantic representation capabilities, thereby\nadvancing AI intelligence closer to human levels. Undoubt-\nedly, LLMs currently serve as the foundation model for NLP\ntasks [4] [5] [6], showcasing strong generalization abilities to\nhandle various NLP tasks such as question answering [7] [8],\nmachine translation [9], code generation [10] [11], etc. LLMs\nhave demonstrated extensive common knowledge and robust\nsemantic comprehension abilities, fundamentally transforming\nexisting text-processing workflows. While initially designed\nfor text data, LLMs are increasingly being utilized for tasks\nLLM-GGALLM-GQPLLM-GILGraph-LLM-based applications\nGraphsLLMs+\nGraph Queries\nLLMsAnswersLLMs\nGraphs\nGraphsGraph representationGraph learning tasksGraph reasoning\nKGsFig. 1: Illustration of the LLM-GGA domain. LLM-GGA do-\nmain includes three principal components: LLM-based graph\nquery processing (LLM-GQP), which necessitates the melding\nof graph analytics techniques and LLM prompts for query pro-\ncessing; LLM-based graph inference and learning (LLM-GIL),\nfocusing on learning and reasoning over graphs; Graph-LLM-\nbased applications that employ the graph-LLM framework to\naddress non-graph tasks, such as recommendation systems.\nbeyond language processing, aiming to leverage the robust ca-\npabilities of LLMs across different tasks, showcasing superior\nperformance.\nGraphs, as structured data, play a crucial role in various real-\nworld application scenarios, including the citation networks\n[12], social networks [13], molecular graphs [14], web links\n[15], and to name a few. Various graph analytics tasks have\nbeen studied to show their usefulness, e.g., node classification,\nlink prediction, subgraph mining, influence maximization, and\nso on. Their versatility and ability to capture complex rela-\ntionships have made graphs indispensable tools in academic\nresearch and industry platforms.", "mimetype": "text/plain", "start_char_idx": 1782, "end_char_idx": 4346, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "57cbc7a7-66aa-40cf-ae44-8431c6df11ec": {"__data__": {"id_": "57cbc7a7-66aa-40cf-ae44-8431c6df11ec", "embedding": null, "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6cd0addb-54a2-401c-9293-89abce52365c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c5b2f7a56f3ce135a5505fbb509a984af76c7125fea007630ef15f1fce8f6fd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f428f706-deda-42ae-902c-bb4f58b4bed8", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "90bc213ac22ca2b068f9d8c9a540c2819b3a2b7db4517fa0488f547601996b1b", "class_name": "RelatedNodeInfo"}}, "text": "beyond language processing, aiming to leverage the robust ca-\npabilities of LLMs across different tasks, showcasing superior\nperformance.\nGraphs, as structured data, play a crucial role in various real-\nworld application scenarios, including the citation networks\n[12], social networks [13], molecular graphs [14], web links\n[15], and to name a few. Various graph analytics tasks have\nbeen studied to show their usefulness, e.g., node classification,\nlink prediction, subgraph mining, influence maximization, and\nso on. Their versatility and ability to capture complex rela-\ntionships have made graphs indispensable tools in academic\nresearch and industry platforms. Recently, one kind of graph-\nbased learning model, graph neural network (GNN) [16] [17],\nhas been widely studied and applied to solve challenging graph\ntasks. The GNN models utilize recursive message passing\n[18] and aggregation mechanisms [19] among nodes to derive\nrepresentations of nodes, edges, or entire graphs, which have\nbeen used for various downstream tasks. This is thanks to\nthe strong ability of GNN models to capture both graph\nstructure and node features. However, GNNs exhibit weak\ngeneralization capabilities [20] [21] [22], requiring retraining\nfor different graph tasks and showing limited transfer ability.arXiv:2404.14809v1  [cs.CL]  23 Apr 2024", "mimetype": "text/plain", "start_char_idx": 3680, "end_char_idx": 5013, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51127c00-5ceb-467a-b0a3-caa85af34564": {"__data__": {"id_": "51127c00-5ceb-467a-b0a3-caa85af34564", "embedding": null, "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7bc5d992-276b-4dce-af34-5555472105c1", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "9b9ebb743092cadb75fecb1a88765731fc688bba1e6166115c4ab45103b88121", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42e86d8c-6918-49fe-8626-7b082fdaea39", "node_type": "1", "metadata": {}, "hash": "134cf810a9fc5cdcb3ab407579d990b601e0bee4c1fb51c619cf4af4e239d14c", "class_name": "RelatedNodeInfo"}}, "text": "In other words, no universal graph foundation model could be\neasily generalized to handle various types of graph tasks.\nTherefore, whether LLMs\u2019 powerful reasoning, semantic\nrepresentation, and generalization capabilities can be applied\nto address graph tasks, leading to the inspiration of a graph\nfoundation model, is the core of current efforts in leveraging\nexisting large language models for graph-related tasks. In one\nword, can LLMs solve graph data tasks? More specifically,\nwe study three detailed questions: (a) what specific graph\ntasks can LLMs answer? (b) How do LLMs tackle these\ntasks? (c) What is the effectiveness of LLM-based methods\nin solving these tasks compared with the existing graph-based\napproaches?\nTo address the above question, this survey conducts a\ncomprehensive study of existing relevant work on graph an-\nalytics and LLMs, focusing on exploring the key issue of\nthe LLM-based generative graph analytics (LLM-GGA) field.\nDrawing from a thorough investigation of the LLM-GGA\ndomain, we offer a structured and methodical analysis that\ndelineates the field into three principal components: LLM-\nbased graph query processing (LLM-GQP), which necessitates\nthe melding of graph analytics techniques and LLM prompts\nfor query processing; LLM-based graph inference and learning\n(LLM-GIL), focusing on learning and reasoning over graphs;\nand lastly, graph-LLM-based applications that employ the\ngraph-LLM framework to address non-graph tasks, such as\nrecommendation systems. The framework is shown in Figure\n1.\nWe categorize these three main components into a total\nof six directions to provide a guideline for researchers to\nconduct more in-depth studies. LLM-GQP includes graph\nunderstanding and KG-based augmented retrieval directions.\nLLM-GIL covers graph learning, graph-formed reasoning, and\ngraph representation directions. The sixth direction is graph-\nLLM-based applications. The following section details these\nsix directions:\n\u2022Graph understanding tasks. This research direction is\nstudying whether LLMs can solve graph algorithm prob-\nlems, exploring whether LLMs can comprehend graph\nstructures to conduct graph mining and graph search. Cur-\nrent methods have primarily explored LLMs\u2019 understand-\ning of graph structures, such as shortest path, clustering\ncoefficient computation [23] [24], and more complex\nproblems like maximum flow and Hamilton path [25] [26]\n[27]. Two main methods are introduced: prompting and\nsupervised fine-tuning (SFT). The prompting methods\nexplore the LLM\u2019s current structural understanding abil-\nity through query processing. Meanwhile, SFT methods\nenhance LLMs\u2019 structure understanding capability by\ntuning it on specific graph datasets.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2703, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "42e86d8c-6918-49fe-8626-7b082fdaea39": {"__data__": {"id_": "42e86d8c-6918-49fe-8626-7b082fdaea39", "embedding": null, "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7bc5d992-276b-4dce-af34-5555472105c1", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "9b9ebb743092cadb75fecb1a88765731fc688bba1e6166115c4ab45103b88121", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "51127c00-5ceb-467a-b0a3-caa85af34564", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2a2fce7e88dd2b67eb2c491e79a83fbdce5506a8c6c0adb75612bcecfd4313a5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d908595-7577-4425-b9a3-a9fb508ef678", "node_type": "1", "metadata": {}, "hash": "05b173bda073bfcf58de574d16a2b7758e2700bc6a08278ecd6daed65196512d", "class_name": "RelatedNodeInfo"}}, "text": "The sixth direction is graph-\nLLM-based applications. The following section details these\nsix directions:\n\u2022Graph understanding tasks. This research direction is\nstudying whether LLMs can solve graph algorithm prob-\nlems, exploring whether LLMs can comprehend graph\nstructures to conduct graph mining and graph search. Cur-\nrent methods have primarily explored LLMs\u2019 understand-\ning of graph structures, such as shortest path, clustering\ncoefficient computation [23] [24], and more complex\nproblems like maximum flow and Hamilton path [25] [26]\n[27]. Two main methods are introduced: prompting and\nsupervised fine-tuning (SFT). The prompting methods\nexplore the LLM\u2019s current structural understanding abil-\nity through query processing. Meanwhile, SFT methods\nenhance LLMs\u2019 structure understanding capability by\ntuning it on specific graph datasets. However, many more\ntasks are yet to be explored, such as the community\nsearch, keyword search, subgraph pattern mining, and\nother NP-hard complex graph problems [28] [29].\n\u2022Graph learning tasks. This direction explores whether\nLLMs can combine graph structure and attributes for\nlearning, extracting features of nodes, edges, and graphs,and understanding the semantic information of graphs,\nfor example, tasks like node classification, graph classi-\nfication, and GQL generation [30] [31] [32] [33]. There\nare two main pipelines: LLM-GNN pipelines and LLM\npipelines. LLMs can leverage their powerful reasoning\nability and vast knowledge repository to enhance GNNs\nand also can predict results directly.\n\u2022Graph-formed reasoning. This direction explores how\nLLMs use graph structures to simulate human thinking\nduring reasoning [34] [35] [36], enabling them to solve\nmore complex reasoning problems such as algorithmic,\nlogical, and mathematical tasks. Graph-formed reasoning\ninvolves two types of reasoning: think on the graph and\nverify on the graph. Think on the graph refers to LLMs\nderiving the final conclusion through the graph structure.\nVerify on the graph refers to verifying the correctness of\nthe LLMs\u2019 intermediate or final outputs through the graph\nstructure.\n\u2022Graph representation. This direction explores enhanc-\ning graph representation with LLMs, particularly for Text\nAttribute Graphs (TAGs). LLMs\u2019 strong text representa-\ntion capabilities allow text embeddings to capture deeper\nsemantic nuances. However, the key challenge in this\narea remains how to capture and integrate graph structure\ninto graph representation effectively [37] [38] [39]. There\nare three forms of graph representation: graph embed-\nding, graph-enhanced text embedding, and graph-encoded\nprompts. Graph embedding methods transform a graph\ninto a sequential format for LLM processing.", "mimetype": "text/plain", "start_char_idx": 1855, "end_char_idx": 4577, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d908595-7577-4425-b9a3-a9fb508ef678": {"__data__": {"id_": "7d908595-7577-4425-b9a3-a9fb508ef678", "embedding": null, "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7bc5d992-276b-4dce-af34-5555472105c1", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "9b9ebb743092cadb75fecb1a88765731fc688bba1e6166115c4ab45103b88121", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42e86d8c-6918-49fe-8626-7b082fdaea39", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2d1ed08c8ca005fa465688e2f5bded7d81d3fc6aeace5c1b7a0278254a0f8799", "class_name": "RelatedNodeInfo"}}, "text": "Graph-formed reasoning\ninvolves two types of reasoning: think on the graph and\nverify on the graph. Think on the graph refers to LLMs\nderiving the final conclusion through the graph structure.\nVerify on the graph refers to verifying the correctness of\nthe LLMs\u2019 intermediate or final outputs through the graph\nstructure.\n\u2022Graph representation. This direction explores enhanc-\ning graph representation with LLMs, particularly for Text\nAttribute Graphs (TAGs). LLMs\u2019 strong text representa-\ntion capabilities allow text embeddings to capture deeper\nsemantic nuances. However, the key challenge in this\narea remains how to capture and integrate graph structure\ninto graph representation effectively [37] [38] [39]. There\nare three forms of graph representation: graph embed-\nding, graph-enhanced text embedding, and graph-encoded\nprompts. Graph embedding methods transform a graph\ninto a sequential format for LLM processing. Graph-\nenhanced text embedding methods integrate structure into\ntext embedding, where the integration method can be\nconcatenation. Graph-encoded prompts focus on the way\na graph is described within prompts.\n\u2022Knowledge Graph (KG) based augmented retrieval.\nThis direction investigates the relationship between LLMs\nand Knowledge Graphs (KGs). With the emergence of\nLLMs, discussions have arisen regarding the potential\nreplacement of KGs [40] [41] [42] [43]. Consequently,\nthis paper discusses the limitations of LLMs in processing\nfactual knowledge, evaluates strategies for improving\nLLM efficacy via KG-based augmented retrieval, and\ninvestigates potential avenues for future advancements in\nthis field.\n\u2022Graph-LLM-based applications. This part explores the\ntasks where graph-LLM-based methods can be applied\nfor useful downstream application [44] [45] [46], such as\nrecommendation systems, conversational understanding,\nand so on.\nWe comprehensively analyze these six research directions\nof LLM-GGA to provide valuable definitions and highlighted\nmethodologies. We also highlight the pros and cons of these\nmethods and showcase future directions. To further explore the\ncapabilities of LLMs reliably, this paper uses the prompting\nmethod to test the effectiveness of LLMs in tasks such as\ngraph structure understanding, graph learning, and graph-", "mimetype": "text/plain", "start_char_idx": 3655, "end_char_idx": 5927, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5bb2c668-41e4-478d-97ba-8ac4c86c1102": {"__data__": {"id_": "5bb2c668-41e4-478d-97ba-8ac4c86c1102", "embedding": null, "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "40979dfbcbcdad6d50b75b8c202d10c5db9d394edf70d01a94e1a8bf833f3d10", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e67eba12-fb45-4fa3-be1f-486d887e2bb5", "node_type": "1", "metadata": {}, "hash": "39dcfcfa7f1373cf22efe6234146e32262dfa134b8c4e814dee3a64e1e354153", "class_name": "RelatedNodeInfo"}}, "text": "formed reasoning. Details of the prompts and results obtained\nduring testing are also provided. Additionally, we refine and\ncompile commonly used and effective prompts for graph-\nrelated tasks, assisting researchers in conducting experiments.\nFurthermore, this paper also organizes and introduces the\ncode for existing popular methods, benchmarks for LLM-GGA\ntasks, and evaluations measuring LLM performance in graph\ntasks to facilitate future research.\nOur contributions and the identified challenges for future\nresearch. In this paper, we provide a comprehensive survey of\nthe state-of-the-art work on LLMs applied to graph data. We\nbegin by delineating six critical directions in the field of LLM-\nGGA: graph structure understanding, graph learning, graph-\nformed reasoning, graph representation, KG-based augmented\nretrieval, and graph-LLM-based applications. This categoriza-\ntion clarifies the current work and offers a guideline for future\nresearch endeavors. In each direction, we propose a structured\nintroduction and summarization using vivid examples and\noffer suitable specific pipelines. We analyze the advantages\nand limitations of current methodologies and suggest avenues\nfor future research. Furthermore, we organize resources related\nto benchmarks, evaluations, and code links within the LLM-\nGGA domain to facilitate further investigation by researchers.\nLastly, we identify the fundamental challenges in the LLM-\nGGA field, which are the primary obstacles to advancing LLM\nin solving graph tasks, including the fundamental issue of how\nsequential LLM handles structural graph data, the efficiency\nissue of large-scale graph data, and the NP-hard problems of\ncomplex graph analytics. This clarification guides the research\ndirection for future work on LLM-GGA.\nRoadmaps . The organization of this paper is as follows. We\nfirst present the fundamental preliminaries and summarize\nthe graph description language, which converts graphs into\nsequences before inputting them into LLMs in Section II.\nThen, we introduce six tasks of LLM-based graph analytics\none by one. We present the graph structure understanding\ndirection in Section III, graph learning direction in Section IV,\ngraph-formed reasoning in Section V, graph representation in\nSection VI, KG-based augmented retrieval in Section VII and\ngraph-LLM-based applications in Section VIII. In the above\nsix directions, we clarify the tasks that LLMs can perform,\ndiscuss the methodologies, conduct a comparative analysis,\nand propose guidelines and principles in this direction. Fol-\nlowing this, Section IX introduces the popular datasets and\nnew datasets for solving the above tasks and also provides\nmetrics for evaluating LLMs or tasks in different directions. In\nSection X, we identify and discuss the current and upcoming\nchallenges that LLM-GGA faces and future directions. Finally,\nour conclusions are presented in Section XI.\nII.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2910, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e67eba12-fb45-4fa3-be1f-486d887e2bb5": {"__data__": {"id_": "e67eba12-fb45-4fa3-be1f-486d887e2bb5", "embedding": null, "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "40979dfbcbcdad6d50b75b8c202d10c5db9d394edf70d01a94e1a8bf833f3d10", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5bb2c668-41e4-478d-97ba-8ac4c86c1102", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "604ddfdf3481ee9e05951272dbb9480dd32852e842b4a41e5fad1fb67ecd8376", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb56eed8-d7d1-493e-acef-36c00ce3f746", "node_type": "1", "metadata": {}, "hash": "ed700ec71bfaba8ddf801ecc6688397da6004864c7ac907e1033db70b41a4106", "class_name": "RelatedNodeInfo"}}, "text": "Then, we introduce six tasks of LLM-based graph analytics\none by one. We present the graph structure understanding\ndirection in Section III, graph learning direction in Section IV,\ngraph-formed reasoning in Section V, graph representation in\nSection VI, KG-based augmented retrieval in Section VII and\ngraph-LLM-based applications in Section VIII. In the above\nsix directions, we clarify the tasks that LLMs can perform,\ndiscuss the methodologies, conduct a comparative analysis,\nand propose guidelines and principles in this direction. Fol-\nlowing this, Section IX introduces the popular datasets and\nnew datasets for solving the above tasks and also provides\nmetrics for evaluating LLMs or tasks in different directions. In\nSection X, we identify and discuss the current and upcoming\nchallenges that LLM-GGA faces and future directions. Finally,\nour conclusions are presented in Section XI.\nII. P RELIMINARY\nIn the subsequent section, we will initially introduce graph\ndata, proceed to discuss GNNs as a paradigm of graph-\nbased learning models, then introduce LLMs and distinguish\nLLMs and PLMs, and ultimately introduce graph descriptionlanguage, which can transform the graph into sequential data\nas the input of LLMs.\nA. Graph\nGraph data represents complex relationships through nodes\nand edges, where nodes represent entities and edges represent\ntheir interconnections. This structure excels at modeling intri-\ncate networks such as social, biological, and transportation\nsystems. It enables analyses like community detection and\nshortest path calculations, offering critical insights into the\ndynamics of various systems. Formally, a general graph can\nbe represented as G= (V,E), where VandEdenote the set\nof nodes and edges. V={v1, v2, ..., v n}where the number\nof nodes is |V|and|V|=n.E={eij}where the number of\nedges is |E|andeijis an edge from vitovj.\nB. Graph Neural Network\nGraph Neural Networks (GNNs) [16] [17] are a type of deep\nlearning model that can handle graph-structured data. The goal\nof these GNNs is to learn representations for each node, which\nare computed based on the node\u2019s own features, the features of\nthe edges connected to it, the representations of its neighbors,\nand the features of its neighboring nodes,\nhl\nv=AGGR (hl\u22121\nv,{hl\nu\u22121 :u\u2208Nv};\u03b8l) (1)\nwhere hl\nvrepresents the representation of node vin the l-th\nlayer. AGGR denotes the aggregation function that aggregates\nthe representations of neighboring nodes from the previous\nlayer.", "mimetype": "text/plain", "start_char_idx": 2014, "end_char_idx": 4485, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fb56eed8-d7d1-493e-acef-36c00ce3f746": {"__data__": {"id_": "fb56eed8-d7d1-493e-acef-36c00ce3f746", "embedding": null, "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "40979dfbcbcdad6d50b75b8c202d10c5db9d394edf70d01a94e1a8bf833f3d10", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e67eba12-fb45-4fa3-be1f-486d887e2bb5", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3cbf2ec10e593a86ab82fbd29e2f9785df0f7e3d2554302bbd1193311e40859d", "class_name": "RelatedNodeInfo"}}, "text": "B. Graph Neural Network\nGraph Neural Networks (GNNs) [16] [17] are a type of deep\nlearning model that can handle graph-structured data. The goal\nof these GNNs is to learn representations for each node, which\nare computed based on the node\u2019s own features, the features of\nthe edges connected to it, the representations of its neighbors,\nand the features of its neighboring nodes,\nhl\nv=AGGR (hl\u22121\nv,{hl\nu\u22121 :u\u2208Nv};\u03b8l) (1)\nwhere hl\nvrepresents the representation of node vin the l-th\nlayer. AGGR denotes the aggregation function that aggregates\nthe representations of neighboring nodes from the previous\nlayer. For the tasks that focus on individual nodes, e.g.,\nnode classification, the learned representations can be used\ndirectly to accomplish specific objectives. However, for the\ntasks that consider the entire graph, e.g., graph classification,\na global representation can be obtained by pooling or applying\nother methods to the representations of all nodes. This global\nrepresentation can then be used to perform the corresponding\ntasks.\nC. Large Language Models\nCurrently, there is no precise definition for Large Language\nModels (LLMs). However, according to the pioneering surveys\n[47] [48] on LLMs, a distinction can be made between LLMs\nand Pre-trained Language Models (PLMs). LLMs are large\nlanguage models with billion-level parameters that are pre-\ntrained on massive amounts of data, such as Llama [5] and\nChatGPT. Conversely, PLMs are pre-trained language models\nwith million-level parameters that can be more easily fine-\ntuned on task-specific data. While LLMs and PLMs share\nsimilarities in their pre-training process, the former is char-\nacterized by its larger size and ability to generate human-like\ntext. Thus, it is essential to consider the potential implications\nof using LLMs in various applications.\nD. Graph Description Language\nGraphs are represented in the structured data in arbitrary\nshapes, while LLMs typically process sequential data, such\nas the text as a sequence of words. To bridge this gap,", "mimetype": "text/plain", "start_char_idx": 3878, "end_char_idx": 5907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "083c5355-3822-4dac-bc58-cb1441b6d345": {"__data__": {"id_": "083c5355-3822-4dac-bc58-cb1441b6d345", "embedding": null, "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66598fac-9327-4310-81ba-8884891fb43e", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a3e7be591857110955c02960ece96b1aff375b4c8ea52dc1625717b87869a941", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e39ae4c-8895-4bc7-b47d-5dd231a7c694", "node_type": "1", "metadata": {}, "hash": "9c59ddeccbf82340114fec8222c3cb0239a92461822b819c4965b3aeee1e63c1", "class_name": "RelatedNodeInfo"}}, "text": "Graph Structure Understanding Tasks\n14320Graph  Size CalculationGiven <graph>, what is the number of nodes and edges in this graph? Please answer with the number of nodes: X, number of edges: X. 14320Degree CalculationGiven <graph>, what is the degree of node 4?  Or, like, find the node degree of node [given node] in the given graph.14320Connected Nodes SearchGiven <graph>. Is node 3 the 1-hop neighbor of node 4? List the answers after \u201cAns:\u201d in the format of [Yes, No,]. 14320Edge ValidationGiven <graph>. Is there an edge between node 1 and node 2?14320Path SearchGiven <graph>. Simple path: Find a single path from node 0 to node 4 connected by edges in the given graph. Shortest path: Give the shortest path from node 0 to node 4.14320Attribute RetrievalGiven <graph>, what is the title of node 0?Abstract: Text in curve orientation, despite being one of the common\u2026Title: Total Text A Comprehensive Dataset For Scene Text Detection And Recognition.14320Graph DensityGiven <graph>, what is the density of the given graph?14320EccentricityGiven <graph>, what is the eccentricity of the node 0?14320Pattern matchingGiven <graph>, in the given graph, the triangle must be connected by three edges, list the triangle after \u201dAns:\u201d in the format of [0-1-2]14320Topological SortingIn a directed graph with 5 nodes numbered from 0 to 4: node 0 should be visited before node 1, ... Q: Can all the nodes be visited? Give the solution.12100Bipartite Graph MatchingThere are 2 job applicants numbered from 0 to 1, and 3 jobs numbered from 0 to 2. Each applicant is interested in some of the jobs. Each job can only accept one applicant and a job applicant can be appointed for only one job. Applicant 0 is interested in job 1, ... Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find the job they are interested in.14320Hamilton PathGiven <graph>, is there a path in this graph that visits every node exactly once? If yes, give the path. Note that in a path, adjacent nodes must be connected with edges.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2041, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2e39ae4c-8895-4bc7-b47d-5dd231a7c694": {"__data__": {"id_": "2e39ae4c-8895-4bc7-b47d-5dd231a7c694", "embedding": null, "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66598fac-9327-4310-81ba-8884891fb43e", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a3e7be591857110955c02960ece96b1aff375b4c8ea52dc1625717b87869a941", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "083c5355-3822-4dac-bc58-cb1441b6d345", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "27fb6c39e40b597e109c713711efc99d310c1bfcce67e38d3de79afa5011053d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b73c03a-7057-4816-b22b-44b2473f6408", "node_type": "1", "metadata": {}, "hash": "8a7182283a7f7a849486e04b857af9c11825b3c40e6eb08353675d3079af51fd", "class_name": "RelatedNodeInfo"}}, "text": "Give the solution.12100Bipartite Graph MatchingThere are 2 job applicants numbered from 0 to 1, and 3 jobs numbered from 0 to 2. Each applicant is interested in some of the jobs. Each job can only accept one applicant and a job applicant can be appointed for only one job. Applicant 0 is interested in job 1, ... Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find the job they are interested in.14320Hamilton PathGiven <graph>, is there a path in this graph that visits every node exactly once? If yes, give the path. Note that in a path, adjacent nodes must be connected with edges. 14320Maximum FlowIn a directed graph with 5 nodes numbered from 0 to 4, and the edges are: an edge from node 0 to node 1 with capacity 10... Q: What is the maximum flow from node 0 to node 3?101559(a)(b)(c) (d) (e)\n(f)(g)(h)(j)\n(k)(l) (m)(n) 14320Graph DiameterGiven <graph>, what is the diameter of the given graph?(i)Fig. 2: Graph Structure Understanding tasks.\nthe graph description language (GDL) transforms the graph\ninto sequential data, which can be inputted into an LLM.\nSpecifically, GDL aims to convert graphs into sequential data\nwhile retaining the structure and unique attributes of the graph.\nThis conversion allows the graph\u2019s information to be fed into\nan LLM for processing. There are several graph description\nlanguages:\n\u2022Text description. Graph structure can be described using\nwords such as \u2018Node 1 is connected to Node 2\u2019 and\n\u2018There are three nodes connected to Node 1\u2019.\n\u2022Adjacency list. An adjacency list represents each vertex\nin the graph with the collection of its neighbouring\nvertices or edges. Node A is connected with node B and\nnode C can be denoted as N(v) ={B, C}.\n\u2022Edge list. An edge list represents the edge connections\nbetween two nodes in the graph. (A, B) indicates a\nconnection between nodes A and B.\n\u2022GML. Graph Modelling Language [49] consists of an\nunordered sequence of node and edge elements enclosed\nwithin \u2018[\u00b7]\u2019.\n\u2022GraphML. Graph Markup Language [50] consists of\nXML containing a graph element and an unordered\nsequence of node and edge elements.\n\u2022SQL. Several specialized SQL languages are designed\nspecifically for working with graph data. These languages\nare also capable of serving as graph description lan-\nguages.", "mimetype": "text/plain", "start_char_idx": 1414, "end_char_idx": 3705, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6b73c03a-7057-4816-b22b-44b2473f6408": {"__data__": {"id_": "6b73c03a-7057-4816-b22b-44b2473f6408", "embedding": null, "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66598fac-9327-4310-81ba-8884891fb43e", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a3e7be591857110955c02960ece96b1aff375b4c8ea52dc1625717b87869a941", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e39ae4c-8895-4bc7-b47d-5dd231a7c694", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "ef3cc905e9fa68414f52aab08c2668023aacad2bd625e601f6fbafe04d7b629b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7817e635-6610-4f17-a01d-1817b4c707bb", "node_type": "1", "metadata": {}, "hash": "1468f8f6e393bdcdfba340738a1dff0f447c089449ee4a74ebb58caa84154171", "class_name": "RelatedNodeInfo"}}, "text": "\u2022Adjacency list. An adjacency list represents each vertex\nin the graph with the collection of its neighbouring\nvertices or edges. Node A is connected with node B and\nnode C can be denoted as N(v) ={B, C}.\n\u2022Edge list. An edge list represents the edge connections\nbetween two nodes in the graph. (A, B) indicates a\nconnection between nodes A and B.\n\u2022GML. Graph Modelling Language [49] consists of an\nunordered sequence of node and edge elements enclosed\nwithin \u2018[\u00b7]\u2019.\n\u2022GraphML. Graph Markup Language [50] consists of\nXML containing a graph element and an unordered\nsequence of node and edge elements.\n\u2022SQL. Several specialized SQL languages are designed\nspecifically for working with graph data. These languages\nare also capable of serving as graph description lan-\nguages. Some notable examples include Cypher [51], a\nquery language developed by Neo4j, and Gremlin [52],\nSPARQL [53], and GSQL [54]. They combine SQL-\nlike syntax with graph-specific constructs and algorithms,\nmaking them suitable for complex graph analytics tasks.\n\u2022Multi-modality encoding. Except for text description,graph structure can also be represented using image\ndescription and motif description. The graph can be visu-\nalized as an image and inputted into an LLM to process\nimages. Alternatively, motifs such as stars, triangles, or\nclique patterns can represent the graph structure as input\ninto an LLM.\n\u2022Encode as a story. The graph can be encoded within\na specific context, such as a friendship, co-authorship,\nsocial network, politician, or expert. For example, the\nconnections between nodes can represent friendship re-\nlationships. We can assign names to the nodes, such as\n\u2018David\u2019 and \u2018Alice\u2019.\nNotably, (1) different graph description languages can yield\ndifferent results of LLMs. Therefore, it is suggested to test\nwith multiple GDLs and select the one with the best experi-\nmental results. (2) If needed, the LLM\u2019s output form can be\nspecified along with GDLs in the prompt. LLMs often generate\nexcessive reasoning processes that may be unnecessary, so\nstandardizing the LLM\u2019s output can be beneficial.\nIII. G RAPH STRUCTURE UNDERSTANDING TASKS\nGraph structure understanding tasks evaluate whether LLMs\ncan comprehend graph structures. Simple tasks include the\nqueries of neighbors, shortest paths, connectivity, the calcu-\nlation of graph radius, and the clustering coefficient. More\ncomplex tasks include solving maximum flow problems and\nperforming topological sorting.", "mimetype": "text/plain", "start_char_idx": 2934, "end_char_idx": 5392, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7817e635-6610-4f17-a01d-1817b4c707bb": {"__data__": {"id_": "7817e635-6610-4f17-a01d-1817b4c707bb", "embedding": null, "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66598fac-9327-4310-81ba-8884891fb43e", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a3e7be591857110955c02960ece96b1aff375b4c8ea52dc1625717b87869a941", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6b73c03a-7057-4816-b22b-44b2473f6408", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c57f25927105a7d1ee50450b910a7e99a3973b1521a38d90f34180cbd8762fe", "class_name": "RelatedNodeInfo"}}, "text": "We can assign names to the nodes, such as\n\u2018David\u2019 and \u2018Alice\u2019.\nNotably, (1) different graph description languages can yield\ndifferent results of LLMs. Therefore, it is suggested to test\nwith multiple GDLs and select the one with the best experi-\nmental results. (2) If needed, the LLM\u2019s output form can be\nspecified along with GDLs in the prompt. LLMs often generate\nexcessive reasoning processes that may be unnecessary, so\nstandardizing the LLM\u2019s output can be beneficial.\nIII. G RAPH STRUCTURE UNDERSTANDING TASKS\nGraph structure understanding tasks evaluate whether LLMs\ncan comprehend graph structures. Simple tasks include the\nqueries of neighbors, shortest paths, connectivity, the calcu-\nlation of graph radius, and the clustering coefficient. More\ncomplex tasks include solving maximum flow problems and\nperforming topological sorting. These tasks need LLMs to\ncomprehend graph structures locally and globally, as shown in\nFigure 2. In this section, we present 21 graph understanding\ntasks along with their definitions. Subsequently, we elaborate\non the two main methods currently used to address graph\nstructure understanding tasks: prompting and supervised fine-\ntuning LLMs.", "mimetype": "text/plain", "start_char_idx": 4548, "end_char_idx": 5734, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77d06247-7c8e-472f-aee9-e7b66e777805": {"__data__": {"id_": "77d06247-7c8e-472f-aee9-e7b66e777805", "embedding": null, "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "574f9694-51c7-47c9-bd44-b78161bc75c0", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0fa48c1f38fccc7a5b1f689e5a54b7dcf91795a122cf582c34014ac920d037bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f2bdf622-04df-4aa2-a512-39c9ef57f172", "node_type": "1", "metadata": {}, "hash": "ef629ce3657e8aa44c9f1b42ffad8e6805db4b800c932248c7a5ab51d464115f", "class_name": "RelatedNodeInfo"}}, "text": "Task Prompts\nGraph Data Loading The structure of the [file path] molecular graph of the benzene ring contains a hexagon.\nGraph Size Detection Given [graph], what is the number of nodes and edges in this graph? Please answer with the number of nodes:\nX, number of edges: X.\nDegree Detection Given [graph], what is the degree of node 4? Or, find the node degree of node [given node] in the given graph.\nConnected Nodes Given [graph]. Is node 5 the 1-hop neighbor of node 4? List the answers after \u201cAns:\u201d in the format of [Yes, No,].\nEdge Detection Given [graph]. Is there an edge between node 1 and node 2?\nPath Simple path: Given the undirected graph with the specified nodes and edges, nodes: [0, 1, 2, 3, 4], edges: [(0,\n1), (1, 4), (1, 3), (4, 3), (3, 2)], find a single path from node 1 to node 2 connected by edges in the given graph.\nShortest path: Given the directed graph with the specified nodes and edges, nodes: [0, 1, 2, 3, 4], edges: [(0, 1),\n(1, 4), (1, 3), (4, 3), (3, 2)], give the shortest path from node 0 to node 4.\nAttribute Retrieval Given [graph]. What is the title of node 0?\nGraph Density Given [graph]. What is the density of the given graph?\nEccentricity Given [graph]. What is the eccentricity of the given graph?\nGraph Radius Given [graph]. What is the radius of the given graph?\nGraph Diameter Given [graph]. What is the diameter of this graph?\nGraph Periphery Given [graph]. What is the periphery of this graph? Or What are the nodes included by the periphery of the given\ngraph?\nClustering Coefficient Computing Given [graph]. What is the clustering coefficient of [given node]?\nTABLE I: Prompts for Graph Structure Understanding Tasks, where [graph] is the input of the data.\nA. Task Introduction\n1) Graph size calculation: Graph size refers to the number\nof nodes and edges in a graph. Given a general graph G=\n(V,E), the graph size detection task is to detect the |V|and|E|\ninG. Through this task, LLMs are expected to understand the\nfundamental structure of a graph accurately. Given a prompt\ndescribing the graph and asking related queries, LLMs are\nsupposed to determine |V|and|E|, as shown in Figure 2 (a).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2143, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f2bdf622-04df-4aa2-a512-39c9ef57f172": {"__data__": {"id_": "f2bdf622-04df-4aa2-a512-39c9ef57f172", "embedding": null, "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "574f9694-51c7-47c9-bd44-b78161bc75c0", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0fa48c1f38fccc7a5b1f689e5a54b7dcf91795a122cf582c34014ac920d037bd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "77d06247-7c8e-472f-aee9-e7b66e777805", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "7b76258c948ed23ae0d3b87cf55c2cf25e7c0c432580045c3325f3731e60460b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "13ab9919-3750-4d34-a1c5-20e16355554a", "node_type": "1", "metadata": {}, "hash": "3cdad20b61bb4e6fd5b5d822a7bec3bb50eedad3d223c2819a555c97a50e2bb8", "class_name": "RelatedNodeInfo"}}, "text": "Graph Periphery Given [graph]. What is the periphery of this graph? Or What are the nodes included by the periphery of the given\ngraph?\nClustering Coefficient Computing Given [graph]. What is the clustering coefficient of [given node]?\nTABLE I: Prompts for Graph Structure Understanding Tasks, where [graph] is the input of the data.\nA. Task Introduction\n1) Graph size calculation: Graph size refers to the number\nof nodes and edges in a graph. Given a general graph G=\n(V,E), the graph size detection task is to detect the |V|and|E|\ninG. Through this task, LLMs are expected to understand the\nfundamental structure of a graph accurately. Given a prompt\ndescribing the graph and asking related queries, LLMs are\nsupposed to determine |V|and|E|, as shown in Figure 2 (a).\n2) Degree calculation: The degree detection task involves\ndetermining the degree of a specific node in a graph. The\nneighbors of node vcan be denoted as N(v) ={u|(u, v)\u2208\nE(v)}, where E(v)is the edge set including edges connected to\nv. The degree of viis the number of its neighbors in G, which\ncan be denotes as degG(vi) =|N(vi)|. Through this task,\nLLMs are expected to comprehend the context surrounding vi\nand identify N(vi)accurately. By inputting a prompt about\nviandG, LLMs are expected to calculate the degree of the\nnode. This task is shown in Figure 2 (b).\n3) Connected nodes search: The connected nodes detection\ntask involves finding all the nodes in NG(vi)ofviinG. Given\nthe prompt about G, LLMs are expected to analyze the local\nstructure of the given node viand determine NG(vi), as shown\nin Figure 2 (c).\n4) Edge validation: The edge detection task refers to\nwhether there exists an edge eijoreijbetween viandvi.\nThrough this task, LLMs are expected to accurately identify\nthe connectivity between nodes and understand the localstructure of nodes. Given the prompt about the neighbors of\nvito the LLMs, LLMs will likely indicate whether eijoreij\nexists, as shown in Figure 2 (d).\n5) Path search: We consider two types of paths, including\nthe simple path and the shortest path, as shown in Figure 2\n(e). Given a graph G={V,E}, the simple path task involves\ndetecting whether there exists a path (vi, ..., v j)between a\nsource node viand a target node vjinG.", "mimetype": "text/plain", "start_char_idx": 1373, "end_char_idx": 3615, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "13ab9919-3750-4d34-a1c5-20e16355554a": {"__data__": {"id_": "13ab9919-3750-4d34-a1c5-20e16355554a", "embedding": null, "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "574f9694-51c7-47c9-bd44-b78161bc75c0", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0fa48c1f38fccc7a5b1f689e5a54b7dcf91795a122cf582c34014ac920d037bd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f2bdf622-04df-4aa2-a512-39c9ef57f172", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8dca356684f6ee43b00f68218e581343e63fca5238d8493224a75d8ea3c57d8f", "class_name": "RelatedNodeInfo"}}, "text": "4) Edge validation: The edge detection task refers to\nwhether there exists an edge eijoreijbetween viandvi.\nThrough this task, LLMs are expected to accurately identify\nthe connectivity between nodes and understand the localstructure of nodes. Given the prompt about the neighbors of\nvito the LLMs, LLMs will likely indicate whether eijoreij\nexists, as shown in Figure 2 (d).\n5) Path search: We consider two types of paths, including\nthe simple path and the shortest path, as shown in Figure 2\n(e). Given a graph G={V,E}, the simple path task involves\ndetecting whether there exists a path (vi, ..., v j)between a\nsource node viand a target node vjinG. In other words, it\nis about finding a simple path (vi, ..., v j)between viandvj\nwithout specific requirements. This task evaluates the ability of\nLLMs to traverse a graph and understand its structure. Given\nthe prompt about Gto LLMs, the goal is to return a simple\npath from vitovj.\nGiven a weighted directed acyclic graph G={V,E}with\neach edge e\u2208 E has a non-negative weight w(e), the shortest\npaths task involve finding a path p= (e1, e2, . . . , e n)from a\nsource node to a target node in Gsuch that the sum of the\nweights of edges w(p) =Pn\ni=1w(ei)is minimized. LLMs\ncan evaluate the length of the shortest path and identify the\nqualified paths. This task can be further divided into three\nobjectives: 1. Finding the shortest path between two nodes. 2.\nFinding all the shortest paths for all paired nodes. 3. Finding\nthe average length of all the shortest paths. This task assesses\nwhether the LLM can effectively determine the shortest route\nbetween two specified nodes within the graph.\n6) Attribute retrieval: The attribute retrieval task involves\nretrieving detailed information related to nodes, such as the", "mimetype": "text/plain", "start_char_idx": 2964, "end_char_idx": 4732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "09d097f3-96ed-483d-a67a-7816d9204eb7": {"__data__": {"id_": "09d097f3-96ed-483d-a67a-7816d9204eb7", "embedding": null, "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "95cd9d160fb18177bf9669f7fbedb915fd6f72dd31aad90d0b4e4781aa30b69f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4a036dc9-a064-410e-89b7-6a339245b223", "node_type": "1", "metadata": {}, "hash": "c2ce647a502170a7f6f8332e7116dcd27727e759b91602d274da1187bb181ede", "class_name": "RelatedNodeInfo"}}, "text": "Task Prompts\nGraph Partition In the academic collaboration network dblp, scholar #355233 is involved in [TBR] local community formed by his/her\ncollaborators.\nGraph Searching According to the Freebase knowledge graph, the relation between entity /m/027rn and entity /m/06cx9 is [TBR].\nPattern matching Triangle: find a single triangle containing node X. Or in the given graph, the triangle must be connected by three edges,\nlist the triangle after \u201dAns:\u201d in the format of [0-1-2]. Cliques: find all the cliques with Nnodes in the given graph, list all\nthe cliques after \u201dAns:\u201d in the format of [0-1-2] and separate the answers by a comma. Wedge Centering find a single\nwedge containing node X in the given graph, node X must be the center of this wedge, list the wedge after \u201dAns:\u201d in the\nformat of [0-1-2].\nCycle Check In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. The nodes are numbered\nfrom 0 to 5, and the edges are: (3,4) (3,5) (1,0) (2,5) (2,0) Q: Is there a cycle in this graph?\nTopological Sort In a directed graph with 5 nodes numbered from 0 to 4: node 0 should be visited before node 4, ... Q: Can all the nodes\nbe visited? Give the solution.\nMaximum Flow In a directed graph with 5 nodes numbered from 0 to 4, and the edges are: an edge from node 0 to node 1 with capacity\n10... Q: What is the maximum flow from node 0 to node 3?\nBipartite Graph Matching There are 2 job applicants numbered from 0 to 1, and 3 jobs numbered from 0 to 2. Each applicant is interested in some\nof the jobs. Each job can only accept one applicant and a job applicant can be appointed for only one job. Applicant 0 is\ninterested in job 1, ... Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find\nthe job they are interested in.\nHamilton Path Given [graph], is there a path in this graph that visits every node exactly once? If yes, give the path. Note that in a path,\nadjacent nodes must be connected with edges.\nGraph Neural Networks Given [graph]. Embeddings: node 0: [1,1], ... In a simple graph convolution layer, each node\u2019s embedding is updated by\nthe sum of its neighbors\u2019 embeddings.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2175, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a036dc9-a064-410e-89b7-6a339245b223": {"__data__": {"id_": "4a036dc9-a064-410e-89b7-6a339245b223", "embedding": null, "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "95cd9d160fb18177bf9669f7fbedb915fd6f72dd31aad90d0b4e4781aa30b69f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "09d097f3-96ed-483d-a67a-7816d9204eb7", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "687edfc0fbdb226a5fc26d983c9cfaa5059fe018d8dd4472848c073c6059942b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3fbeeb20-c298-4836-ad21-9af69c034820", "node_type": "1", "metadata": {}, "hash": "877f41c1ad600f7b5ad6ab5328d2b96a1adb136eaf8370681ac45757087ade6b", "class_name": "RelatedNodeInfo"}}, "text": "Bipartite Graph Matching There are 2 job applicants numbered from 0 to 1, and 3 jobs numbered from 0 to 2. Each applicant is interested in some\nof the jobs. Each job can only accept one applicant and a job applicant can be appointed for only one job. Applicant 0 is\ninterested in job 1, ... Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find\nthe job they are interested in.\nHamilton Path Given [graph], is there a path in this graph that visits every node exactly once? If yes, give the path. Note that in a path,\nadjacent nodes must be connected with edges.\nGraph Neural Networks Given [graph]. Embeddings: node 0: [1,1], ... In a simple graph convolution layer, each node\u2019s embedding is updated by\nthe sum of its neighbors\u2019 embeddings. Q: What\u2019s the embedding of each node after one layer of simple graph convolution\nlayer?\nDynamic Graph In an undirected dynamic graph, (u, v, t) means that node u and node v are linked with an undirected edge at time t. Your\ntask is to answer when two nodes are first connected in the dynamic graph. Two nodes are connected if there exists a\npath between them. Given an undirected dynamic graph with the edges [(0, 1, 0), (1, 2, 1), (0, 2, 2)]. When are node 0\nand node 2 first connected?\nTABLE II: Prompts for Graph Structure Understanding Tasks, where [graph] is the input of the data. [TBR] means to be\nreasoned by LLMs.\nattributes of a node. For example, in a citation network, LLMs\nare tasked with retrieving specific attributes of a node, such\nas the title, abstract, or author of a paper. Given the prompt\naboutGand detailed attribute information, LLMs are expected\nto retrieve the required information, as shown in Figure 2 (f).\n7) Graph density: Graph density represents the ratio be-\ntween the number of edges present in a graph and the\nmaximum number of edges that the graph can have. For an\nundirected simple graph G={V,E}, the graph density is\ndefined as:\nD=2|E|\n|V|(|V| \u2212 1)(2)\nFor a directed simple graph, the graph density is defined as:\nD=|E|\n|V|(|V| \u2212 1)(3)\nThis task requires LLM to calculate the density of a given\ngraph and assess its understanding of the entire graph, as\nshown in Figure 2 (g).", "mimetype": "text/plain", "start_char_idx": 1394, "end_char_idx": 3591, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3fbeeb20-c298-4836-ad21-9af69c034820": {"__data__": {"id_": "3fbeeb20-c298-4836-ad21-9af69c034820", "embedding": null, "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "95cd9d160fb18177bf9669f7fbedb915fd6f72dd31aad90d0b4e4781aa30b69f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a036dc9-a064-410e-89b7-6a339245b223", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "36924922ec09194738c63f4e8929c46b30dcb9efba03a46fec01c1dcf9b11fee", "class_name": "RelatedNodeInfo"}}, "text": "Given the prompt\naboutGand detailed attribute information, LLMs are expected\nto retrieve the required information, as shown in Figure 2 (f).\n7) Graph density: Graph density represents the ratio be-\ntween the number of edges present in a graph and the\nmaximum number of edges that the graph can have. For an\nundirected simple graph G={V,E}, the graph density is\ndefined as:\nD=2|E|\n|V|(|V| \u2212 1)(2)\nFor a directed simple graph, the graph density is defined as:\nD=|E|\n|V|(|V| \u2212 1)(3)\nThis task requires LLM to calculate the density of a given\ngraph and assess its understanding of the entire graph, as\nshown in Figure 2 (g).\n8) Eccentricity: The eccentricity of a node in a graph is\ndefined as the length of the longest shortest path starting at that\nnode. The eccentricity of one node: this task requires LLMsto answer the eccentricity of a given node. The eccentricity of\nmany nodes: this task requires LLMs to answer the eccentricity\nof a subset of nodes or all the nodes in the graph, as shown\nin Figure 2 (h).\n9) Graph radius: Based on the eccentricity of nodes, the\nradius of a graph is the minimum eccentricity of any vertex in\nthe graph. LLMs can calculate the radius of the given graph\nwith the description of the graph.\n10) Graph center: The center of a graph is the set of\nvertices of graph eccentricity equal to the graph radius. Based\non the eccentricity task and graph radius task, LLMs should be\ngiven the graph information and asked to calculate the graph\ncenter.\n11) Graph diameter: Based on the shortest path, the diam-\neter of a graph is the length of the shortest path between the\nmost distant nodes. LLMs can calculate the graph\u2019s diameter\nwith the given graph information, as shown in Figure 2 (i).\n12) Graph periphery: Based on the graph eccentricities and\ngraph diameter, the graph periphery is a set of vertices that\nhave graph eccentricities equal to the graph diameter. LLMs\ncan answer questions related to the graph periphery using the\ngiven graph information.", "mimetype": "text/plain", "start_char_idx": 2971, "end_char_idx": 4955, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9910a34a-1acf-41cb-81d1-6b52b1132055": {"__data__": {"id_": "9910a34a-1acf-41cb-81d1-6b52b1132055", "embedding": null, "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e642579e-94d1-4167-bd49-35a00b42755f", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "047205b82dcb4d3135857d4c6e2296e69bcf4d9449035388c10cf96e8b7dc7f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3e6e083a-4c82-4144-998f-04eb09eb2845", "node_type": "1", "metadata": {}, "hash": "2afe2ebbf8d83159738fdb62a5b7c360b1379e9a207d5b96cb325865d7b6b174", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 3: Examples for Path Task with GPT3.5 - Graph Structure\nUnderstanding Tasks.\nFig. 4: Examples for Maximum Flow Task with GPT3.5 -\nGraph Structure Understanding Tasks.\nFig. 5: Examples for Bipartite Graph Matching Task with\nGPT3.5 - Graph Structure Understanding Tasks.13) Clustering coefficient computing: The clustering coef-\nficient is a measure of how connected a vertex\u2019s neighbors are\nto one another. We define the edges among neighbors of vi\nas{ejk:vj, vk\u2208 NG(vi), ejk\u2208 E} . For directed graphs, the\nclustering coefficient is defined as:\nCi=|{ejk:vj, vk\u2208 NG(vi), ejk\u2208 E}|\n|NG(vi)||NG(vi)\u22121|(4)\nFor undirected graphs, the clustering coefficient is defined as:\nCi=2|{ejk:vj, vk\u2208 NG(vi), ejk\u2208 E}|\n|NG(vi)||NG(vi)\u22121|(5)\nLLMs can calculate the clustering coefficient as a measure of\nthe degree to which nodes in a graph tend to cluster together.\n14) Graph partition: This task is an online social network\nreasoning task, which is to infer the community structure of\nan online social network by partitioning users into different\nclusters based on their interaction information. Each cluster\nrepresents a social community formed by users who interact\nwith each other frequently. LLMs partition the users of the\nsocial network based on user social interaction patterns and\ngenerate the resulting cluster assignments.\n15) Graph searching: This task is a knowledge graph\nreasoning task, which involves inferring relationships between\nentities based on their information or inferring connected\nentities based on the information of entities and relationships.\nSpecifically, LLM takes entities or relationships as input\nand searches for relevant entities or relationships to generate\noutput.\n16) Pattern matching: This task is to identify star, wedge,\ntriangle, or clique patterns that contain a target node. The\ntarget node can be defined as the center of the pattern.\nAlternatively, the task can involve identifying whether these\npatterns exist in a given graph and determining the number\nof occurrences. Given a description of the LLM graph, the\ngoal is for LLM to identify different patterns and provide the\ncorresponding answers, as shown in Figure 2 (j).\n17) Cycle validation: This task is to determine whether a\ngraph contains a cycle. Given G={V,E}, a cycle is a non-\nempty trail with a vertex sequence (v1, v2, ..., v n, v1). Given\nthe graph information, LLM is asked to determine whether\nthis graph has a cycle.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e6e083a-4c82-4144-998f-04eb09eb2845": {"__data__": {"id_": "3e6e083a-4c82-4144-998f-04eb09eb2845", "embedding": null, "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e642579e-94d1-4167-bd49-35a00b42755f", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "047205b82dcb4d3135857d4c6e2296e69bcf4d9449035388c10cf96e8b7dc7f9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9910a34a-1acf-41cb-81d1-6b52b1132055", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3f330b601a605fa1aa11b6542f01a7e62d79ea5c6b58104a2650e0671d043702", "class_name": "RelatedNodeInfo"}}, "text": "Specifically, LLM takes entities or relationships as input\nand searches for relevant entities or relationships to generate\noutput.\n16) Pattern matching: This task is to identify star, wedge,\ntriangle, or clique patterns that contain a target node. The\ntarget node can be defined as the center of the pattern.\nAlternatively, the task can involve identifying whether these\npatterns exist in a given graph and determining the number\nof occurrences. Given a description of the LLM graph, the\ngoal is for LLM to identify different patterns and provide the\ncorresponding answers, as shown in Figure 2 (j).\n17) Cycle validation: This task is to determine whether a\ngraph contains a cycle. Given G={V,E}, a cycle is a non-\nempty trail with a vertex sequence (v1, v2, ..., v n, v1). Given\nthe graph information, LLM is asked to determine whether\nthis graph has a cycle.\n18) Topological sorting: Topological sorting of a directed\ngraph G={V,E}refers to a linear ordering of its nodes,\nwhere each node comes before all the nodes it points to,\nfor example, there exists a directed edge eijfrom vitovj,\nvicomes before vjin the ordering. The resulting array of\nnode ordering is called topological ordering. LLM is required\nto generate a valid topological sorting for the given directed\ngraph, and there may be multiple valid solutions, as shown in\nFigure 2 (k).\n19) Maximum flow: Given a capacity constraint, the max-\nimum flow problem involves finding the maximum flow that\ncan be sent through pipes, channels, or other pathways in a\nnetwork. Define a flow as fijfrom vitovjand the capacity\non edge eijascij. Given the capability constraints, fij\u2264cij", "mimetype": "text/plain", "start_char_idx": 1559, "end_char_idx": 3196, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "473267cb-b912-4ce8-96fc-9275f8ca408c": {"__data__": {"id_": "473267cb-b912-4ce8-96fc-9275f8ca408c", "embedding": null, "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "52e14c2ca78b8a08a67af8c7c52da9bf9e23008bfe64d9c6ec6ee1aa0602acf4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1365f001-2798-45be-9a09-b2ce3e137ad5", "node_type": "1", "metadata": {}, "hash": "97d6f5245c723ac87caea91a1f6a760133f0f47b1cb890bc1c9469f9052d0490", "class_name": "RelatedNodeInfo"}}, "text": "Manual promptSelf-promptingAPI call prompts\u2026\u2026\u2026\u2026\u2026\u2026Frozen LLMManual prompt: Given <graph>, what is the number of nodes and edges in this graph? Please answer with the number of nodes: X, number of edges: X. \u2026\u2026\u2026\u2026\u2026\u2026Frozen LLMInstructor: You are a brilliant graph master that can handle anything related to graphs like retrieval, detection and classification.Graph description language: GML, GraphML, etc. Query: What is the clustering coefficient of node X?New contexts: Text description of input graph generated by LLM itself.Final output: The clustering coefficient of node X is \u2026\u2026\u2026\u2026\u2026\u2026\u2026Trainable LLMRegular prompt: What is the diameter of the binomial tree?API call prompt: The diameter of the binomial tree is Cerulean [GR(GL(\u201cgpr\u201d, \u201cbinomial_tree\u201d), \u201ctoolx:diameter\u201d) \u2192r]Fig. 6: Promoting methods in graph structure understanding tasks. There are three categories: manual prompts, self-prompting,\nand API call prompts.\nfor all eij. Meanwhile,P\nfij>0fij=P\nfji>0fjifor\u2200viexcept for\nthe source and the target {s, t}Given a network graph, LLM\ngenerates a path that maximizes the flow from the source to\nthe sink, as shown in Figure 2 (l).\n20) Bipartite graph matching: A bipartite graph is a type\nof graph where the nodes can be divided into two disjoint sets,\nUandV, such that there are no adjacent nodes within each set.\nA matching in a bipartite graph is a set of edges where no two\nedges share an endpoint. In a maximum matching, if any edge\nis added, it is no longer a matching. For a given bipartite graph,\nthere can be multiple maximum matchings. LLM can generate\na solution that finds the maximum matching, as shown in\nFigure 2 (m).\n21) Hamilton Path: In an undirected graph, a Hamiltonian\npath is a path in the graph that visits each vertex exactly once.\nGiven an undirected graph, the task is for LLM to find a valid\nHamiltonian path, as shown in Figure 2 (n).\nB. Graph Structure Understanding Methods\nThe rise of LLMs has sparked researchers\u2019 interest in\nexploring their powerful text processing and generalization\ncapabilities for graph reasoning. Therefore, existing efforts\nhave introduced various benchmarks to test LLMs\u2019 graph\nreasoning potential, aiming to explore their capacity to address\ngraph-related problems. Prompting methods have emerged as\nthe primary approach to assess LLMs\u2019 understanding of graph\nstructures, with some studies also focusing on fine-tuning\nLLMs to enhance their graph reasoning abilities.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2429, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1365f001-2798-45be-9a09-b2ce3e137ad5": {"__data__": {"id_": "1365f001-2798-45be-9a09-b2ce3e137ad5", "embedding": null, "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "52e14c2ca78b8a08a67af8c7c52da9bf9e23008bfe64d9c6ec6ee1aa0602acf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "473267cb-b912-4ce8-96fc-9275f8ca408c", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "779d694185f1a2160a6ee8c88713818a569cb3761439174f031f30ae0569e80e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d715779d-3df4-409e-adea-c4aa1b274b71", "node_type": "1", "metadata": {}, "hash": "a3258e967c12da43d20780f22f91304919850500091b0b524cef7b1db5d79d5d", "class_name": "RelatedNodeInfo"}}, "text": "LLM can generate\na solution that finds the maximum matching, as shown in\nFigure 2 (m).\n21) Hamilton Path: In an undirected graph, a Hamiltonian\npath is a path in the graph that visits each vertex exactly once.\nGiven an undirected graph, the task is for LLM to find a valid\nHamiltonian path, as shown in Figure 2 (n).\nB. Graph Structure Understanding Methods\nThe rise of LLMs has sparked researchers\u2019 interest in\nexploring their powerful text processing and generalization\ncapabilities for graph reasoning. Therefore, existing efforts\nhave introduced various benchmarks to test LLMs\u2019 graph\nreasoning potential, aiming to explore their capacity to address\ngraph-related problems. Prompting methods have emerged as\nthe primary approach to assess LLMs\u2019 understanding of graph\nstructures, with some studies also focusing on fine-tuning\nLLMs to enhance their graph reasoning abilities. Thus, the\nfollowing two main methods are introduced: prompting method\nandfine-tuning LLMs .\n1)Prompting method :The prompting method [55] can\nbe categorized into three main types: manual prompt, self-\nprompting, and API call prompt, as shown in Figure 6.\nMost studies utilize manual prompts, where carefully crafted\nprompts guide LLMs to comprehend graph structures better\nand understand the objectives of graph tasks, thereby leading\nto improved performance on graph-related tasks.\nManual prompts. NLGraph [27] introduces a benchmark\naiming to assess the understanding capabilities of LLMs in\nprocessing textual descriptions of graphs and translating theminto conceptual spaces. This benchmark covers various graph\nreasoning tasks like connectivity, shortest path, maximum flow,\nand graph neural network construction, with three difficulty\nlevels (easy, medium, hard) based on graph size and density.\nMeanwhile, the number of nodes n=|V|and the probability\npcontrol edge generation, allowing manipulation of graph size\nand density for a more reliable evaluation of LLM potential\nin graph comprehension.\nNext, to guide LLMs in solving these graph tasks, two\nprompt methods are proposed by NLGraph [27]: build-a-graph\nprompting and algorithmic prompting.\nPrompt III-1: Build-a-Graph Prompting. Build-a-Graph\nprompting method is to guide LLMs to conceptual grounding\nby adding one sentence shown as red words below:\nPrompt III-1: Build-a-Graph Prompting\nGiven <graph description >.Let\u2019s construct a graph\nwith the nodes and edges first. Q: What is the degree\nof node 4?\nPrompt III-2: Algorithmic Prompting.", "mimetype": "text/plain", "start_char_idx": 1550, "end_char_idx": 4034, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d715779d-3df4-409e-adea-c4aa1b274b71": {"__data__": {"id_": "d715779d-3df4-409e-adea-c4aa1b274b71", "embedding": null, "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "52e14c2ca78b8a08a67af8c7c52da9bf9e23008bfe64d9c6ec6ee1aa0602acf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1365f001-2798-45be-9a09-b2ce3e137ad5", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "eacb6d022ed2f4e184d65d6dea6384e09ef5c66f1d4ce27558000447f4619802", "class_name": "RelatedNodeInfo"}}, "text": "Meanwhile, the number of nodes n=|V|and the probability\npcontrol edge generation, allowing manipulation of graph size\nand density for a more reliable evaluation of LLM potential\nin graph comprehension.\nNext, to guide LLMs in solving these graph tasks, two\nprompt methods are proposed by NLGraph [27]: build-a-graph\nprompting and algorithmic prompting.\nPrompt III-1: Build-a-Graph Prompting. Build-a-Graph\nprompting method is to guide LLMs to conceptual grounding\nby adding one sentence shown as red words below:\nPrompt III-1: Build-a-Graph Prompting\nGiven <graph description >.Let\u2019s construct a graph\nwith the nodes and edges first. Q: What is the degree\nof node 4?\nPrompt III-2: Algorithmic Prompting. The algorithmic\nprompting method is designed to guide LLMs to engage in\nalgorithmic reflection and thinking by adding the details of\nthe algorithm shown as red words below:\nPrompt III-2: Algorithmic Prompting\nWe can use a Depth-First Search (DFS) algorithm to\nfind the shortest path between two given nodes in an\nundirected graph.\nThe basic idea is to start at one of the nodes and use\nDFS to explore all of its adjacent nodes. At each\nnode, you can keep track of the distance it takes to\nreach that node from the starting node.\nOnce you have explored all the adjacent nodes, you\ncan backtrack and pick the node which has the\nshortest distance to reach the destination node.\nGiven <graph description >. Q: Give the shortest path", "mimetype": "text/plain", "start_char_idx": 3332, "end_char_idx": 4763, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ac154c45-0153-4bd7-a193-7a585b69b8f8": {"__data__": {"id_": "ac154c45-0153-4bd7-a193-7a585b69b8f8", "embedding": null, "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73b1775f-5c5d-4d04-9781-24eeffc77174", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f3e9455642d4acf9cb3838d1db07e4030857aeb6a21adaf56dd0bc82273dc280", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16f45661-8e39-47b5-b369-5dcde8079e86", "node_type": "1", "metadata": {}, "hash": "fe1b70de02fd99fa048b58ca2d0cae2e5d698c47b264945dcfeaf00fe5497e7a", "class_name": "RelatedNodeInfo"}}, "text": "from node 0 to node 4.\nCompared with other advanced prompts and in-context\nlearning techniques, the two proposed prompts perform better\non graph tasks. Based on the experiments, LLMs indeed pos-\nsess preliminary graph reasoning abilities. Also, the benefits\nof advanced prompting and in-context learning diminish in\ncomplex graph problems and may even have a negative impact.\nLLMs are also susceptible to false correlations, performing\npoorly on graph structures such as chains and cliques.\nTo explore whether LLMs can truly comprehend graph\nstructures and reason on graphs, meanwhile, enhance the\nperformance of LLM-GQP tasks, [26] and [24] test LLMs\nalso using manual prompts, where [26] explores the conditions\nunder which LLMs can benefit from the inherent structural\ninformation in the data and examines two potential factors in-\nfluencing LLM\u2019s performance: data leakage and homogeneity.\nIn summary, the conclusions are as follows:\n\u2022No evidence suggests that LLM\u2019s performance is signif-\nicantly attributed to data leakage.\n\u2022The performance of LLMs on target nodes is positively\ncorrelated with the local homogeneity of the nodes.\n[24] investigates the graph reasoning capabilities of LLMs\nand introduces new evaluation metrics\u2014comprehension, cor-\nrectness, fidelity, and rectification\u2014to assess LLMs\u2019 pro-\nficiency in understanding graph structures and performing\nreasoning tasks. The findings reveal that LLMs can effectively\nunderstand graph structures and perform reasoning tasks.\nHowever, LLMs still face challenges in structural reasoning,\nparticularly in multi-answer tasks where GPT models demon-\nstrate errors and overconfidence. In contrast, GPT-4 displays\nimproved self-correction abilities.\nBeyond static graphs, LLMs\u2019 ability to understand dynamic\ngraph structures is also assessed. Dynamic graphs change\nover time, capturing temporal network evolution patterns.\nLLM4DyG [25] introduces the LLM4DyG benchmark, which\nuses prompting methods to evaluate LLMs\u2019 spatio-temporal\nunderstanding capabilities on dynamic graphs.\nPrompt III-3: DST2. The newly proposed Disentangled\nSpatial-Temporal Thoughts (DST2) prompting technique en-\nhances LLMs\u2019 spatial and temporal understanding of dynamic\ngraphs. DST2 is shown below:\nPrompt III-3: DST2\nDyG Instruction: In an undirected dynamic graph, (u,\nv, t) means that node u and node v are linked with an\nundirected edge at time t.\nTask Instruction: Your task is to answer when two\nnodes are first connected in the dynamic graph. Two\nnodes are connected if there exists a path between them.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "16f45661-8e39-47b5-b369-5dcde8079e86": {"__data__": {"id_": "16f45661-8e39-47b5-b369-5dcde8079e86", "embedding": null, "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73b1775f-5c5d-4d04-9781-24eeffc77174", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f3e9455642d4acf9cb3838d1db07e4030857aeb6a21adaf56dd0bc82273dc280", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ac154c45-0153-4bd7-a193-7a585b69b8f8", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "587325470fc2f33135acae1b73c1f081de9414f8d31329ef9485755539ca78e2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "662f975b-3b80-44ef-a9e2-6b27ab361ad3", "node_type": "1", "metadata": {}, "hash": "866858924a2253fc84835f733b3f03dc21438520af6551c1f6233f9da01d67e4", "class_name": "RelatedNodeInfo"}}, "text": "Dynamic graphs change\nover time, capturing temporal network evolution patterns.\nLLM4DyG [25] introduces the LLM4DyG benchmark, which\nuses prompting methods to evaluate LLMs\u2019 spatio-temporal\nunderstanding capabilities on dynamic graphs.\nPrompt III-3: DST2. The newly proposed Disentangled\nSpatial-Temporal Thoughts (DST2) prompting technique en-\nhances LLMs\u2019 spatial and temporal understanding of dynamic\ngraphs. DST2 is shown below:\nPrompt III-3: DST2\nDyG Instruction: In an undirected dynamic graph, (u,\nv, t) means that node u and node v are linked with an\nundirected edge at time t.\nTask Instruction: Your task is to answer when two\nnodes are first connected in the dynamic graph. Two\nnodes are connected if there exists a path between them.\nAnswer Instruction: Give the answer as an integer\nnumber at the last of your response after \u2019Answer:\u2019Exemplar: Here is an example: Question: Given an\nundirected dynamic graph with the edges [(0, 1, 0), (1,\n2, 1), (0, 2, 2)]. When are node 0 and node 2 first\nconnected? Answer:1\nQuestion: Question: Given an undirected dynamic\ngraph with the edges [(0, 9, 0), (1, 9, 0), (2, 5, 0), (1, 2,\n1), (2, 6, 1), (3, 7, 1), (4, 5, 2), (4, 7, 2), (7, 8, 2), (0, 1,\n3), (1, 6, 3), (5, 6, 3), (0, 4, 4), (3, 4, 4), (3, 6, 4), (4, 6,\n4), (4, 9, 4), (6, 7, 4)]. When are node 2 and node 1\nfirst connected?\nResults show that LLMs have preliminary spatio-temporal\nunderstanding capabilities on dynamic graphs. Dynamic graph\ntasks become increasingly challenging with larger graph sizes\nand densities while insensitive to periods and data generation\nmechanisms.\nWe provide manual prompt examples for various graph\nstructure understanding tasks in Table I and Table II. Addi-\ntionally, we test LLMs with GPT 3.5 for path, max flow, and\nbipartite graph matching using manual prompts, as shown in\nFigure 3, Figure 4 and Figure 5 respectively.\nFor self-prompting.", "mimetype": "text/plain", "start_char_idx": 1802, "end_char_idx": 3688, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "662f975b-3b80-44ef-a9e2-6b27ab361ad3": {"__data__": {"id_": "662f975b-3b80-44ef-a9e2-6b27ab361ad3", "embedding": null, "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73b1775f-5c5d-4d04-9781-24eeffc77174", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f3e9455642d4acf9cb3838d1db07e4030857aeb6a21adaf56dd0bc82273dc280", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16f45661-8e39-47b5-b369-5dcde8079e86", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "98eed3a692f36616d6019e9796b583e8e296f9802e0ecc7fd1e9ccbee084ee5e", "class_name": "RelatedNodeInfo"}}, "text": "When are node 2 and node 1\nfirst connected?\nResults show that LLMs have preliminary spatio-temporal\nunderstanding capabilities on dynamic graphs. Dynamic graph\ntasks become increasingly challenging with larger graph sizes\nand densities while insensitive to periods and data generation\nmechanisms.\nWe provide manual prompt examples for various graph\nstructure understanding tasks in Table I and Table II. Addi-\ntionally, we test LLMs with GPT 3.5 for path, max flow, and\nbipartite graph matching using manual prompts, as shown in\nFigure 3, Figure 4 and Figure 5 respectively.\nFor self-prompting. Self-prompting refers to the process\nwhere an LLM continuously updates the initial prompt to make\nit easier for LLMs to understand and more beneficial for solv-\ning tasks. In other words, the LLM designs prompts based on\nthe original prompt. GPT4Graph [23] utilizes self-prompting\nby continuously updating the prompt with descriptions related\nto the graph. Specifically, first, the graph data is converted into\ngraph description languages, as shown in Section II-D. Then,\ntogether with queries, it is inputted into the prompt handler to\ncreate a prompt, which is then inputted into the LLM. Based\non the output of the LLM, the prompt is updated and re-\ninput into the LLM, repeating multiple rounds of updates to\nobtain an optimized graph description context, such as context\nsummarization and format explanation. This process can be\nseen as the LLM\u2019s self-updating prompt procedure. Finally,\nthe optimized graph description context is input along with\nthe original input into the LLM to obtain the final result.\nPrompt III-4: Self-prompting. The input original prompt is\nshown below:\nPrompt III-4: Self-prompting\nInstructor: You are a brilliant graph master that can\nhandle anything related to graphs like retrieval, detection\nand classification.\nGraph description language: GML, GraphML as\nshown in Section II-D.\nContext: Node P357 has 4 neighbors, where each of\nwhich are about anomaly detection with statistical\nmodels...\nQuery: What is the clustering coefficient of node P357?\nThis paper conducts experiments on the obgn-arxiv [56] and", "mimetype": "text/plain", "start_char_idx": 3094, "end_char_idx": 5229, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ef098096-5368-453c-8f3c-a65e61b8d0da": {"__data__": {"id_": "ef098096-5368-453c-8f3c-a65e61b8d0da", "embedding": null, "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68dff32f-927c-4c17-855c-9a312571a7a6", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "da3ecfb46fbbfc1418e168798e35b1f787e106a7326f8f763fa8f86a7631cb6e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e23b7d11-8522-45fa-b836-b617cb14a48c", "node_type": "1", "metadata": {}, "hash": "26f768b2b89768489103b7a82a0b268824801df2fe293414205da41e278e27b4", "class_name": "RelatedNodeInfo"}}, "text": "Aminer [57] datasets and finds that:\n\u2022The design of prompts significantly impacts the results.\nThe choice of graph description language, the orga-\nnization of input data, and the position of in-context\nknowledge, such as questions, statements, and examples,\nall affect the model\u2019s ability to understand the graph\nstructure.\n\u2022Role prompting techniques can improve the effectiveness\nof LLMs by guiding the model to view the graph as\nroles and relationships between roles in a specific context.\nProviding LLMs with more semantic information leads to\nmore accurate results.\n\u2022Examples in prompts have mixed impacts on graph\nstructure understanding. Adding examples in prompts to\nguide LLMs in understanding graph structures may not\nnecessarily improve the results; in some graph structure\nlearning tasks, examples may introduce noise.\nAPI call prompts LLMs exhibit limited ability to perform\nprecise mathematical calculations, multi-step logical reason-\ning, spatial topological structuring, and temporal information\nprocessing. To bridge these gaps, taking inspiration from\nrecent models such as ChatGPT and Toolformer [58], Graph-\nToolFormer [59] is proposed to equip LLMs with graph\nreasoning capabilities by training them over a prompt dataset\nthat contains graph reasoning API annotated by ChatGPT.\nThese graph reasoning APIs are used to call external reasoning\ntools. Then, the trained LLMs can solve graph tasks, from\nloading graph data and inferring graph attributes to graph\npartition tasks.\nThe framework consists of three parts. First, it generates a\nprompt dataset by providing ChatGPT with a regular prompt,\nguiding ChatGPT to add an API call to the original prompt,\nand then creating a prompt with an API call.\nPrompt III-5: API call prompts\nPrompt III-5: API call prompts\nExample 1\nInput:(Regular prompt)\nThe structure of the benzene ring molecular graph of\nbenzene ring contains a hexagon.\nOutput:(API call prompt)\nThe structure of the [GL(\u201dbenzenering\u201d)] molecular\ngraph of benzene ring contains a hexagon.\nExample 2\nInput:(Regular prompt)\nWhat is the diameter of the binomial tree?\nOutput:(API call prompt)\nThe diameter of the binomial tree is [GR(GL(\u201dgpr\u201d,\n\u201dbinomial tree\u201d), \u201dtoolx:diameter\u201d) \u2192r].\nSecond, fine-tune existing LLMs such as GPT-J [60] [61],\nLLaMA [5] [62], etc., using technologies like LoRA [63]\non the generated prompt dataset.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2357, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e23b7d11-8522-45fa-b836-b617cb14a48c": {"__data__": {"id_": "e23b7d11-8522-45fa-b836-b617cb14a48c", "embedding": null, "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68dff32f-927c-4c17-855c-9a312571a7a6", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "da3ecfb46fbbfc1418e168798e35b1f787e106a7326f8f763fa8f86a7631cb6e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ef098096-5368-453c-8f3c-a65e61b8d0da", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "aad8f5f8fa751db1642576873ce36e42c1b731ab7648d2485e81da201a2417df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22e35448-1073-4be6-ba5b-8a8fa5b71cbb", "node_type": "1", "metadata": {}, "hash": "24fbd967159fa3d9f33d649071d49c57a6f48753a5c0a625fd8709dabe256ebd", "class_name": "RelatedNodeInfo"}}, "text": "Prompt III-5: API call prompts\nPrompt III-5: API call prompts\nExample 1\nInput:(Regular prompt)\nThe structure of the benzene ring molecular graph of\nbenzene ring contains a hexagon.\nOutput:(API call prompt)\nThe structure of the [GL(\u201dbenzenering\u201d)] molecular\ngraph of benzene ring contains a hexagon.\nExample 2\nInput:(Regular prompt)\nWhat is the diameter of the binomial tree?\nOutput:(API call prompt)\nThe diameter of the binomial tree is [GR(GL(\u201dgpr\u201d,\n\u201dbinomial tree\u201d), \u201dtoolx:diameter\u201d) \u2192r].\nSecond, fine-tune existing LLMs such as GPT-J [60] [61],\nLLaMA [5] [62], etc., using technologies like LoRA [63]\non the generated prompt dataset. Thirdly, utilize the fine-\ntuned LLM for inference to add graph reasoning API calls\n\u2026\u2026\u2026\u2026\u2026\u2026Instructions: How many C-C-O triangles are in the molecule?Graph-enhanced prefix:Structural and textual featuresLLMResponse: There is 1 C-C-O triangle in the molecule.Fig. 7: Supervised fine-tuning (SFT) method in graph structure\nunderstanding tasks. Prefix tuning is shown above: combine\ngraph structural and textual information as prefixes in prefix\ntuning and input it into LLM with instructions, like GraphLLM\n[64]. Instruction tuning can also be used.\ninto statements. After generating API call statements, how\ncan external graph tools be invoked? Graph reasoning query\nprocessing comes in. Graph reasoning query processing entails\nutilizing external graph reasoning tools based on API call\nstatements to obtain the final answer.\n2)Supervised fine-tuning (SFT) method :Beyond lever-\naging prompts for graph-structured tasks with LLMs, cer-\ntain studies have also implemented supervised fine-tuning of\nLLMs, illustrated in Figure 7. GraphLLM [64] is committed\nto addressing the obstacles in graph reasoning by LLMs and\nintroduces a hybrid model that inherits the capabilities of both\ngraph learning models and LLMs, enabling LLMs to interpret\nand reason about graph data proficiently, utilizing the superior\nexpressive power of graph learning models.\nC. Comparisons and Discussions\nIn the following part, we compare the prompting and SFT\nmethods mentioned above.\nThe prompting method can be divided into three cate-\ngories: manual prompts, self-prompting, and API call prompts.\nMost current methods primarily rely on manual prompts,\nincorporating techniques like Chain of Thought (CoT) [65],\nself-consistency [66], and in-context learning [67]. To obtain\nbetter prompt representations, self-prompting methods are also\nwidely used.", "mimetype": "text/plain", "start_char_idx": 1720, "end_char_idx": 4182, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "22e35448-1073-4be6-ba5b-8a8fa5b71cbb": {"__data__": {"id_": "22e35448-1073-4be6-ba5b-8a8fa5b71cbb", "embedding": null, "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68dff32f-927c-4c17-855c-9a312571a7a6", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "da3ecfb46fbbfc1418e168798e35b1f787e106a7326f8f763fa8f86a7631cb6e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e23b7d11-8522-45fa-b836-b617cb14a48c", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2ab5f37cdbab317bebede7d3fd7d8bf30ba1d5bea294f35f0eb8ea4c0f2233f1", "class_name": "RelatedNodeInfo"}}, "text": "GraphLLM [64] is committed\nto addressing the obstacles in graph reasoning by LLMs and\nintroduces a hybrid model that inherits the capabilities of both\ngraph learning models and LLMs, enabling LLMs to interpret\nand reason about graph data proficiently, utilizing the superior\nexpressive power of graph learning models.\nC. Comparisons and Discussions\nIn the following part, we compare the prompting and SFT\nmethods mentioned above.\nThe prompting method can be divided into three cate-\ngories: manual prompts, self-prompting, and API call prompts.\nMost current methods primarily rely on manual prompts,\nincorporating techniques like Chain of Thought (CoT) [65],\nself-consistency [66], and in-context learning [67]. To obtain\nbetter prompt representations, self-prompting methods are also\nwidely used. However, the exclusive use of manual prompts\nand self-prompting offers limited enhancement to model per-\nformance, as they merely tap into the pre-existing capabilities\nof LLMs. Additionally, due to the limited input window of\nLLM, the graph size that can be input to LLM at once is also\nrestricted, while graph sizes in the real world are typically\nlarge.\nFor the prompting method, we also propose two feasible\ndirections to better leverage existing LLMs for handling struc-\nture understanding tasks. The first direction is breaking down\ncomplex tasks into several sub-problems. While LLMs can\ntackle simple graph tasks, they struggle with more challenging\nones. Breaking down complex graph understanding tasks into\nsimpler components enables LLMs to engage in multi-step\nreasoning processes, leading to the resolution of complex", "mimetype": "text/plain", "start_char_idx": 3385, "end_char_idx": 5013, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fd6be985-59f8-4c74-aa36-87ab035a8ec7": {"__data__": {"id_": "fd6be985-59f8-4c74-aa36-87ab035a8ec7", "embedding": null, "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1cebebbc9dba708e3c6e6a9a6b715e2a1ebdaa9e30926c8a479fc01002c09be6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "658f33cd-d755-4d81-ac05-effd5fb8cee7", "node_type": "1", "metadata": {}, "hash": "750c132fe44b7234417f2f933ac3a8a4ca2cce5256a3ca95a4173e821df0f619", "class_name": "RelatedNodeInfo"}}, "text": "Graph Learning Tasks\nUSKGQA\nGiven <knowledge graph>, the director who directs Inception also direct what?InceptionNolanOppenheimerLeonardois starred byGQL Generation\nGiven <graph>, the director who directs Inception also direct what? Use Cypher to answer.14320Node ClassificationGiven <graph>, which arxiv CS subcategory does paper \u201dpaper title\u201d with abstract \u201dpaper abstract\u201d belongs to? use the abbreviation to answer.Abstract: Text in curve orientation, despite being one of the common\u2026Title: Total Text A Comprehensive Dataset For Scene Text Detection And Recognition.CCCCCOHCGiven <graph>, is this molecule active with H3C4?Graph Classification\n14320Node Feature ExplanationGiven <graph>, which arXiv CS sub-category does this paper belong to? Give 5 likely arXiv CS subcategories as a comma-separated list ordered from most to least likely, in the form \u201dcs.XX\u201d, and provide your reasoning. Abstract: Text in curve orientation, despite being one of the common\u2026Title: Total Text A Comprehensive Dataset For Scene Text Detection And Recognition.14320Edge ClassificationLearnable prompt\nUSInceptionNolanOppenheimerLeonardois starred by(a) (b) (c) \n(d) (e) (f) Fig. 8: Graph Learning tasks.\nissues, such as GoT [59], which can help address more\nintricate graph tasks like generating GNN frameworks, k-truss\ntasks, kd-core tasks, etc. The second direction is API call\nprompts. Inspired by ToolFormer [58], LLMs can be trained\nas agents to utilize tools for graph tasks that are hard to\nsolve. However, current API call prompt methods [59] utilize\nLLMs not as agents but solely to convert user queries into\nAPI command strings for processing by subsequent programs,\nexemplified in Prompt III-5 .\nHowever, compared to prompting methods, fine-tuning\nLLMs with graph data seems a better way to enhance their\nunderstanding of graph structures. There are two mainstream\nmethods for fine-tuning LLMs: Supervised Fine-Tuning (SFT)\nand Reinforcement Learning with Human Feedback (RLHF)\n[6]. SFT helps LLMs understand prompts and generate mean-\ningful responses. However, SFT only offers a single human-\nwritten response for each prompt, whereas RLHF provides\ndetailed human feedback through pairwise comparison label-\ning. Furthermore, to address the instability issue in PPO [68]\ntraining, the Reward Ranked Fine-Tuning (RAFT) [69] can\nalso be attempted which requires online interaction. For offline\nalgorithms, methods like DPO [3] and Preference Ranking\nOptimization (PRO) [70] can also be utilized for training\nLLMs.\nIV.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "658f33cd-d755-4d81-ac05-effd5fb8cee7": {"__data__": {"id_": "658f33cd-d755-4d81-ac05-effd5fb8cee7", "embedding": null, "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1cebebbc9dba708e3c6e6a9a6b715e2a1ebdaa9e30926c8a479fc01002c09be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fd6be985-59f8-4c74-aa36-87ab035a8ec7", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b99c3dff15c992ea8ea8110a7a30614e0b8cc45237365bd6d8387eb93d727a80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7129a5f0-2cff-4e87-be92-466b1e2f738c", "node_type": "1", "metadata": {}, "hash": "308bb3fba5b52c8e37257e7b4f1e1811c9ec70a60d6d8640dd2a7b52a46c1fed", "class_name": "RelatedNodeInfo"}}, "text": "However, compared to prompting methods, fine-tuning\nLLMs with graph data seems a better way to enhance their\nunderstanding of graph structures. There are two mainstream\nmethods for fine-tuning LLMs: Supervised Fine-Tuning (SFT)\nand Reinforcement Learning with Human Feedback (RLHF)\n[6]. SFT helps LLMs understand prompts and generate mean-\ningful responses. However, SFT only offers a single human-\nwritten response for each prompt, whereas RLHF provides\ndetailed human feedback through pairwise comparison label-\ning. Furthermore, to address the instability issue in PPO [68]\ntraining, the Reward Ranked Fine-Tuning (RAFT) [69] can\nalso be attempted which requires online interaction. For offline\nalgorithms, methods like DPO [3] and Preference Ranking\nOptimization (PRO) [70] can also be utilized for training\nLLMs.\nIV. G RAPH LEARNING TASKS\nA. Tasks Introduction\nRecently, LLMs have been shown to possess extensive\ncommon sense and powerful semantic understanding capa-\nbilities, fundamentally transforming the existing workflow\nfor processing text. However, whether LLMs can effectively\nhandle graph learning tasks, transferring their generalization\nability from text tasks to graph learning tasks, such as node\nand graph classification, is still a research subject that needsexploring. These tasks require the model to learn and solve\ngraph learning tasks, as shown in Figure 8. In this section, we\npresent seven graph learning tasks along with their definitions.\nNext, we introduce graph learning methods, categorized into\nthree types based on the role of LLMs: LLMs act as enhancers,\nLLMs act as predictors, and graph prompts.\n1) Node classification: The node classification task requires\nLLM to learn based on the neighbors of a node or the attributes\nof a node. It involves classifying unseen nodes in a given\ngraph, such as categorizing papers in an academic network\ninto different research directions, as shown in Figure 8 (a).\n2) Graph classification: The graph classification task re-\nquires LLM to classify the entire graph. LLM is given several\nlabeled graphs and is expected to classify unseen graphs. For\nexample, a molecule can be viewed as a graph, and LLM\ncan predict the properties or functions of the molecule by\nclassifying the graph, as shown in Figure 8 (b).\n3) Edge classification: The edge classification task involves\nclassifying the edges in a graph. Existing methods improve\nedge classification by training a learnable graph prompt and\ncombining it with a GNN or LLM, as shown in Figure 8 (c).", "mimetype": "text/plain", "start_char_idx": 1695, "end_char_idx": 4218, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7129a5f0-2cff-4e87-be92-466b1e2f738c": {"__data__": {"id_": "7129a5f0-2cff-4e87-be92-466b1e2f738c", "embedding": null, "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1cebebbc9dba708e3c6e6a9a6b715e2a1ebdaa9e30926c8a479fc01002c09be6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "658f33cd-d755-4d81-ac05-effd5fb8cee7", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "d9b4d6628924f5c9aaaaa84e33f23b9fc604bc7ed18340137a05f0ca2055c051", "class_name": "RelatedNodeInfo"}}, "text": "It involves classifying unseen nodes in a given\ngraph, such as categorizing papers in an academic network\ninto different research directions, as shown in Figure 8 (a).\n2) Graph classification: The graph classification task re-\nquires LLM to classify the entire graph. LLM is given several\nlabeled graphs and is expected to classify unseen graphs. For\nexample, a molecule can be viewed as a graph, and LLM\ncan predict the properties or functions of the molecule by\nclassifying the graph, as shown in Figure 8 (b).\n3) Edge classification: The edge classification task involves\nclassifying the edges in a graph. Existing methods improve\nedge classification by training a learnable graph prompt and\ncombining it with a GNN or LLM, as shown in Figure 8 (c).\n4) Node generation: The node generation task refers to pro-\nviding requirements for an LLM to generate nodes, allowing it\nto generate node attributes, which are then added to the TAG\nto enhance it.\n5) Knowledge graph question qnswering (KGQA): Knowl-\nedge graph organizes data into a structured format, represent-\ning entities, properties, and relationships. Knowledge graph\nquestion answering (KGQA) aims to capture the most appro-\npriate answers by querying the knowledge graph (KG) using\nnatural language questions. This task evaluates the ability of\nLLM to reason and understand the underlying graph structure\nto provide accurate answers, as shown in Figure 8 (d).\n6) Graph query language (GQL) generation: The graph\nquery language generation task involves generating graph", "mimetype": "text/plain", "start_char_idx": 3466, "end_char_idx": 4996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c23dcb4-26f5-47cb-9f56-ee9ac2bc66fa": {"__data__": {"id_": "1c23dcb4-26f5-47cb-9f56-ee9ac2bc66fa", "embedding": null, "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "08d53ae4-bf38-4160-96cd-5714cb401e7e", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "93bb83f8e06d3f3897454d75064b5eb5430010e58a102e6ea353439e8fcab743", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c261c705-1f41-4272-9cde-7d78eb378419", "node_type": "1", "metadata": {}, "hash": "9d6a7a878987a9fb015f3466910e14e43ac23b6c80187bd30e8ea8cff7114053", "class_name": "RelatedNodeInfo"}}, "text": "Task Prompts\nKGQA Given [knowledge graph], the director who directs Inception also direct what?\nGQL Generation Given [graph], the director who directs Inception also direct what? Use Cypher to answer.\nNode Classification Which arxiv CS subcategory does paper \u201dpaper title\u201d with abstract \u201dpaper abstract\u201d belongs to? use the abbreviation\nto answer.\nGraph Classification Given [graph]. Is this molecule active with H3C4?\nNode Feature Explanation Abstract: Text in curve orientation, despite being one of the common text orientations in real world environment... Title:\nTotal Text A Comprehensive Dataset For Scene Text Detection And Recognition. Question: Which arXiv CS sub-category\ndoes this paper belong to? Give 5 likely arXiv CS sub-categories as a comma-separated list ordered from most to least\nlikely, in the form \u201dcs.XX\u201d, and provide your reasoning.\nEdge classification learnable prompt\nTABLE III: Prompts for Graph Learning Tasks, where [\u00b7] is the input of the data.\nquery languages, including GQL and Cypher, to perform op-\nerations on graph databases. Evaluating LLM\u2019s ability to gen-\nerate GQL helps users extract information from the database,\nas shown in Figure 8 (e).\n7) Node feature explanation: Node feature explanation task\ninvolves extracting the attributes of nodes in a text attribute\ngraph. For example, in an academic paper network, the node\nattributes may include abstracts, titles, etc. LLM is expected to\nprovide reasoning for the classification process of nodes based\non their text attributes and explain the features of the nodes,\nas shown in Figure 8 (f).\nB. Graph Learning Methods\nLLM-GIL studies focusing on graph learning tasks can be\ncategorized into three main groups: LLMs act as enhancers,\nLLMs act as predictors, and graph prompts. When LLMs act\nas enhancers, they leverage their advanced semantic under-\nstanding of the text, strong reasoning capabilities, and vast\nknowledge repository to enhance the text attributes associated\nwith nodes in the graph to enhance GNNs. When LLMs act\nas predictors, LLMs are queried or fine-tuned to predict task\nresults. Inspired by NLP ideas, the Graph prompt aims to\ncreate a unified framework capable of solving multiple graph\nlearning tasks. Although LLMs are not used, the concept aligns\nwith LLM-based pipelines.\nIn summary, integrating LLMs in graph learning tasks\npresents a promising avenue for advancing the field. By\nleveraging the strengths of LLMs as enhancers and predictors,\nalong with the strategic use of graph prompts, researchers can\nexplore new directions for enhanced performance and more\nprofound insights in LLM-GIL tasks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2616, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c261c705-1f41-4272-9cde-7d78eb378419": {"__data__": {"id_": "c261c705-1f41-4272-9cde-7d78eb378419", "embedding": null, "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "08d53ae4-bf38-4160-96cd-5714cb401e7e", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "93bb83f8e06d3f3897454d75064b5eb5430010e58a102e6ea353439e8fcab743", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c23dcb4-26f5-47cb-9f56-ee9ac2bc66fa", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f160556e1c58a533eaed11d8dfd13b1c81ac38259fbce96839d37db9c952a48e", "class_name": "RelatedNodeInfo"}}, "text": "When LLMs act\nas enhancers, they leverage their advanced semantic under-\nstanding of the text, strong reasoning capabilities, and vast\nknowledge repository to enhance the text attributes associated\nwith nodes in the graph to enhance GNNs. When LLMs act\nas predictors, LLMs are queried or fine-tuned to predict task\nresults. Inspired by NLP ideas, the Graph prompt aims to\ncreate a unified framework capable of solving multiple graph\nlearning tasks. Although LLMs are not used, the concept aligns\nwith LLM-based pipelines.\nIn summary, integrating LLMs in graph learning tasks\npresents a promising avenue for advancing the field. By\nleveraging the strengths of LLMs as enhancers and predictors,\nalong with the strategic use of graph prompts, researchers can\nexplore new directions for enhanced performance and more\nprofound insights in LLM-GIL tasks.\n1)LLMs act as enhancers : LLMs act as enhancers per-\ntains to the LLMs-GNNs pipelines, where LLMs assume an\nenhancer role. Within this framework, LLMs are tasked with\nprocessing text attributes, while GNNs are responsible for\nhandling graph structures, capitalizing on the complementary\nstrengths of both components to address graph learning tasks\neffectively. LLMs bolster GNNs through three distinct mecha-\nnisms: encoding the graph into embeddings (as shown in Fig-\nEncoding graph into embeddings.Generating graph pseudo labels.Providing external knowledge/explanations.\u2026Trainable LLM\u2026\u2026\u2026Frozen LLM\u2026\u2026\u2026Trainable LM\u2026\u2026\nTextEmbeddingsNode Text Attribute\nGraphStructureGNN+Fig. 9: Encoding graph into embeddings, when LLMs act as\nenhancers. Input the node text attribute into LM/LLM to obtain\ntext embeddings, then combine the text embeddings with the\ngraph structure for training and learning in GNNs.\nure 9), generating graph pseudo labels (as shown in Figure 10),\nand providing external knowledge or explanations (as shown\nin Figure 11). Subsequently, we will provide a comprehensive\nelaboration on these three enhancement strategies.\nEncoding graph into embeddings. LLMs possess signif-\nicant semantic comprehension capabilities to encode better\nnode embeddings, as shown in Figure 9. TAPE [30] integrates\nLM with LLM to generate node embeddings. The process\ninvolves fine-tuning two LM models using original node text\nattributes and LLM explanations for node prediction. The", "mimetype": "text/plain", "start_char_idx": 1768, "end_char_idx": 4093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2364dff8-cb51-4d62-bf6b-192430b80a39": {"__data__": {"id_": "2364dff8-cb51-4d62-bf6b-192430b80a39", "embedding": null, "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8dd4767b3761480ba8a095576c1da047e442025f504514742aaa1fdc272dca7a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f09384d9-35d4-4fde-ba8f-ce23f412e0d8", "node_type": "1", "metadata": {}, "hash": "14fc1e394ca0e3b7ac856faaae415b9cb46e2991c3077ad9d98f2529fdeb63a9", "class_name": "RelatedNodeInfo"}}, "text": "Encoding graph into embeddings.Generating graph pseudo labels.Providing external knowledge/explanations.Unlabelednodes\nNodeswithpseudolabelsTrainingGNNAnnotationwithLLMFig. 10: Generating graph pseudo labels, when LLMs act as\nenhancers. Input unlabeled nodes into LLM for labeling, then\nuse the labeled nodes with pseudo-labels as input for training\nthe GNNs for graph learning.\nEncoding graph into embeddings.Generating graph pseudo labels.Providing external knowledge/explanations.Node Text Attribute\nLLMsEnhancedtextattributesNode Text Attribute\nDesignedqueries\nLLMsExplanationforreasoningprocess1.2.\nFig. 11: Providing external knowledge/explanations, when\nLLMs act as enhancers. Two pipelines are shown above. In\nthe first pipeline, input node text attributes into LLM for\nelaboration, enhancing the detail of the text attributes. In the\nsecond pipeline, input node text attributes and designed queries\ninto LLM. LLM leverages the text attributes to answer queries\nand explains the reasoning process.\nresulting embeddings are then used as input to train a GNN\nmodel for node classification tasks. To unify graph data and\ngraph learning tasks, OFA [32] introduces a comprehensive\nframework that unifies diverse graph data by describing nodes\nand edges using natural language and encoding varied and\npotentially cross-domain text attributes into feature vectors\nwithin the same embedding space. The obtained feature vec-\ntors are then fed into a GNN to tackle various downstream\ntasks effectively. Moreover, SIMTEG [71] and GLEM [31]\ninvolve training an LM with Lora and subsequently generating\nembeddings as text representations, then a GNN is trained on\ntop of these text embeddings. On this basis, G-prompt [33]\nintroduces a graph adapter to extract node features, thereby\nobtaining improved node representations.\nGenerating graph pseudo labels. Many existing pipelines\nutilize LLMs to process text attributes as node features, then\nfeed the embeddings produced by LLM into a GNN model forlearning, as shown in Figure 10. However, the simultaneous\ntraining of LLM and GNN poses a significant computational\nchallenge. To bridge this gap, GLEM [31] suggests training\nthe GNN and LM separately in a variational Expectation-\nMaximization (EM) framework. In the E-step, the LM predicts\nboth gold labels and pseudo-labels from the GNN, while in the\nM-step, the GNN predicts gold labels and LM-inferred pseudo\nlabels using the embeddings and pseudo-labels provided by the\nLM.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2474, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f09384d9-35d4-4fde-ba8f-ce23f412e0d8": {"__data__": {"id_": "f09384d9-35d4-4fde-ba8f-ce23f412e0d8", "embedding": null, "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8dd4767b3761480ba8a095576c1da047e442025f504514742aaa1fdc272dca7a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2364dff8-cb51-4d62-bf6b-192430b80a39", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "5f8c98b30669d7953b091bdd337bcca2bf004fe196011a4fafc2d55f041dcdfc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20fd018e-7887-4920-ba4d-751e6f972ec5", "node_type": "1", "metadata": {}, "hash": "c1a88ae056ae063f529fe79ae2d3ab60ee90bbdb353f423bccab4c8a134c6d82", "class_name": "RelatedNodeInfo"}}, "text": "On this basis, G-prompt [33]\nintroduces a graph adapter to extract node features, thereby\nobtaining improved node representations.\nGenerating graph pseudo labels. Many existing pipelines\nutilize LLMs to process text attributes as node features, then\nfeed the embeddings produced by LLM into a GNN model forlearning, as shown in Figure 10. However, the simultaneous\ntraining of LLM and GNN poses a significant computational\nchallenge. To bridge this gap, GLEM [31] suggests training\nthe GNN and LM separately in a variational Expectation-\nMaximization (EM) framework. In the E-step, the LM predicts\nboth gold labels and pseudo-labels from the GNN, while in the\nM-step, the GNN predicts gold labels and LM-inferred pseudo\nlabels using the embeddings and pseudo-labels provided by the\nLM.\nMoreover, due to the high cost of annotation and the\nnecessity for GNN to learn from a substantial amount of\nhigh-quality labeled data to ensure its performance on graph\ntasks, leveraging the zero-shot learning capability of LLM\nbecomes advantageous. Therefore, employing LLM for graph\nannotation can enhance GNN training even with limited la-\nbeled data. LLM-GNN [72] proposes to select a candidate\nnode set to be annotated. Subsequently, LLMs annotate the\ncandidate node set, and post-filtering is conducted to eliminate\nlow-quality annotations. Finally, the GNN is trained using\nthe high-quality annotation set and utilized for prediction.\nLLM-GNN [72] proposes to select a candidate node set for\nannotation by LLMs, followed by post-filtering to remove low-\nquality annotations. Then, GNN is trained using high-quality\nannotations for prediction.\nProviding external knowledge/explanations. LLMs pos-\nsess a vast knowledge base, enabling them to provide external\nknowledge or explanations related to node features when en-\ncoding them, as shown in Figure 11. The additional knowledge\nassists the model in better extracting and capturing node\nfeatures. Graph-LLM [73] utilizes LLMs, such as ChatGPT, to\nexplain text attributes, enhancing them and generating pseudo\nlabels. These enhanced attributes are then fed into a trainable\nLLM, like Llama, to produce node feature embeddings. The\ncombined pseudo labels and embeddings are input into a GNN,\nwhich delivers the final prediction outcomes.\nSimilarly, TAPE [30] leverages LLMs to provide external\nexplanations. In a citation network where each node contains\ntext attributes like title and abstract, the text attribute of each\nnode serves as input to an LLM.", "mimetype": "text/plain", "start_char_idx": 1689, "end_char_idx": 4185, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20fd018e-7887-4920-ba4d-751e6f972ec5": {"__data__": {"id_": "20fd018e-7887-4920-ba4d-751e6f972ec5", "embedding": null, "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8dd4767b3761480ba8a095576c1da047e442025f504514742aaa1fdc272dca7a", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f09384d9-35d4-4fde-ba8f-ce23f412e0d8", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "33d6e628a89aa8da7a18f57e61b013ff91d44d7a15ef958e405d594814837fbd", "class_name": "RelatedNodeInfo"}}, "text": "Providing external knowledge/explanations. LLMs pos-\nsess a vast knowledge base, enabling them to provide external\nknowledge or explanations related to node features when en-\ncoding them, as shown in Figure 11. The additional knowledge\nassists the model in better extracting and capturing node\nfeatures. Graph-LLM [73] utilizes LLMs, such as ChatGPT, to\nexplain text attributes, enhancing them and generating pseudo\nlabels. These enhanced attributes are then fed into a trainable\nLLM, like Llama, to produce node feature embeddings. The\ncombined pseudo labels and embeddings are input into a GNN,\nwhich delivers the final prediction outcomes.\nSimilarly, TAPE [30] leverages LLMs to provide external\nexplanations. In a citation network where each node contains\ntext attributes like title and abstract, the text attribute of each\nnode serves as input to an LLM. The LLM categorizes the\nnodes and generates multiple predictions ranked in a list with\naccompanying reasoning explanations. This approach aims\nto extract the LLM\u2019s reasoning capabilities while integrating\nexternal knowledge to aid in understanding node text attributes\nand extracting node features.\n2)LLMs act as predictors. :When LLMs are predictors,\nthey are usually directly employed as standalone predictors.\nThe critical aspect of integrating LLMs as predictors lies\nin crafting a well-designed prompt that encompasses text\nattributes and graph structures, enabling LLMs to compre-\nhend the graph structure effectively and enhance prediction\naccuracy. Additionally, there are other methodologies to fine-\ntune LLMs, such as utilizing techniques like LoRA [63] and\ninstruction tuning, aiming to deepen the LLM\u2019s understanding\nof the graph structure. Based on whether LLMs undergo\nparameter training, they are categorized into prompting LLMs\nand SFT LLMs, as shown in Figure 12.", "mimetype": "text/plain", "start_char_idx": 3326, "end_char_idx": 5167, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97fbe4a2-1747-4cb6-bc19-1afc1299fba9": {"__data__": {"id_": "97fbe4a2-1747-4cb6-bc19-1afc1299fba9", "embedding": null, "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f085d5e4-0b19-4a6c-a7ae-2a7dc1808050", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "307941d324de3b682f023d3e01c2f78c0f77cf5a0b92652cbb234b104e69c14e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a2d87bd-651a-4cdf-9765-22ee0f97fc4e", "node_type": "1", "metadata": {}, "hash": "4b81db4a210d13e8231911542f63f7f7d8e30f720f7c54e77d7fa41fcc545477", "class_name": "RelatedNodeInfo"}}, "text": "Prompting LLMs\nSupervised fine-tuning (SFT) LLMs.\u2026\u2026\u2026\u2026\u2026\u2026Trainable LLMInstructions: How many C-C-O triangles are in the molecule?Response: There is 1 C-C-O triangle in the molecule.Response: There is no C-C-O triangle in the molecule.Response: There is 4C-C-O triangle in the molecule.Instructiontuning\u2026\u2026\u2026\u2026\u2026\u2026Frozen LLMManualprompt:The title of one paper is <Title>and its abstract is <Abstract>. This paper is cited by the following papers: <Titlelist1>. Each of these papers belongs to one category in: <Categories>.You need to analyze the paper\u2019s topic based on the given title and abstract.Fig. 12: LLMs act as predictors. For prompting LLMs, input\ndesigned manual prompts into LLM, enabling it to predict\nnodes/links/graphs. For SFT LLMs, input instructions into the\nLLM to generate multiple answers. Tuning the LLM is then\nbased on these multiple responses.\nPrompting LLMs. The prompting method can be divided\ninto two categories. One type is the manual prompts, which\nare manually written prompts.\nPrompt IV-1: Manual Prompt Template with Slots. For\ninstance, Beyond Text [74], ENG [75], and Graph Agent\n[76] provide a manual prompt template with slots. By filling\nthese slots with different examples, various prompts can be\nconstructed. For example:\nPrompt IV-1: Manual Prompt Template with Slots\nThe title of one paper is <Title>and its abstract is\n<Abstract >. This paper is cited by the following\npapers: <Titlelist1 >. Each of these papers belongs to\none category in: <Categories >. You need to 1.Analyse\nthe papers\u2019 topic based on the given title and abstract;\n2.Analyse the pattern of citation information based on\ntheir titles, and retrieve the citation information you\nthink is important to help you determine the category of\nthe first given paper. Now you need to combine the\ninformation from 1 and 2 to predict the category of the\nfirst given paper. You should only output one category.\nCompared to manual prompts, LPNL [77] generates\nFig. 13: Examples for Node Classification Task with GPT4 -\nGraph Learning Tasks.\nprompts through sampling. Specifically, it conducts a two-\nstage sampling process on the source node and each candidate\nneighbor from the original candidate set to acquire anchor\nnodes. Prompt generation is then based on these anchor nodes.\nWe provide manual prompt examples for various graph\nlearning tasks in Table III.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2352, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a2d87bd-651a-4cdf-9765-22ee0f97fc4e": {"__data__": {"id_": "8a2d87bd-651a-4cdf-9765-22ee0f97fc4e", "embedding": null, "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f085d5e4-0b19-4a6c-a7ae-2a7dc1808050", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "307941d324de3b682f023d3e01c2f78c0f77cf5a0b92652cbb234b104e69c14e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "97fbe4a2-1747-4cb6-bc19-1afc1299fba9", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "76b91675b5084a0e566f32ac833d69b3c3ac7cc5923a5e7b19837b6df0a321eb", "class_name": "RelatedNodeInfo"}}, "text": "You need to 1.Analyse\nthe papers\u2019 topic based on the given title and abstract;\n2.Analyse the pattern of citation information based on\ntheir titles, and retrieve the citation information you\nthink is important to help you determine the category of\nthe first given paper. Now you need to combine the\ninformation from 1 and 2 to predict the category of the\nfirst given paper. You should only output one category.\nCompared to manual prompts, LPNL [77] generates\nFig. 13: Examples for Node Classification Task with GPT4 -\nGraph Learning Tasks.\nprompts through sampling. Specifically, it conducts a two-\nstage sampling process on the source node and each candidate\nneighbor from the original candidate set to acquire anchor\nnodes. Prompt generation is then based on these anchor nodes.\nWe provide manual prompt examples for various graph\nlearning tasks in Table III. Additionally, we test LLMs with\nGPT 3.5 for node classification and KGQA using manual\nprompts, as shown in Figure 13 and Figure 14.\nSupervised fine-tuning (SFT) LLMs. IntructGLM [78] and\nGraphGPT [79] both employ SFT to train LLM for the node\nclassification task. IntructGLM [78] utilizes a single LLM by\nprompting methods. The prompt includes the description of\nnode attributes and structure through text descriptions and\ncorresponding queries. LLMs are then tasked with answer-\ning questions and determining node categories, leading to\nfine-tuning through supervised learning. On the other hand,\nGraphGPT [79] feeds graph structural information and text", "mimetype": "text/plain", "start_char_idx": 1492, "end_char_idx": 3008, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba43e147-174c-445f-8134-d207255f449c": {"__data__": {"id_": "ba43e147-174c-445f-8134-d207255f449c", "embedding": null, "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dc08fcf3c8395afd89ebea4e28d52f2ca0240f133ddf9a5695b31f2d38aded5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc", "node_type": "1", "metadata": {}, "hash": "b68253cd422d0c3cadbe6b27f2230fc97b40e0a5b4b5dad43bd6aa3ea40a483d", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 14: Examples for KGQA with GPT3.5 - Graph Learning\nTasks.\nPrefixtasksDownstreamtasksUnifiedtasksGNNTrainingonunifiedtasks\nTunablepromptPre-trainedGNNTrainingonPrefixtasksDownstreamtasksUnifying+DownstreamtasksTuningpromptfor\nFig. 15: Graph prompt for graph learning.Graph prompt meth-\nods first unify prefix and downstream tasks, then pre-train\nGNN on the unified tasks. The pre-trained GNN, when faced\nwith different downstream tasks, combines with a tunable\nprompt through tuning prompts to handle the downstream\ntasks better.\ninto LLM via embedding. Subsequently, two rounds of in-\nstruction tuning are conducted to refine LLM and effectively\naddress the node classification task. IntructGLM [78] em-\nploys prompts to input subgraph structures into LLM, while\nGraphGPT [79] inputs them into LLM through embedding.\n3)Graph prompt :In graph learning tasks, a wide array of\ntasks at the node, edge, and graph levels creates a challenge in\nachieving compatibility between pre-training and downstream\ntasks, potentially leading to negative transfer effects that can\nharm the performance of downstream tasks and compromise\nthe reliability of transfer learning in graph data. Current\nmethods aim to harmonize pre-training and downstream tasks\nto facilitate more effective transfer learning of graph infor-\nmation. Despite these efforts, it remains essential to identify\ntask-specific differences for optimal performance. Inspired by\nNLP, researchers have started incorporating prompts in graph\ncontexts to enable the reuse of pre-trained models across\nvarious downstream tasks without the need for repeated fine-tuning, as shown in Figure 15. The integration of prompts\nis crucial in assisting downstream tasks in achieving task-\nspecific optimal outcomes, bridging the gap between pre-\ntrained models and the diverse array of graph tasks to enhance\nperformance and transferability.\nGPPT [80] and GraphPrompt [81] aim to unify pre-training\nand downstream tasks in graph learning. GPPT transforms\nnode classification tasks into edge prediction tasks and em-\nploys masked edge prediction for GNN pre-training. Mean-\nwhile, GraphPrompt combines node and graph classification\ntasks into a subgraph similarity prediction task and utilizes\ngraph prompt functions, introducing unified instances and task\ntemplates to enhance performance. Subsequent research, like\nAll in One [82], further consolidates edge, node, and graph\nclassification tasks into a single framework using multi-task\nprompting approaches, standardizing graph prompts similar to\nlanguage prompts and enhancing initialization through meta-\nlearning techniques for improved reliability and generality\nacross different tasks in graph data analysis.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2707, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc": {"__data__": {"id_": "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc", "embedding": null, "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dc08fcf3c8395afd89ebea4e28d52f2ca0240f133ddf9a5695b31f2d38aded5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba43e147-174c-445f-8134-d207255f449c", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "9fed75016df41cbc2152dc4e3701c9ac4a24ea25b4d3abf1e4995902e6fec374", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f29c625b-2500-48d8-abcb-f0860007b797", "node_type": "1", "metadata": {}, "hash": "fb07145c88c28fda8f3b84e122d1922ed53a4b80a31c1ab24ef081107a3f8fce", "class_name": "RelatedNodeInfo"}}, "text": "GPPT [80] and GraphPrompt [81] aim to unify pre-training\nand downstream tasks in graph learning. GPPT transforms\nnode classification tasks into edge prediction tasks and em-\nploys masked edge prediction for GNN pre-training. Mean-\nwhile, GraphPrompt combines node and graph classification\ntasks into a subgraph similarity prediction task and utilizes\ngraph prompt functions, introducing unified instances and task\ntemplates to enhance performance. Subsequent research, like\nAll in One [82], further consolidates edge, node, and graph\nclassification tasks into a single framework using multi-task\nprompting approaches, standardizing graph prompts similar to\nlanguage prompts and enhancing initialization through meta-\nlearning techniques for improved reliability and generality\nacross different tasks in graph data analysis.\nC. Comparisons and Discussions\nFor addressing graph learning tasks, existing methods [30]\n[79] [82] categorize based on the role of LLM into three types:\nLLMs act as enhancers (LLM-GNN pipelines), LLMs act as\npredictors (LLM pipelines), and graph prompts. In the part\nof graph prompts, we introduce the prompting engineering\nin GNNs without utilizing LLMs. Graph prompts aim to\nunify downstream tasks and construct a universal framework.\nTherefore, it is compared with LLM-GNN pipelines and LLM\npipelines to provide a comprehensive overview.\nWhen LLMs act as enhancers, the most popular pipeline is\nthe LLM-GNN pipeline. There are three categories of LLM-\nGNN pipelines, depending on how LLM enhances GNN:\nencoding the graph into embeddings, generating graph pseudo\nlabels, and providing external knowledge/explanations. How-\never, the LLM-GNN pipelines that are currently available are\nnot end-to-end pipelines, meaning that LLM and GNN cannot\nbe trained together. LLM and GNN can be trained separately\nusing frameworks like EM framework [31] or by freezing\nLLM and using it as an external knowledge base. Co-training\nLLM and GNN can lead to issues like gradient vanishing,\nwhich is a significant obstacle in current LLM-GNN pipelines\ndue to the large number of parameters in LLM compared\nto GNN. To solve this problem, methods like knowledge\ndistillation can reduce the number of LLM parameters while\nretaining the beneficial capabilities for downstream tasks.\nWhen LLMs act as predictors, two main methods are\nused: prompting LLMs and SFT LLMs. All approaches for\nfine-tuning LLMs can be reviewed in the \u201dcomparisons and\ndiscussions\u201d section of Section III. Currently, SFT and DPO\nare popular methods for fine-tuning LLMs.", "mimetype": "text/plain", "start_char_idx": 1884, "end_char_idx": 4433, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f29c625b-2500-48d8-abcb-f0860007b797": {"__data__": {"id_": "f29c625b-2500-48d8-abcb-f0860007b797", "embedding": null, "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dc08fcf3c8395afd89ebea4e28d52f2ca0240f133ddf9a5695b31f2d38aded5e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "838e2ee95a8527905b9bc1bf0cd02cc4c0a15b396d3f7a8e1d2790c1d19b91f6", "class_name": "RelatedNodeInfo"}}, "text": "LLM and GNN can be trained separately\nusing frameworks like EM framework [31] or by freezing\nLLM and using it as an external knowledge base. Co-training\nLLM and GNN can lead to issues like gradient vanishing,\nwhich is a significant obstacle in current LLM-GNN pipelines\ndue to the large number of parameters in LLM compared\nto GNN. To solve this problem, methods like knowledge\ndistillation can reduce the number of LLM parameters while\nretaining the beneficial capabilities for downstream tasks.\nWhen LLMs act as predictors, two main methods are\nused: prompting LLMs and SFT LLMs. All approaches for\nfine-tuning LLMs can be reviewed in the \u201dcomparisons and\ndiscussions\u201d section of Section III. Currently, SFT and DPO\nare popular methods for fine-tuning LLMs.\nFor graph prompt, the workflow involves unifying pre-\ntraining and downstream tasks, followed by prompt tuning\nfor different downstream tasks through prompt engineering,\nas shown in Figure 15. Graph prompts require fewer tunable", "mimetype": "text/plain", "start_char_idx": 3674, "end_char_idx": 4662, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4272bda-de67-42a8-a372-c60868934a2e": {"__data__": {"id_": "b4272bda-de67-42a8-a372-c60868934a2e", "embedding": null, "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45917dba-0753-4365-8c31-c6ae446b4a70", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b8eef15910d21a4681a311b6b10998ec936d01d29ff7c85fa4976356c46aa014", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c", "node_type": "1", "metadata": {}, "hash": "1a0e83710f97cf6a5d19a6d9d7036181098fe19a7d7b5c7e2d2b3c23e038015d", "class_name": "RelatedNodeInfo"}}, "text": "Graph ReasoningSortingSort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional text. Input: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7] Output: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]Find the intersection of two sets of numbers. Output only the set of numbers that are present in both sets, no additional text. Input Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24, 10, 9, 3, 20, 8] Input Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23]Set Operations\nCount the frequency of how many times each country is explicitly named in the input text. You can generate any intermediate lists and states, but the final output should only contain the frequency of each country that appears at least once in the following json format, prefixed with \u201dOutput: \u201d (make sure to keep the same spelling for each country in the output as in the input text): {{ \u201dcountry1\u201d: frequency1, \u201dcountry2\u201d: frequency2, ... }}Keyword CountingKeyword: frequencyMerge the following 4 NDA documents -into a single NDA, maximizing retained information and minimizing redundancy. Output only the created NDA between the tags and , without any additional text. Here are NDAs: [four documents] Document MergingMath word problemsJanet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers\u2019 market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers\u2019 market?Math problems\nMulti-hop Question AnsweringQuestion triplets: (\u2019Hypocrite\u2019, directed by, $1), ($1, death date, $2) Question: When did the director of film Hypocrite (Film) die? To answer this question, we answer the following subquestions: (1) Who directed Hypocrite (Film)? (2) When did Miguel Morayta die? Logic reasoning\u2022 Premises: 1.It is not true that some giant language models do not have good performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1967, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c": {"__data__": {"id_": "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c", "embedding": null, "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45917dba-0753-4365-8c31-c6ae446b4a70", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b8eef15910d21a4681a311b6b10998ec936d01d29ff7c85fa4976356c46aa014", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4272bda-de67-42a8-a372-c60868934a2e", "node_type": "1", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "212bc3f4fc673bab5e0db1cde265a3a7cae1923b4050cc5c592c1bdd4e6489c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2f800325-9f87-4567-95df-39f099ce6576", "node_type": "1", "metadata": {}, "hash": "cb113298bdccd665c669b57aed52da00ea5b3cbb5f1a5c09c5a377ea6468f852", "class_name": "RelatedNodeInfo"}}, "text": "Here are NDAs: [four documents] Document MergingMath word problemsJanet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers\u2019 market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers\u2019 market?Math problems\nMulti-hop Question AnsweringQuestion triplets: (\u2019Hypocrite\u2019, directed by, $1), ($1, death date, $2) Question: When did the director of film Hypocrite (Film) die? To answer this question, we answer the following subquestions: (1) Who directed Hypocrite (Film)? (2) When did Miguel Morayta die? Logic reasoning\u2022 Premises: 1.It is not true that some giant language models do not have good performance. 2.All language models with good performance are used by some researchers. 3.If a language model is used by some researchers, it is popular. 4.If BERT is a giant language model, then GPT-3 is also a giant language model. 5.BERT is a giant language model. \u2022 Hypothesis: GPT-3 is popular. Give hypothesis label, true or false.51012048195133970011112334557899(a) (b) (c) (d) \n(e) (a) \n(f) (g) Fig. 16: Graph-formed Reasoning Tasks.\nFig. 17: Illustration of human logical derivation. [35]\nparameters compared to LLM-GNN and LLM pipelines; how-\never, they have a shallower semantic understanding of graph\nattributes. In LLM pipelines, LLMs need to undergo alignment\ntuning before they can be used for various downstream tasks.\nIn LLM-GNN pipelines, there is a general trend of training\nGNNs. Combining LLM-GNN and graph prompts is possible\nbecause graph prompts are designed for GNNs through prompt\nengineering and can be applied to LLM-GNN pipelines. By\nleveraging LLM\u2019s robust semantic representation capabilities\nand the lightweight fine-tuning of graph prompts, similar\nresults can be achieved.\nClassical graph tasks, such as node classification on at-\ntributed static networks, have recently obtained the most\nattention. However, there is potential for more complex tasks\nin the future, such as predicting graph evolution on dynamic\ngraphs. Leveraging LLM models that are suitable for handling\nsequential data and can process time series data, along with\nGNNs that are adept at capturing changes in graph structures,\ncan help address a broader range of problems effectively.", "mimetype": "text/plain", "start_char_idx": 1209, "end_char_idx": 3541, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2f800325-9f87-4567-95df-39f099ce6576": {"__data__": {"id_": "2f800325-9f87-4567-95df-39f099ce6576", "embedding": null, "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45917dba-0753-4365-8c31-c6ae446b4a70", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b8eef15910d21a4681a311b6b10998ec936d01d29ff7c85fa4976356c46aa014", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c", "node_type": "1", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "5828c71f78b5fdd8c977626fbc34344f94a62bc0c71bc2946e9fccada7d61c4d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3795f35d-9d1c-495b-b41f-4fdb28e3f281", "node_type": "1", "metadata": {}, "hash": "915754c774a0e83601a0d5ea0c303d122681f4ee9f0a1faa193fbacd1ba3e063", "class_name": "RelatedNodeInfo"}}, "text": "In LLM-GNN pipelines, there is a general trend of training\nGNNs. Combining LLM-GNN and graph prompts is possible\nbecause graph prompts are designed for GNNs through prompt\nengineering and can be applied to LLM-GNN pipelines. By\nleveraging LLM\u2019s robust semantic representation capabilities\nand the lightweight fine-tuning of graph prompts, similar\nresults can be achieved.\nClassical graph tasks, such as node classification on at-\ntributed static networks, have recently obtained the most\nattention. However, there is potential for more complex tasks\nin the future, such as predicting graph evolution on dynamic\ngraphs. Leveraging LLM models that are suitable for handling\nsequential data and can process time series data, along with\nGNNs that are adept at capturing changes in graph structures,\ncan help address a broader range of problems effectively. By\ncombining the strengths of LLM and GNN, we can tackle\nmore challenging tasks in the field of graph analysis.V. G RAPH -FORMED REASONING\nA. Tasks Introduction\nGraph-formed reasoning refers to combining the graph form\nwith LLMs to obtain more accurate and reliable answers.\nLLMs have strong reasoning capabilities, and many prompting\nmethods are proposed to enhance LLMs\u2019 reasoning abilities,\naddressing algorithmic problems, mathematical issues, etc.,\nsuch as chain of thought, self-consistency, in-context learning,\nand more. However, these methods diverge from the patterns\nof human thought. The human thought process is typically\nnon-linear rather than a simple chain of continuous thoughts,\nlike in Figure 17. Graphs can represent the thinking patterns\nof individuals during the thought process. Suppose LLMs\ncan also use graph-formed reasoning for inference. In that\ncase, they may be able to solve more complex problems,\nsuch as algorithmic problems, logical reasoning problems,\nand mathematical word problems, as shown in Figure 16. In\nthis section, we present seven graph-formed reasoning tasks\nalong with their definitions. Next, we introduce graph-formed\nreasoning methods involving two types of reasoning: think on\nthe graph and verify on the graph.\n1) Sorting: The problem of sorting involves arranging\ncertain elements in a specific order. For example, sorting a\nlist of duplicate numbers from 0 to 9 can be done using a\nmerge-based sorting algorithm. First, the input sequence of\nnumbers is divided into subarrays. Then, these subarrays are\nsorted individually and merged to form the final solution, as\nshown in Figure 16 (a).\n2) Set operations: Set operation task mainly focuses on\nset intersection.", "mimetype": "text/plain", "start_char_idx": 2689, "end_char_idx": 5258, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3795f35d-9d1c-495b-b41f-4fdb28e3f281": {"__data__": {"id_": "3795f35d-9d1c-495b-b41f-4fdb28e3f281", "embedding": null, "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45917dba-0753-4365-8c31-c6ae446b4a70", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b8eef15910d21a4681a311b6b10998ec936d01d29ff7c85fa4976356c46aa014", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f800325-9f87-4567-95df-39f099ce6576", "node_type": "1", "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "6011b71f63c7dcff1227f7f479e323b7c2ed6b94dd16476305a23c46584267ca", "class_name": "RelatedNodeInfo"}}, "text": "In that\ncase, they may be able to solve more complex problems,\nsuch as algorithmic problems, logical reasoning problems,\nand mathematical word problems, as shown in Figure 16. In\nthis section, we present seven graph-formed reasoning tasks\nalong with their definitions. Next, we introduce graph-formed\nreasoning methods involving two types of reasoning: think on\nthe graph and verify on the graph.\n1) Sorting: The problem of sorting involves arranging\ncertain elements in a specific order. For example, sorting a\nlist of duplicate numbers from 0 to 9 can be done using a\nmerge-based sorting algorithm. First, the input sequence of\nnumbers is divided into subarrays. Then, these subarrays are\nsorted individually and merged to form the final solution, as\nshown in Figure 16 (a).\n2) Set operations: Set operation task mainly focuses on\nset intersection. Specifically, the second input set is split into\nsubsets and the intersection of those subsets with the first input\nset is determined with the help of the LLM, as shown in Figure\n16 (b).\n3) Keyword counting: The keyword counting task aims to\ndetermine the frequency of specific keywords within a given\ncategory in the input text. The input text is divided into", "mimetype": "text/plain", "start_char_idx": 4408, "end_char_idx": 5619, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5af3080b-576f-4cbf-8bcb-e34fe4f59259": {"__data__": {"id_": "5af3080b-576f-4cbf-8bcb-e34fe4f59259", "embedding": null, "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73ffba1a-3744-44b9-b40b-23f80d706a77", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8cc863f87e0fce67484d57ce1ace909d863ffff0443a708a5e5305df5d641d82", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65", "node_type": "1", "metadata": {}, "hash": "ea78c193557a9f4a1997df8a43ccb3b52e04f9c74202efbf4d67baa819aa879a", "class_name": "RelatedNodeInfo"}}, "text": "ThinkongraphVerifyongraphLLM's intermediate answerLLM\u2019sfinalanswerInput\nDeletedintermediate answer\nThinkingprocessInputLLM's intermediate conclusionVerificationVerify whether two conclusions from two paths are the same.VerifyingprocessFig. 18: Graph-formed reasoning. Two directions: think on graphs and verify on graphs. Think on the graph refers to using\nthe graph structure to derive the final conclusion during the LLMs\u2019 reasoning process. Verify on the graph refers to using the\ngraph to verify the correctness of the LLMs\u2019 intermediate and final output.\nmultiple paragraphs, and the keywords are counted in each\nparagraph, with the sub-results aggregated, as shown in Figure\n16 (e).\n4) Document merging: Document merging is the process\nof generating a new document based on multiple input docu-\nments that have overlapping content sections. The goal is to\nminimize duplication as much as possible while preserving the\nmaximum amount of information, as shown in Figure 16 (c).\n5) Math word problems: Math word problems include\nsingle- and multi-step word problems with addition, multipli-\ncation, subtraction, division and other math topics. LLM re-\nquires an understanding of text and mathematical relationships\nand involves a multi-step reasoning process where calculations\nare performed step by step to arrive at an answer ultimately,\nas shown in Figure 16 (d).\n6) Multi-hop question qnswering: Multi-hop question an-\nswering requires LLM to retrieve and integrate information\nfrom multiple text passages or multi-hop graphs to answer\nquestions. For a complex reasoning question, LLM uses a\nsophisticated thinking process to perform reasoning and ul-\ntimately arrive at the correct answer, as shown in Figure 16\n(f).\n7) Logic reasoning: Logical reasoning is a process aimed at\nconcluding rigorously. It occurs in inference or argumentation,\nstarting from a set of premises and reasoning towards a\nconclusion supported by those premises. Propositional logic\nis the most fundamental logical system, consisting of p, q, r,\nand various operations, as shown in Figure 16 (g).\nB. Graph-formed Reasoning Methods\nThe graph form, with its inherent structural features, not\nonly mimics human reasoning patterns but also validates\nanswers from LLM through the relationships between nodes\nand local structure. Existing work can roughly be divided\ninto two categories: think on the graph and verify on the\ngraph , as shown in Figure 18. Think on the graph refers\nto LLM thinking in the form of a graph, where each node\non the graph represents a step in the thinking process oran intermediate conclusion during thinking, and the edges\non the graph indicate the direction of LLM inference or the\nrelationships between intermediate thinking steps.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2739, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65": {"__data__": {"id_": "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65", "embedding": null, "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73ffba1a-3744-44b9-b40b-23f80d706a77", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8cc863f87e0fce67484d57ce1ace909d863ffff0443a708a5e5305df5d641d82", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5af3080b-576f-4cbf-8bcb-e34fe4f59259", "node_type": "1", "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "412a6d3af4135e3135534754065bf87e28170faeb9caf681cf525f1276edd7bf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f59b949-78ca-4fe2-8c95-3437eb10e622", "node_type": "1", "metadata": {}, "hash": "6f17abbb6d53dc1663782641e9229e79e5eb1d754d9460ede4e1cbc2964b87d4", "class_name": "RelatedNodeInfo"}}, "text": "It occurs in inference or argumentation,\nstarting from a set of premises and reasoning towards a\nconclusion supported by those premises. Propositional logic\nis the most fundamental logical system, consisting of p, q, r,\nand various operations, as shown in Figure 16 (g).\nB. Graph-formed Reasoning Methods\nThe graph form, with its inherent structural features, not\nonly mimics human reasoning patterns but also validates\nanswers from LLM through the relationships between nodes\nand local structure. Existing work can roughly be divided\ninto two categories: think on the graph and verify on the\ngraph , as shown in Figure 18. Think on the graph refers\nto LLM thinking in the form of a graph, where each node\non the graph represents a step in the thinking process oran intermediate conclusion during thinking, and the edges\non the graph indicate the direction of LLM inference or the\nrelationships between intermediate thinking steps. In this way,\nthe LLM thinking process can be visually represented in graph\nform. Verify on the graph means verifying the consistency and\ncorrectness of answers by utilizing the graph\u2019s structure. For\nexample, if the end node of different paths is the same, the\nresults derived from different paths should be the same. If\ncontradictory conclusions arise, then the obtained conclusion\nis incorrect.\n1)Think on the graph :The GoT* reasoning method [36]\nis proposed with a two-stage framework to enable LLM to\nreason on a graph for answering multiple-choice questions.\nInitially, the input query is converted into a graph form, and\nwith the incorporation of graph and multimodal features, LLM\ngenerates rationale. This rationale updates the graph to a graph\nwith rationales, which is then combined with the original input\nand fed into the decoder to obtain the final answer.\nHowever, GoT* allows LLM to enhance the graph us-\ning multimodal information but does not reason step-by-\nstep deduction in graph form. The Graph of Thought (GoT)\n[34] represents LLM\u2019s intermediate thinking as an arbitrary\ngraph, facilitating powerful prompting for solving algorithmic\nproblems like sorting and keyword counts. LLM thoughts are\ndepicted as vertices in this approach, with edges representing\ndependencies between them. By continuously adding LLM\nresponses to the graph, arbitrary thoughts can be aggregated,\nforming a directed acyclic graph.\nMultiple LLMs can also be collaboratively harnessed to\ntackle complex mathematical challenges, extending beyond\nthe capabilities of a single LLM. Cumulative Reasoning (CR)\n[35] is proposed as a more human-like reasoning process. CR\nutilizes three LLMs in different roles: the proposer, verifier,\nand reporter.", "mimetype": "text/plain", "start_char_idx": 1808, "end_char_idx": 4478, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f59b949-78ca-4fe2-8c95-3437eb10e622": {"__data__": {"id_": "7f59b949-78ca-4fe2-8c95-3437eb10e622", "embedding": null, "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73ffba1a-3744-44b9-b40b-23f80d706a77", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8cc863f87e0fce67484d57ce1ace909d863ffff0443a708a5e5305df5d641d82", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65", "node_type": "1", "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "aa18c9bf293fb220c8ecb7fd595628c9ab35087adfbfb6021155d57b6e340c02", "class_name": "RelatedNodeInfo"}}, "text": "However, GoT* allows LLM to enhance the graph us-\ning multimodal information but does not reason step-by-\nstep deduction in graph form. The Graph of Thought (GoT)\n[34] represents LLM\u2019s intermediate thinking as an arbitrary\ngraph, facilitating powerful prompting for solving algorithmic\nproblems like sorting and keyword counts. LLM thoughts are\ndepicted as vertices in this approach, with edges representing\ndependencies between them. By continuously adding LLM\nresponses to the graph, arbitrary thoughts can be aggregated,\nforming a directed acyclic graph.\nMultiple LLMs can also be collaboratively harnessed to\ntackle complex mathematical challenges, extending beyond\nthe capabilities of a single LLM. Cumulative Reasoning (CR)\n[35] is proposed as a more human-like reasoning process. CR\nutilizes three LLMs in different roles: the proposer, verifier,\nand reporter. The proposer suggests the next step, the verifier\nchecks the accuracy of the steps, and the reporter decides\nwhen the reasoning process should end. Three roles of LLMs\ncollaborate to achieve more accurate reasoning processes.", "mimetype": "text/plain", "start_char_idx": 3611, "end_char_idx": 4704, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67dd2691-0fda-47f8-b2a6-8c0b9b5beff1": {"__data__": {"id_": "67dd2691-0fda-47f8-b2a6-8c0b9b5beff1", "embedding": null, "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "39445c8894959d6b3aae45b2ad1a4fe5190c8f9400cb82a10390db386197b100", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "08955ce6-2570-448d-be28-3e8edfe82241", "node_type": "1", "metadata": {}, "hash": "d2e4eb8d6f97f99372b594da7597939d87f6140792258145c62dc9ff0ffd5f55", "class_name": "RelatedNodeInfo"}}, "text": "Task Prompts\nSorting <Instruction >Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no\nadditional text. </Instruction ><Examples >like Input: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7] Output: [0, 0,\n1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9] </Examples >Input: [input list]\nSet Operations <Instruction >Find the intersection of two sets of numbers. Output only the set of numbers that are present in\nboth sets, no additional text. </Instruction ><Examples >like Input Set 1: [13, 16, 30, 6, 21, 7, 31, 15, 11, 1, 24,\n10, 9, 3, 20, 8] Input Set 2: [25, 24, 10, 4, 27, 0, 14, 12, 8, 2, 29, 20, 17, 19, 26, 23] Output: [24, 10, 20, 8]\n</Examples >Input Set 1: set1 Input Set 2: set2\nKeyword Counting <Instruction >Count the frequency of how many times each country is explicitly named in the input text. You can\ngenerate any intermediate lists and states, but the final output should only contain the frequency of each country that\nappears at least once in the following json format, prefixed with \u201dOutput: \u201d (make sure to keep the same spelling\nfor each country in the output as in the input text): {{\u201dcountry1\u201d: frequency1, \u201dcountry2\u201d: frequency2, ... }}\n</Instruction ><Approach >To count the frequency for each country follow these steps: 1. Split the input passage\ninto four paragraphs of similar length. 2. Count the frequency of each country in each paragraph. 3. Combine the\nfrequencies of each country from each paragraph by adding them together. </Approach ><Examples >(Omitted)\n</Examples >Input: input text\nDocument Merging Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained information\nand minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >, without\nany additional text. Here are NDAs: [four documents]\nMath word problems Q: Janet\u2019s ducks lay 16 eggs per day.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1898, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08955ce6-2570-448d-be28-3e8edfe82241": {"__data__": {"id_": "08955ce6-2570-448d-be28-3e8edfe82241", "embedding": null, "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "39445c8894959d6b3aae45b2ad1a4fe5190c8f9400cb82a10390db386197b100", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67dd2691-0fda-47f8-b2a6-8c0b9b5beff1", "node_type": "1", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a5300e28becd5740838ad27c15a96aa7abfb6cca2ae0ad1946980dfb7db3788b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5f651246-5fa9-4967-b88b-206da360133f", "node_type": "1", "metadata": {}, "hash": "dd21d203400cc210c9737eaddaa2732296ae25f756180ef8eb0383367cb970ca", "class_name": "RelatedNodeInfo"}}, "text": "Split the input passage\ninto four paragraphs of similar length. 2. Count the frequency of each country in each paragraph. 3. Combine the\nfrequencies of each country from each paragraph by adding them together. </Approach ><Examples >(Omitted)\n</Examples >Input: input text\nDocument Merging Merge the following 4 NDA documents <Doc1>-<Doc4>into a single NDA, maximizing retained information\nand minimizing redundancy. Output only the created NDA between the tags <Merged >and</Merged >, without\nany additional text. Here are NDAs: [four documents]\nMath word problems Q: Janet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends\nevery day with four. She sells the remainder at the farmers\u2019 market daily for $2 per fresh duck egg. How much\nin dollars does she make every day at the farmers\u2019 market?\nMulti-hop Question Answering Question triplets: (\u2019Hypocrite\u2019, directed by, $1), ($1, death date, $2) Question: When did the director of film\nHypocrite (Film) die? To answer this question, we answer the following subquestions: (1) Who directed Hypocrite\n(Film)? The film Hypocrite was directed by Miguel Morayta. (2) When did Miguel Morayta die? Miguel Morayta\ndied on 19 June 2013. So the answer is 19 June 2013.\nLogic reasoning \u2022 Premises: 1. It is not true that some giant language models do not have good performance. 2. All language\nmodels with good performance are used by some researchers. 3. If a language model is used by some researchers,\nit is popular. 4. If BERT is a giant language model, then GPT-3 is also a giant language model. 5. BERT is a\ngiant language model. \u2022 Hypothesis: GPT-3 is popular. \u2022 Label: [True]\nTABLE IV: Prompts for Graph-formed Reasoning.\n2)Verify on the graph : Verify on the graph is to validate\nthe intermediate reasoning results of LLM to enhance its\nperformance. The Reasoning Graph Verifier (RGV) [83] in this\nstudy assumes a logical connection between the intermediate\nsteps of different inference paths created by LLM. This allows\nthe multiple solutions generated by LLM for a reasoning task\nto be structured into a reasoning graph, aiming to improve\nthe accuracy and reliability of the outcomes. By constructing\nreasoning graphs from the various solutions provided by LLM,\na verifier is trained to determine the correctness of the resulting\nreasoning graph.", "mimetype": "text/plain", "start_char_idx": 1295, "end_char_idx": 3645, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5f651246-5fa9-4967-b88b-206da360133f": {"__data__": {"id_": "5f651246-5fa9-4967-b88b-206da360133f", "embedding": null, "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "39445c8894959d6b3aae45b2ad1a4fe5190c8f9400cb82a10390db386197b100", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "08955ce6-2570-448d-be28-3e8edfe82241", "node_type": "1", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "17d54d7b8b84b2dac40cbb1531bc506ccf71f34b4251ab9a8ff6c384476ca2f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f571c7ef-c8ea-4264-888c-2d44d3847f0a", "node_type": "1", "metadata": {}, "hash": "cbe545d5e0d602ea522e3fe9003b5788bd136f3605ca4194acd223feb7b29c2e", "class_name": "RelatedNodeInfo"}}, "text": "If BERT is a giant language model, then GPT-3 is also a giant language model. 5. BERT is a\ngiant language model. \u2022 Hypothesis: GPT-3 is popular. \u2022 Label: [True]\nTABLE IV: Prompts for Graph-formed Reasoning.\n2)Verify on the graph : Verify on the graph is to validate\nthe intermediate reasoning results of LLM to enhance its\nperformance. The Reasoning Graph Verifier (RGV) [83] in this\nstudy assumes a logical connection between the intermediate\nsteps of different inference paths created by LLM. This allows\nthe multiple solutions generated by LLM for a reasoning task\nto be structured into a reasoning graph, aiming to improve\nthe accuracy and reliability of the outcomes. By constructing\nreasoning graphs from the various solutions provided by LLM,\na verifier is trained to determine the correctness of the resulting\nreasoning graph. During the prediction phase, RGV assesses\nthe solutions and selects the highest-scoring one as the final\nanswer.\nHowever, this work trains an extra model to determine\nwhether the graph formed by the solutions generated by LLM\nis correct rather than utilizing the knowledge within the graph\nand the relationships between the knowledge for validation.\nThe Graph-guided CoT [84] approach aims to improve the\nrelevance of rationales generated by CoT during multi-step\nreasoning. It starts by extracting triplets from questions using\nLLM to build a question graph and generates intermediate sub-\nquestions from this graph. To ensure the rationale from LLM is\nlogical, Retrieval Augmented Generation (RAG) is used. In an\nopen-book scenario, knowledge retrieval is based on the sub-questions, providing retrieved documents and sub-questions\nas input to LLMs. LLMs generate rationales for the sub-\nquestions, creating a rationale graph. Based on the rationale\ngraph, the study assesses whether the generated rationales\naid in solving the original question. By iteratively generating\nintermediate rationales, the solution to the original question\ncan be determined.\nFinally, we provide manual prompt examples for various\ngraph learning tasks in Table IV. Additionally, we test LLMs\nwith GPT-4 for sorting and logic reasoning using manual\nprompts, as shown in Figure 19.\nC. Comparisons and Discussions\nGraph-formed reasoning is categorized into think on the\ngraph andverify on the graph .Think on the graph refers to\nusing the graph structure to derive the final conclusion during\nthe reasoning process with LLM. On the other hand, verify\non the graph involves treating the intermediate or final results\ngenerated by LLM as nodes on the graph and using the graph\nto determine if there are contradictions between the nodes,\nthus verifying the correctness of the LLM output.", "mimetype": "text/plain", "start_char_idx": 2811, "end_char_idx": 5508, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f571c7ef-c8ea-4264-888c-2d44d3847f0a": {"__data__": {"id_": "f571c7ef-c8ea-4264-888c-2d44d3847f0a", "embedding": null, "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "39445c8894959d6b3aae45b2ad1a4fe5190c8f9400cb82a10390db386197b100", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f651246-5fa9-4967-b88b-206da360133f", "node_type": "1", "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "619909734d442de4969b26e706bc20488ce520decec5b33eabd756b1d58b02ae", "class_name": "RelatedNodeInfo"}}, "text": "Based on the rationale\ngraph, the study assesses whether the generated rationales\naid in solving the original question. By iteratively generating\nintermediate rationales, the solution to the original question\ncan be determined.\nFinally, we provide manual prompt examples for various\ngraph learning tasks in Table IV. Additionally, we test LLMs\nwith GPT-4 for sorting and logic reasoning using manual\nprompts, as shown in Figure 19.\nC. Comparisons and Discussions\nGraph-formed reasoning is categorized into think on the\ngraph andverify on the graph .Think on the graph refers to\nusing the graph structure to derive the final conclusion during\nthe reasoning process with LLM. On the other hand, verify\non the graph involves treating the intermediate or final results\ngenerated by LLM as nodes on the graph and using the graph\nto determine if there are contradictions between the nodes,\nthus verifying the correctness of the LLM output.\nFor \u201cthink on the graph\u201d, a common issue with existing\napproaches is their lack of convenience. Compared to CoT\nand SC, the reasoning processes in current works are complex,", "mimetype": "text/plain", "start_char_idx": 4575, "end_char_idx": 5682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "32497538-d1fb-4035-81f0-92d347009f16": {"__data__": {"id_": "32497538-d1fb-4035-81f0-92d347009f16", "embedding": null, "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b99a8f-2296-4196-8f73-21e233697462", "node_type": "4", "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "ac8a811d510dd4e865e71090fcdadf788036bfcf99bc371ccf1e87fd7c40cd2b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "89c04de1-534e-4c35-b326-0ab0a360183e", "node_type": "1", "metadata": {}, "hash": "473666a9b6cea2f462285d063b686d5cb807ace6a2def0aec8e0585321a968e9", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 19: Examples for Logic Reasoning Task with GPT4 -\nGraph Reasoning Tasks.\nrequiring multiple stages of reasoning and validation. Graph\nof thought methods are not plug and play, which contradicts\nthe original intent of prompts. Even though using more LLMs\ncan simplify the reasoning and validation process, it raises the\ncost and barrier to entry for reasoning. Therefore, the current\nchallenge is to find a plug-and-play, low-barrier LLM graph\nreasoning method that improves LLM reasoning capabilities.\nFor \u201cverify on the graph\u201d, the current approaches have yet to\nutilize the nature of the graph structure for validation. Existing\nmethods either retrain a model to determine correctness or use\na KG for assessment without using the relationships between\nnodes to infer whether the conclusions within each node in\nthe graph are correct.\nTherefore, for the \u201cthink on the graph,\u201d the future direction\ncould focus on developing a plug-and-play, low-barrier LLM\ngraph reasoning method that enhances LLM reasoning abili-\nties, a pressing issue that needs to be addressed. On the other\nhand, concerning the \u201cverify on the graph\u201d method, future\nresearch could explore how to utilize the relationships between\nnodes in the graph structure to verify the outputs of LLM or\nthe reasoning process itself.VI. G RAPH REPRESENTATION\nA. Tasks Introduction\nLLMs\u2019 powerful text representation abilities empower text\nembeddings to capture deeper semantic nuances, which also\ncan enhance graph representations, particularly for Text At-\ntributed Graphs (TAGs). When dealing with structured text\ndata, the key challenge is integrating graph structures into text\nembeddings produced by LLMs to enhance their informative-\nness or enable LLMs to process text embeddings with graph\nstructures within the text space. Moreover, effectively incor-\nporating the graph description within the prompt is essential\nfor LLMs, especially in closed-source models like ChatGPT,\nwhere the embedding is invisible. How the graph is encoded\nwithin the prompt influences the model\u2019s comprehension of\nthe graph. Thus, we summarize three types of graph repre-\nsentation: graph embedding ,graph-enhanced text embedding ,\nandgraph-encoded prompts , as shown in Figure 20. Next, we\nintroduce graph-formed reasoning methods corresponding to\nthe above three types.\n1) Graph embedding: Graph embedding focuses on trans-\nforming a graph into a specific ordered sequence, which is then\nfed into an LLM to learn the sequence\u2019s embedding using their\nexcellent semantic capturing ability and then derive the graph\nembedding.\n2) Graph-enhanced text embedding: Graph-enhanced text\nembedding emphasizes incorporating structural embedding\ninto text embedding. There are two types of embeddings:\nstructural embedding, which captures the local structure, and\ntext embedding, which captures the semantic meaning.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2854, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89c04de1-534e-4c35-b326-0ab0a360183e": {"__data__": {"id_": "89c04de1-534e-4c35-b326-0ab0a360183e", "embedding": null, "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09b99a8f-2296-4196-8f73-21e233697462", "node_type": "4", "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "ac8a811d510dd4e865e71090fcdadf788036bfcf99bc371ccf1e87fd7c40cd2b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32497538-d1fb-4035-81f0-92d347009f16", "node_type": "1", "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c8b44b9ebaa3cb2c0c53f8ebb10566a37d5daff2b4550e4a93a6146e27e02fb7", "class_name": "RelatedNodeInfo"}}, "text": "How the graph is encoded\nwithin the prompt influences the model\u2019s comprehension of\nthe graph. Thus, we summarize three types of graph repre-\nsentation: graph embedding ,graph-enhanced text embedding ,\nandgraph-encoded prompts , as shown in Figure 20. Next, we\nintroduce graph-formed reasoning methods corresponding to\nthe above three types.\n1) Graph embedding: Graph embedding focuses on trans-\nforming a graph into a specific ordered sequence, which is then\nfed into an LLM to learn the sequence\u2019s embedding using their\nexcellent semantic capturing ability and then derive the graph\nembedding.\n2) Graph-enhanced text embedding: Graph-enhanced text\nembedding emphasizes incorporating structural embedding\ninto text embedding. There are two types of embeddings:\nstructural embedding, which captures the local structure, and\ntext embedding, which captures the semantic meaning. How to\ncombine these two types of embeddings is the core of graph-\nenhanced text embedding.\n3) Graph-encoded prompts: Graph-encoded prompts con-\ncentrate on how to describe a graph so that LLMs can\nunderstand it more efficiently and then input it into LLMs.\nFor instance, in a regular graph, the graph can be placed in a\nstory context by assuming that the relationships between the\nnodes are friends or colleagues.\nWith the emergence of LLM, much work has been done on\ngraph representation. Three goals of the graph representation\ndirection can be identified from the above three categories:\nto obtain better graph embeddings as an input into GNNs, to\nobtain better text embeddings as an input into LLMs/LMs,\nand to get better prompts for graph description as an input\ninto LLMs.\nB. Graph Representation Methods\nFor the three categories of tasks mentioned above, each\ntype of task has specific focuses, technical characteristics, and\nobjectives.\n1)Graph embedding :Text data is sequential, while graph\ndata is structural, posing a challenge for LLMs, which excel at\nhandling text but struggle with graphs. How do we transform\ngraphs into sequences? Graph embedding methods use specific\norder sequences to represent the graph, where specific order\nrepresents graph structure. WalkLM [38] aims to enhance", "mimetype": "text/plain", "start_char_idx": 1979, "end_char_idx": 4157, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "45333901-a829-425f-9567-c62c03e0ac68": {"__data__": {"id_": "45333901-a829-425f-9567-c62c03e0ac68", "embedding": null, "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ad0a921-d639-4813-8c5c-4d47f9632345", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c5a4f289afafde70e2fd148a857bb1b5a0b62719b453c8f3fcf3a17eb8252a9b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff", "node_type": "1", "metadata": {}, "hash": "b9920d117afe7c6d37ae124054504ac153c2ebe167588fb346c0812cb4e377e0", "class_name": "RelatedNodeInfo"}}, "text": "GraphrepresentationGraph embeddingGraph-enhanced text embeddingGraph-encoded promptsGraph1432014314013204\u2026\u2026SpecificordersequencesLLM/PLMGraphEmbeddingsTextembeddingsTexttokensLLM/PLMTextembeddingswithgraphstructureGraphstructuralembeddings+\u2026\u2026\nPrompt:(placinggraphGinmultiplecontexts)GdescribesafriendshipgraphamongJames,David,John\u2026Gdescribesaco-authorshipgraphamongJames,David,John\u2026GdescribesasocialnetworkgraphamongJames,David,John\u2026\u2026\u2026LLMResponse: \u2026\u2026Fig. 20: Graph representation. Three types of graph representation are shown: graph embedding, graph-enhanced text embedding,\nand graph-encoded prompts. Graph embedding methods use specific order sequences to represent the graph. Graph-enhanced\ntext embedding emphasizes incorporating structural embedding into text embedding. Graph-encoded prompts concentrate on\nhow to describe a graph in prompts.\ngraph representations in TAGs by utilizing a language model.\nInitially, text sequences are generated on the TAG through\nthe random walk algorithm, capturing structural features and\nnode proximity. By incorporating text information from nodes\nand edges into these sequences based on the graph structure,\nthe texturing process preserves component attributes. Subse-\nquently, these sequences are input into a masked language\nmodel for training, where each token represents a node or\nedge, leading to improved graph representations and enhanced\ndownstream task efficiency. Notably, various masked language\nmodel options, including LLMs, are available.\nWhile WalkLM [38] focuses on superior graph embeddings\nfor tasks like node classification, GraphText [37] transforms\ngraphs into the natural language to enable LLMs to process\ngraph data in the text domain, leveraging LLMs\u2019 generalization\ncapabilities for graph tasks. GraphText [37] reformulates graph\nreasoning as text-to-text problems, establishing text input and\noutput spaces. GraphText first constructs grammar trees for\ngraphs, then traverses them to generate graph text sequences,\nand finally maps the graph to the text space. The text input is\nthen fed into an LLM, with the LLM results mapped to the\nlabel space, effectively enabling LLMs to handle graph tasks.\n2)Graph-enhanced text embedding :Current work focuses\non simply passing graph structure information to the LLM\nthrough prompts without deeply learning the graph structure,\nwhich can lead to an LLM\u2019s insufficient understanding of\ncomplex structural relationships.\nDGTL [39] integrates graph information into text with\nLLMs for node classification tasks. It begins by inputting text\ninto a frozen LLM to create text embeddings from the last\nlayer. Then, a disentangled graph learning method is employed\nto extract various structural details and generate structure\nembeddings.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2743, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff": {"__data__": {"id_": "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff", "embedding": null, "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ad0a921-d639-4813-8c5c-4d47f9632345", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c5a4f289afafde70e2fd148a857bb1b5a0b62719b453c8f3fcf3a17eb8252a9b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45333901-a829-425f-9567-c62c03e0ac68", "node_type": "1", "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "fd6096fcace3b81c9b64507b07f146b171dca339715c4824940a8c80041ca59f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d3a91f10-768a-4593-bc07-5dbf88014b0a", "node_type": "1", "metadata": {}, "hash": "1fe253f06bf40ef1417627315dea7670b2c2aae930bf99dd40ece7153d4709a7", "class_name": "RelatedNodeInfo"}}, "text": "GraphText first constructs grammar trees for\ngraphs, then traverses them to generate graph text sequences,\nand finally maps the graph to the text space. The text input is\nthen fed into an LLM, with the LLM results mapped to the\nlabel space, effectively enabling LLMs to handle graph tasks.\n2)Graph-enhanced text embedding :Current work focuses\non simply passing graph structure information to the LLM\nthrough prompts without deeply learning the graph structure,\nwhich can lead to an LLM\u2019s insufficient understanding of\ncomplex structural relationships.\nDGTL [39] integrates graph information into text with\nLLMs for node classification tasks. It begins by inputting text\ninto a frozen LLM to create text embeddings from the last\nlayer. Then, a disentangled graph learning method is employed\nto extract various structural details and generate structure\nembeddings. These structure embeddings are combined with\nthe text embeddings and fed back into the frozen LLM for\nnode classification. The entire process is fine-tuned to optimize\nthe disentangled graph learning for better results.\nWhile DGTL [39] concentrates on utilizing LLMs to in-\ntegrate text and graph structure for graph tasks, G2P2 [85]\nemphasizes merging graph structure with text to address textclassification tasks. Textual data commonly exhibit network\nstructures, such as hyperlinks in citation networks or purchase\nnetworks, which encapsulate meaningful semantic relation-\nships that can enhance text classification performance.\nG2P2 [85] is proposed to tackle low-resource text clas-\nsification through a dual approach. Three graph interaction-\nbased contrastive strategies are introduced during pre-training\nto jointly pre-train the graph-text model. In the downstream\nclassification process, efforts are made to facilitate the joint\npre-trained model in achieving low-resource classification.\n3)Graph-encoded prompts :The prompting method is\ncrucial for LLMs to solve tasks. For closed-source LLMs,\nthe prompt serves as instructions to guide the LLM in under-\nstanding and solving problems. Therefore, effectively encoding\ngraphs in the prompt is vital for LLMs to comprehend graph\nstructure and solve graph tasks. Graph encoding refers to how\ngraphs are represented in the prompt.\nTalk Like A Graph [86] introduces diverse graph encoding\ntechniques by placing the same graph in multiple contexts.\nThis strategy highlights how a node, which may lack intrinsic\nmeaning, can be interpreted differently based on the context;\nfor instance, a node could represent a person named David,\nwith edges indicating various relationships like co-authorships\nor friendships. When asking LLM the degree of one node, in\nthe given contexts, that equals how many friendships David\nhas.", "mimetype": "text/plain", "start_char_idx": 1880, "end_char_idx": 4617, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d3a91f10-768a-4593-bc07-5dbf88014b0a": {"__data__": {"id_": "d3a91f10-768a-4593-bc07-5dbf88014b0a", "embedding": null, "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ad0a921-d639-4813-8c5c-4d47f9632345", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c5a4f289afafde70e2fd148a857bb1b5a0b62719b453c8f3fcf3a17eb8252a9b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff", "node_type": "1", "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "d11e126642cf208b27d2909f20ae4415ba850eac15a3b3149033a1a892cf0e0b", "class_name": "RelatedNodeInfo"}}, "text": "3)Graph-encoded prompts :The prompting method is\ncrucial for LLMs to solve tasks. For closed-source LLMs,\nthe prompt serves as instructions to guide the LLM in under-\nstanding and solving problems. Therefore, effectively encoding\ngraphs in the prompt is vital for LLMs to comprehend graph\nstructure and solve graph tasks. Graph encoding refers to how\ngraphs are represented in the prompt.\nTalk Like A Graph [86] introduces diverse graph encoding\ntechniques by placing the same graph in multiple contexts.\nThis strategy highlights how a node, which may lack intrinsic\nmeaning, can be interpreted differently based on the context;\nfor instance, a node could represent a person named David,\nwith edges indicating various relationships like co-authorships\nor friendships. When asking LLM the degree of one node, in\nthe given contexts, that equals how many friendships David\nhas.\nIn contrast, Talk Like A Graph [86] primarily emphasizes\ntext modality graph encoding, while Which Modality Should I\nUse [87] employs three encoding modalities - text, image, and\nmotif - to encode graphs. The latter method utilizes different\nprompt techniques to evaluate the overall connectivity of a\ngraph, enabling LLMs to handle intricate graph structures\nmore effectively. Specifically, the text modality encoding pro-\nvides insights into subgraphs and their connections at a local\nlevel, while the motif modality encoding captures essential\ngraph patterns like stars, triangles, and cliques, offering a bal-\nanced perspective on local and global information. Moreover,\nthe image modality encoding delivers a broader view of nodes\nwith limited labels, effectively utilizing the input context.", "mimetype": "text/plain", "start_char_idx": 3743, "end_char_idx": 5415, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "250bb72d-46e5-4860-ade6-1205ec9df923": {"__data__": {"id_": "250bb72d-46e5-4860-ade6-1205ec9df923", "embedding": null, "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87634c56-a74f-43c1-aad8-9d65949efca2", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "682e0336ada51df88b4b64c907052cf5083675c69dc16558685adefe9eb51872", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ac34f5d-b8da-4a0e-9d18-91dead60e538", "node_type": "1", "metadata": {}, "hash": "cc4fb8a53d5f15110f1f109d3f84ca134f89e5c358072a85e38de31ab4f96b51", "class_name": "RelatedNodeInfo"}}, "text": "Query: What other works does the director who directed Inception have?\nKGsLLMs1. \"The Dark Knight Trilogy\" 2. \"Interstellar\"3. \"Dunkirk\"4. \"Memento\"5. \"The Prestige\"6. \"Insomnia\"Incomplete answerQuery: What other works does the director who directed Inception have?LLMs1. \"The Dark Knight Trilogy\" 2. \"Interstellar\"3. \"Dunkirk\"4. \"Memento\"5. \"The Prestige\"6. \"Insomnia\"7. \u201cOppenheimer\"Complete answer+KGs enhanced LLMsFig. 21: KG-based augmented retrieval. Knowledge graphs can\nenhance LLMs to provide more comprehensive answers.\nIn comparing these two methods, Talk Like A Graph [86]\nfocuses on diverse graph encoding within text modality by\nconstructing contexts, whereas Which Modality Should I Use\n[87] utilizes multiple modalities to encode graphs compre-\nhensively, enhancing the LLMs\u2019 ability to understand graph\nstructures.\nC. Comparisons and Discussions\nGraph embedding focuses on transforming a graph into a\nspecific ordered sequence, which is then fed into an LLM\nto learn the sequence\u2019s embedding and derive the graph em-\nbedding. On the other hand, graph-enhanced text embedding\nemphasizes incorporating structural embedding into text em-\nbedding. Lastly, graph-encoded prompts concentrate on how\nto describe a graph and input it into an LLM.\nHowever, due to LLMs\u2019 powerful text representation capa-\nbilities, the first two methods exhibit a deep semantic under-\nstanding of graph attributes. However, they still need suitable\nstructural information capturing, which remains rudimentary\nand inadequate. Additionally, aligning the graph structure\nfeatures with text features to better represent the graph\u2019s\nfeatures is a current issue that needs to be addressed.\nFor graph-encoded prompts, most methods build a narrative\ncontext for the graph or describe it multimodally before feed-\ning it into an LLM. Both methods enable the LLM to interpret\nthe graph from various perspectives to improve performance.\nThe critical challenge currently lies in designing diverse and\neasily understandable graph descriptions for LLMs, convey-\ning essential graph descriptions while enhancing the LLM\u2019s\ncomprehension of the input description.\nVII. K NOWLEDGE GRAPH BASED AUGMENTED\nRETRIEVAL\nLLMs have shown remarkable reasoning capabilities in\nchallenging tasks, sparking debates on the potential replace-\nment of Knowledge Graphs (KGs) in triplet form (subject,\npredicate, object) by LLMs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2385, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6ac34f5d-b8da-4a0e-9d18-91dead60e538": {"__data__": {"id_": "6ac34f5d-b8da-4a0e-9d18-91dead60e538", "embedding": null, "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87634c56-a74f-43c1-aad8-9d65949efca2", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "682e0336ada51df88b4b64c907052cf5083675c69dc16558685adefe9eb51872", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "250bb72d-46e5-4860-ade6-1205ec9df923", "node_type": "1", "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f3d102b95bf968bd643d65df225a8014f3073b9be286aaf02ee2d6398bdd5e01", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aba5f559-5219-4853-bd75-cc0ee93fb232", "node_type": "1", "metadata": {}, "hash": "e2df304b3cf31e393987d808d10517031a9d3b5fdba841c0136898577c45a412", "class_name": "RelatedNodeInfo"}}, "text": "Additionally, aligning the graph structure\nfeatures with text features to better represent the graph\u2019s\nfeatures is a current issue that needs to be addressed.\nFor graph-encoded prompts, most methods build a narrative\ncontext for the graph or describe it multimodally before feed-\ning it into an LLM. Both methods enable the LLM to interpret\nthe graph from various perspectives to improve performance.\nThe critical challenge currently lies in designing diverse and\neasily understandable graph descriptions for LLMs, convey-\ning essential graph descriptions while enhancing the LLM\u2019s\ncomprehension of the input description.\nVII. K NOWLEDGE GRAPH BASED AUGMENTED\nRETRIEVAL\nLLMs have shown remarkable reasoning capabilities in\nchallenging tasks, sparking debates on the potential replace-\nment of Knowledge Graphs (KGs) in triplet form (subject,\npredicate, object) by LLMs. Recent LLMs are seen as viable\nalternatives to structured knowledge repositories such as KGs,indicating a shift towards utilizing LLMs for processing real-\nworld factual knowledge [88] [89].\nA. LLMs limitations and comparison with KGs\nLLMs, while powerful, face several significant challenges:\n\u2022Hallucination is a common issue for LLMs due to a\nlack of domain-specific knowledge and knowledge ob-\nsolescence, leading to incorrect reasoning and reduced\ncredibility in critical scenarios like medical diagnosis and\nlegal judgments [88] [90] [43]. Although some LLMs can\nexplain predictions through causal chains, they struggle\nto address hallucination effectively. Integrating external\nKGs can help mitigate these problems [41].\n\u2022Insufficient domain knowledge hampers LLM perfor-\nmance in specific areas, including private datasets, ne-\ncessitating the integration of domain-specific knowledge\ngraphs to enhance their ability to answer domain-specific\nquestions [40].\n\u2022LLMs struggle with recalling facts when generating\nknowledge-based content, despite excelling in learning\nlanguage patterns and conversing with humans [89].\n\u2022LLMs have limitations in accurately capturing and re-\ntrieving foundational knowledge, hindering their ability\nto access factual information effectively [42].\nIn contrast, KGs like Wikipedia and DBpedia are structured\nrepositories of rich factual knowledge, providing a more\nexplicit and reliable source of information compared to the\nblack-box nature of LLMs, as shown in Figure 21. How do\nwe measure the shortcomings of LLM relative to KG? KGLens\nis proposed as an effective method to evaluate the factual\naccuracy and identify knowledge gaps in LLMs by assessing\nthe alignment between a KG and LLM [91].", "mimetype": "text/plain", "start_char_idx": 1516, "end_char_idx": 4117, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aba5f559-5219-4853-bd75-cc0ee93fb232": {"__data__": {"id_": "aba5f559-5219-4853-bd75-cc0ee93fb232", "embedding": null, "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "87634c56-a74f-43c1-aad8-9d65949efca2", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "682e0336ada51df88b4b64c907052cf5083675c69dc16558685adefe9eb51872", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ac34f5d-b8da-4a0e-9d18-91dead60e538", "node_type": "1", "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "369cb2cad275d98126dccb7d2d878ad78be3e6e0900266bd30dc3fa1d541b745", "class_name": "RelatedNodeInfo"}}, "text": "\u2022LLMs struggle with recalling facts when generating\nknowledge-based content, despite excelling in learning\nlanguage patterns and conversing with humans [89].\n\u2022LLMs have limitations in accurately capturing and re-\ntrieving foundational knowledge, hindering their ability\nto access factual information effectively [42].\nIn contrast, KGs like Wikipedia and DBpedia are structured\nrepositories of rich factual knowledge, providing a more\nexplicit and reliable source of information compared to the\nblack-box nature of LLMs, as shown in Figure 21. How do\nwe measure the shortcomings of LLM relative to KG? KGLens\nis proposed as an effective method to evaluate the factual\naccuracy and identify knowledge gaps in LLMs by assessing\nthe alignment between a KG and LLM [91].\nB. Solutions to LLMs limitations\nTo address the limitations of LLMs, such as hallucination,\ninsufficient domain knowledge, etc., integrating LLMs with\nKGs is a potential way to allow LLMs to learn knowledge\nfrom KGs and enhance their capabilities. The REASONING\nON GRAPHS (RoG) framework [43] synergizes LLMs with\nKGs for faithful and interpretable reasoning. Specifically,\nRoG utilizes a planning retrieval-reasoning framework where\nrelation paths grounded by KGs are generated as faithful plans.\nThese plans are then used to retrieve valid reasoning paths\nfrom KGs to facilitate LLMs\u2019 faithful reasoning. Existing work\nhas taken on the challenges posed by the four main limitations\nof LLMs through distinct perspectives, each offering unique\nsolutions.\nAddressing the first limitation concerning hallucination is-\nsues in LLMs, the Head to Tail benchmark [88] is introduced\nto assess LLMs\u2019 reliability in answering factual questions\nand to evaluate the probability of hallucination in generating\nKG triples. Additionally, it explores whether factors like\nmodel size or instruction tuning can enhance LLM knowledge.\nThink-on-Graph (ToG) [41] partially addresses hallucination\nby involving the LLM agent in iteratively searching KGs,\nidentifying promising reasoning paths, and providing likely", "mimetype": "text/plain", "start_char_idx": 3352, "end_char_idx": 5411, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bb26f8b0-e476-4eb2-9537-caa3f3afaf91": {"__data__": {"id_": "bb26f8b0-e476-4eb2-9537-caa3f3afaf91", "embedding": null, "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13558517-2121-4d6d-92b0-bc91292b9028", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "093c3f13436aaa5104d7974fc4bfab9897d80fd11eda896b63d019af6af39d2c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c7e32be-40b9-427c-869d-a7ccfc03fbef", "node_type": "1", "metadata": {}, "hash": "f33da3367d9b175c184f643d0149b7c07ecdaaed5fee0243807af7b5001f8e55", "class_name": "RelatedNodeInfo"}}, "text": "reasoning outcomes. The second limitation is LLM needs\ndomain-specific knowledge. To tackle this, GLaM [40] is\ndeveloped to convert knowledge graphs into text paired with\nlabeled questions and answers, allowing LLMs to acquire and\nrespond to domain-specific knowledge. Regarding the third\nlimitation related to LLMs forgetting facts, integrating KGs\nwith PLMs (KGPLMs) [89] is introduced to enhance the\nmodel\u2019s ability to recall facts compared to standalone LLMs.\nThis approach emphasizes the competitive and complementary\nrelationship between LLMs and KGs, where LLMs improve\nknowledge extraction accuracy, and KGs guide LLM training\nto enhance memory and knowledge application capabilities.\nFinally, the fourth limitation pertains to LLMs\u2019 challenge\nin accurately retrieving and returning knowledge from KGs.\nKGs can enhance LLM performance by incorporating them\nduring pre-training and inference stages or to deepen LLM\u2019s\nunderstanding of acquired knowledge. Graph Neural Prompt-\ning (GNP) [42] is proposed to augment pre-trained LLMs\nusing foundational knowledge, such as retrieval-augmented\ngeneration, to facilitate effective learning from KGs. GNP [42]\nretrieves and encodes relevant, grounded knowledge to gener-\nate Graph Neural Prompts, embedding vectors that provide\nguidance and instructions for LLMs.\nC. Other KG + LLMs works\n1)KG tasks with LLMs :Moreover, LLMs can enhance\nKGs to tackle a broader array of challenges. By leverag-\ning LLMs, KGs can be fortified to perform various KG-\nrelated tasks such as embedding, completion, construction,\ntext generation from graphs, and question answering [90].\nAn illustrative example is how LLMs can support KG tasks\nsuch as knowledge graph alignment. In entity alignment tasks\nbetween different knowledge graphs, the objective is to iden-\ntify pairs of entities representing the same entity. To address\nthis, AutoAlign [92] facilitates alignment without the need for\nexpensive manual seed creation. Specifically, AutoAlign [92]\nautomatically identifies similarities between predicates across\ndifferent KGs with the assistance of LLMs.\n2)Applications of KGs + LLMs :The combination of KGs\nand LLMs has other applications as well. For instance, it can\naddress tasks like multi-document question answering. Knowl-\nedge Graph Prompting (KGP) [93] is introduced to design\nappropriate context by building and exploring a knowledge\ngraph. Subsequently, this context guides LLMs for answering\nmulti-document questions.\nD. Summary\nIn conjunction with LLMs, the future directions for KGs fo-\ncus on overcoming challenges and seizing opportunities in this\nevolving field.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2617, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c7e32be-40b9-427c-869d-a7ccfc03fbef": {"__data__": {"id_": "1c7e32be-40b9-427c-869d-a7ccfc03fbef", "embedding": null, "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13558517-2121-4d6d-92b0-bc91292b9028", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "093c3f13436aaa5104d7974fc4bfab9897d80fd11eda896b63d019af6af39d2c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bb26f8b0-e476-4eb2-9537-caa3f3afaf91", "node_type": "1", "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2165a5f0364d5a074ae7003bd2edc3caf46948a8019d9981818a3c4bd317ec85", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27ccdbee-50f3-47a9-a617-1f446d497103", "node_type": "1", "metadata": {}, "hash": "9c1f51b3d6c9e1b4f79c86fc08f45e0848e6331852ad5d1bbab0efd898371b0b", "class_name": "RelatedNodeInfo"}}, "text": "To address\nthis, AutoAlign [92] facilitates alignment without the need for\nexpensive manual seed creation. Specifically, AutoAlign [92]\nautomatically identifies similarities between predicates across\ndifferent KGs with the assistance of LLMs.\n2)Applications of KGs + LLMs :The combination of KGs\nand LLMs has other applications as well. For instance, it can\naddress tasks like multi-document question answering. Knowl-\nedge Graph Prompting (KGP) [93] is introduced to design\nappropriate context by building and exploring a knowledge\ngraph. Subsequently, this context guides LLMs for answering\nmulti-document questions.\nD. Summary\nIn conjunction with LLMs, the future directions for KGs fo-\ncus on overcoming challenges and seizing opportunities in this\nevolving field. Firstly, leveraging KGs for Hallucination Detec-\ntion in LLMs aims to address the issue of generating inaccurate\ncontent. Secondly, utilizing KGs for Editing Knowledge in\nLLMs will enable the swift adaptation of internal knowledge\nto real-world changes. Moreover, the challenge of injecting\nknowledge into Black-box LLMs due to restricted access to\ninternal structures necessitates innovative approaches. Lastly,\nOccupationsLLM tuningBehavior GraphFig. 22: Graph-LLM-based applications - Recommendation\nsystems. This shows LLM for graph data understanding in\nonline job recommendations [46].\nintegrating Multi-Modal LLMs with KGs can enrich handling\ndiverse data types within knowledge graphs [90].\nVIII. G RAPH -LLM- BASED APPLICATIONS\nGraph-LLM-based applications refer to frameworks that\nintegrate graphs with LLMs. Apart from their applications\nin graph-related tasks, they are also utilized in various other\ndomains (as shown in Figure ??), such as conversational\nunderstanding and recommendation systems, as shown in\nFigure 22. Common frameworks involve combining GNNs\nwith LLMs, merging graph data with LLMs, and exploring\nadditional innovative approaches that leverage the advantages\nbetween graph structures and language models for diverse\napplications.\n1) Conversational understanding: By combining LLM\nwith graph traversal, collaborative query rewriting [94] is\nproposed to improve the coverage of unseen interactions,\naddressing the flawed queries users pose in dialogue systems.\nFlawed queries often arise due to ambiguities or inaccura-\ncies in automatic speech recognition and natural language\nunderstanding. When integrated with graph traversal, LLM\ncan effectively navigate through the graph structure to retrieve\nrelevant information and provide more accurate responses.\n2) Response forecasting: LLM can effectively handle social\nnetworks and extract latent personas from users\u2019 profiles and\nhistorical posts.", "mimetype": "text/plain", "start_char_idx": 1849, "end_char_idx": 4545, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "27ccdbee-50f3-47a9-a617-1f446d497103": {"__data__": {"id_": "27ccdbee-50f3-47a9-a617-1f446d497103", "embedding": null, "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13558517-2121-4d6d-92b0-bc91292b9028", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "093c3f13436aaa5104d7974fc4bfab9897d80fd11eda896b63d019af6af39d2c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c7e32be-40b9-427c-869d-a7ccfc03fbef", "node_type": "1", "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a1c07fb380c5a271df8cdc89fad8125096d199f59ee0edfdf15e78b0398af732", "class_name": "RelatedNodeInfo"}}, "text": "?), such as conversational\nunderstanding and recommendation systems, as shown in\nFigure 22. Common frameworks involve combining GNNs\nwith LLMs, merging graph data with LLMs, and exploring\nadditional innovative approaches that leverage the advantages\nbetween graph structures and language models for diverse\napplications.\n1) Conversational understanding: By combining LLM\nwith graph traversal, collaborative query rewriting [94] is\nproposed to improve the coverage of unseen interactions,\naddressing the flawed queries users pose in dialogue systems.\nFlawed queries often arise due to ambiguities or inaccura-\ncies in automatic speech recognition and natural language\nunderstanding. When integrated with graph traversal, LLM\ncan effectively navigate through the graph structure to retrieve\nrelevant information and provide more accurate responses.\n2) Response forecasting: LLM can effectively handle social\nnetworks and extract latent personas from users\u2019 profiles and\nhistorical posts. SOCIALSENSE [95] is proposed to utilize\nLLMs to extract information to predict the reactions of news\nmedia. By analyzing individuals\u2019 characteristics and behavior\npatterns within social networks, LLM can effectively predict\nthe impact of news releases and prevent unintended adverse\noutcomes.\n3) Multi-domain dialogue state tracking: LLM can learn\nfrom multi-domain dialogue history, query, and graph prompts,\nenabling it to track dialogue states and generate dialogue\ncontent, like SHEGO [96]. By incorporating information from\nvarious sources, such as previous dialogue exchanges, user\nqueries, and relevant graph prompts, LLM can understand the\nconversation\u2019s context and dynamics, allowing LLM to track\nthe current dialogue state effectively and generate appropriate\nresponses or dialogue content based on the inputs.\n4) Recommendation systems: LLMs can also help address\nissues in recommendation systems [46], as many tasks in\nrecommendation systems require learning graph structures,\nsuch as user-item interaction networks. LLMRec [44] aims", "mimetype": "text/plain", "start_char_idx": 3560, "end_char_idx": 5592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96ebaa49-9d6b-46c9-80c6-92475d954c54": {"__data__": {"id_": "96ebaa49-9d6b-46c9-80c6-92475d954c54", "embedding": null, "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9", "node_type": "4", "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a59e1228e9f1ceb6aedb8090087b7bf058c761cf05250e09032e9ebe6e2ff195", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "352c9c51-58d2-4850-a51f-63861c78d891", "node_type": "1", "metadata": {}, "hash": "2105ed9cbaf7e8f4c306c318165cabd1d77582a2a8eb76533bdf4856ecd5cb8d", "class_name": "RelatedNodeInfo"}}, "text": "to enhance recommendation systems by tackling data sparsity\nby adopting three simple yet effective LLM-based graph-\nenhancement strategies.\n5) Graph neural architecture search: LLMs can help ad-\ndress Graph Neural Architecture Search (GNAS). GNAS re-\nquires intensive human effort and rich domain knowledge\nto design search spaces and strategies. Leveraging powerful\nknowledge and reasoning capabilities, LLMs can identify\nsuitable GNN frameworks within the search space of graph\nneural network frameworks. GPT4GNAS [45] integrates GPT-\n4 into GNAS, introducing a new set of prompts for GPT-4 to\nguide it towards generating graph neural structures.\nIX. B ENCHMARK DATASETS AND EVALUATIONS\nIn this section, we summarize benchmark datasets and\nevaluation metrics for LLMs.\nA. Datasets\nThis paper summarizes the popular and new datasets, the\nLLM employed, the performed tasks, and the links to the open-\nsource code in the LLM-GGA area, as illustrated in Table V.\nBelow, we introduce commonly used benchmarks and the new\nbenchmarks proposed for the LLM-GGA field.\n1) Popular datasets: Popular benchmark refers to a graph\nbenchmark that is widely and frequently used. We have sys-\ntematically categorized these popular benchmarks according to\nsix directions, detailing which benchmarks are used for each\ndirection. Below are listed popular benchmarks commonly\nused in the six directions.\n\u2022Graph structure understanding : ogbn-arxiv [56],\nogbn-products [56], Cora [100], CiteSeer [101],\nAminer(DBLP) [57], MetaQA [102], Wikidata5M [103],\nPROTEINS [104], MUTAG [105], NCI1 [106], PTC\n[107], Foursqure [108].\n\u2022Graph learning : ogbn-arxiv [56], ogbn-products [56],\nogb-papers110M [56], ogb-citation2 [56], Cora [100],\nCiteSeer [101], Amazon-items [109], PubMed [110],\nReddit [111], CoraFull [112], Amazon [113], PROTEINS\n[104], COX2 [114], BZR [114], OAG [115]\n\u2022Graph-formed reasoning : GSM8K [116], SV AMP\n[117], FOLIO [118]\n\u2022Graph representation : Cora [100], CiteSeer [101],\nGoodreads-books [119], PubMed [110], Amazon [113],\nMIMIIC-III [120], Freebase [121], FB15K-237 [122]\n\u2022KG-based augmented retrieval : CWQ [123], WebQSP\n[124], Wikidata [103]\n\u2022Graph-LLM-based applications : depending on specific\napplications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2210, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "352c9c51-58d2-4850-a51f-63861c78d891": {"__data__": {"id_": "352c9c51-58d2-4850-a51f-63861c78d891", "embedding": null, "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9", "node_type": "4", "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a59e1228e9f1ceb6aedb8090087b7bf058c761cf05250e09032e9ebe6e2ff195", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "96ebaa49-9d6b-46c9-80c6-92475d954c54", "node_type": "1", "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "d95b8055e6ef9501a6f8e749706ffa8260ee0eb471a940089c546cd5390f3554", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "196898ed-09ee-482b-923c-9cc1ac53a6f0", "node_type": "1", "metadata": {}, "hash": "d71f8b740a6925c87173e60d5c41dcb45ee1bce1090d885aa02b7246cd8da840", "class_name": "RelatedNodeInfo"}}, "text": "2) New datasets: More than existing datasets are needed to\nexplore LLMs\u2019 ability to understand graph structures and their\npotential to solve graph problems better. As a result, many\nworks have proposed new benchmarks to advance research in\nthis field, as shown in Table VI.\n\u2022GPR [59] contains 37 particular connected graph in-\nstances generated by the Networkx toolkit, which include\nthe \u201cbull graph,\u201d \u201cwheel graph,\u201d \u201clollipop graph,\u201d etc.These generated graph instances are relatively small, with\nabout 15 nodes and 28 links on average.\n\u2022GraphTMI [87] is a graph benchmark featuring a hi-\nerarchy of graphs, associated prompts, and encoding\nmodalities. Different graph task difficulty depends on the\ndual criteria of 1) count of motifs and 2) homophily in\nthe graph, which yields a dataset of EASY , MEDIUM,\nand HARD graph problems.\n\u2022LLM4DyG [25] benchmark is to evaluate whether LLMs\nare capable of understanding spatial-temporal information\non the dynamic graph. Nine dynamic graph tasks are\ndesigned to assess LLMs\u2019 abilities considering spatial and\ntemporal dimensions.\n\u2022GraphQA [86] comprises a set of diverse fundamental\ngraph problems with more varied and realistic graph\nstructures compared to previous studies in LLM research.\nGraphQA is designed to measure the performance of\nLLMs in graph data reasoning.\n\u2022NLGraph [27] benchmark is to examine whether lan-\nguage models can reason with graphs and structures.\nNLGraph contains eight graph structure understanding\ntasks with varying algorithmic difficulties. Depending\non different network sizes, graph sparsity, and more,\nNLGraph results in easy, medium, and hard subsets in\neach graph reasoning task to enable difficulty scaling and\nfine-grained analysis.\n\u2022GraphextQA [98] benchmark is a dataset for open do-\nmain question answering. It includes paired subgraphs\nused to develop and evaluate graph language models.\nThe subgraphs are retrieved from Wikidata and contain\nreasoning paths from entities mentioned in the questions\nto the entities that the questions are asking about.\n\u2022CS-TAG [99] benchmark is a comprehensive and wide-\nranging compilation of benchmark datasets for TAGs.\nThis dataset encompasses a variety of challenging scenar-\nios, ranging from citation networks to purchase graphs.\nThe collection consists of eight distinct TAGs sourced\nfrom diverse domains.\nWe also list which directions these new benchmarks are typ-\nically used for. For graph structure understanding, GPR [59],\nGraphTMI [87], LLM4DyG [25], NLGraph [27], and CS-TAG\n[99]can be used. For graph learning, CS-TAG [99] can be used.\nFor graph-formed reasoning, GraphextQA [98] can be used.", "mimetype": "text/plain", "start_char_idx": 2211, "end_char_idx": 4840, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "196898ed-09ee-482b-923c-9cc1ac53a6f0": {"__data__": {"id_": "196898ed-09ee-482b-923c-9cc1ac53a6f0", "embedding": null, "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9", "node_type": "4", "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "a59e1228e9f1ceb6aedb8090087b7bf058c761cf05250e09032e9ebe6e2ff195", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "352c9c51-58d2-4850-a51f-63861c78d891", "node_type": "1", "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "4739702c144778befc7ede7f8e6de212c094f3486b462a56aac626915d25ce45", "class_name": "RelatedNodeInfo"}}, "text": "It includes paired subgraphs\nused to develop and evaluate graph language models.\nThe subgraphs are retrieved from Wikidata and contain\nreasoning paths from entities mentioned in the questions\nto the entities that the questions are asking about.\n\u2022CS-TAG [99] benchmark is a comprehensive and wide-\nranging compilation of benchmark datasets for TAGs.\nThis dataset encompasses a variety of challenging scenar-\nios, ranging from citation networks to purchase graphs.\nThe collection consists of eight distinct TAGs sourced\nfrom diverse domains.\nWe also list which directions these new benchmarks are typ-\nically used for. For graph structure understanding, GPR [59],\nGraphTMI [87], LLM4DyG [25], NLGraph [27], and CS-TAG\n[99]can be used. For graph learning, CS-TAG [99] can be used.\nFor graph-formed reasoning, GraphextQA [98] can be used.\nFor graph representation, GraphTMI [87], GraphQA [86], and\nCS-TAG [99] can be used. For KG-based augmented retrieval,\nGraphextQA [98] can be used.\nB. Evaluations\nEvaluating the results of different tasks related to LLM-\nGGA is also a critical issue. Thus, selecting evaluation metrics\nto assess the results is essential to determining how well LLMs\nperform their understanding of graphs and how effectively\nmodels combining graphs and LLMs perform on various tasks\nis vital. This section summarizes the metrics of different tasks,\nshown as Table VII. Note that all test results related to LLMs", "mimetype": "text/plain", "start_char_idx": 4006, "end_char_idx": 5434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2f82d87d-bd81-4350-a233-6409ce7f9607": {"__data__": {"id_": "2f82d87d-bd81-4350-a233-6409ce7f9607", "embedding": null, "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d", "node_type": "4", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3c539cf5078c29c8cf999880849757af2113e736f676a053a9394364d4a70129", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdd846e1-cd86-4f33-a2c7-c0c278433cf8", "node_type": "1", "metadata": {}, "hash": "1745ad3ea22bc6138925db0099a8b0af26e37d2795d101349df3daa97c26af1e", "class_name": "RelatedNodeInfo"}}, "text": "TABLE V: A summary of LLM-GGA methods with datasets and source links.\nMethod Dataset LLM Task Link\nInstrucGLM [78] ogbn-arxiv, Cora, PubMed Flan-T5 (instruction-finetune), Llama-\nv1-7b (LoRA)Link, Node code link\nGPT4Graph [23] ogbn-arxiv,Aminer,Wiki,MetaQA InstructGPT-3(frozen) Reasoning, Node, Graph code link\nLLMtoGraph [24] generated by GPTs GPT-3.5-turbo, GPT-4, Wizard-Vicuna-\n13B, 30B-Lazarus-Uncensored-HFMulti-hop Reasoning code link\nGraph-LLM [73] ogbn-arxiv, Cora, PubMed, ogbn-products LLaMA, text-ada-embedding-002,\nPalm-Cortex-001Node code link\nTAPE [30] ogbn-arxiv, Cora, PubMed, ogbn-products GPT-3.5 Node code link\nLLM4DyG [25] LLM4DyG GPT-3.5-turbo, Vicuna-7B, Vicuna-13B,\nLlama-2-13B, CodeLlama-2-13BGraph -\nGraphGPT [79] ogbn-arxiv, Cora, PubMed vicuna-7B-v1.1, vicuna-7B-v1.5 Node code link\nGPPT [80] Cora, Reddit, CoraFull, Amazon-CoBuy,\nogbn-arxiv etc.- Link, Node code link\nGraphPrompt [81] Flickr, PROTEINS, COX2, ENZYMES, BZR - Link, Node, Graph code link\nAll in one [82] Cora, CiteSeer, Reddit, Amazon, Pubmed - Link, Edge, Node, Graph code link\nGraph-ToolFormer [59] GPR, Cora, Pubmed, Citeseer, PROTEINS,\nMUTAG, NCI1, PTC, Twitter, FoursquareGPT-J-6B Q&A, Reasoning code link\nRGV [83] GSM8K, SV AMP, ASDiv-a GPT-3.5-turbo math problems -\nLLM-GNN [72] CORA, CITESEER, PUBMED, WIKICS,\nOGBN-ARXIV , OGBN-PRODUCTSGPT-3.5-turbo Node code link\nWhich Modality should I use [87] Cora, Citeseer, Pubmed,GraphTMI GPT-4, GPT-4V Representation, Node -\nWalkLM [38] PubMed, MIMIC-III,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1499, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdd846e1-cd86-4f33-a2c7-c0c278433cf8": {"__data__": {"id_": "bdd846e1-cd86-4f33-a2c7-c0c278433cf8", "embedding": null, "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d", "node_type": "4", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3c539cf5078c29c8cf999880849757af2113e736f676a053a9394364d4a70129", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2f82d87d-bd81-4350-a233-6409ce7f9607", "node_type": "1", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c79e9525facd13803b01eaa5cadbed6bbcda4e34057ca4de9b239f7cde8eb2a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d20a4616-c53d-4257-9898-e11e238f14c4", "node_type": "1", "metadata": {}, "hash": "bebdff24c159227eef3011b586f73917edfa7e029e46c13b858fbc02fab355b6", "class_name": "RelatedNodeInfo"}}, "text": "Reddit, Amazon, Pubmed - Link, Edge, Node, Graph code link\nGraph-ToolFormer [59] GPR, Cora, Pubmed, Citeseer, PROTEINS,\nMUTAG, NCI1, PTC, Twitter, FoursquareGPT-J-6B Q&A, Reasoning code link\nRGV [83] GSM8K, SV AMP, ASDiv-a GPT-3.5-turbo math problems -\nLLM-GNN [72] CORA, CITESEER, PUBMED, WIKICS,\nOGBN-ARXIV , OGBN-PRODUCTSGPT-3.5-turbo Node code link\nWhich Modality should I use [87] Cora, Citeseer, Pubmed,GraphTMI GPT-4, GPT-4V Representation, Node -\nWalkLM [38] PubMed, MIMIC-III, Freebase, FB15K-237 PLMs Representation, Node, Link code link\nGraphText [37] Cora, Citeseer, Texas, Wisconsin, Cornell Llama-2-7B Node code link\nTALK LIKE A GRAPH [86] GraphQA PaLM 2-XXS, PaLM 62B Node, Link -\nGraph-guided CoT [84] 2WikiMultihopQA, MusiQue, Bamboogle Llama-2-13B,Llama-2-70B multi-hop question answering -\nNLGraph [27] NLGraph TEXT-DA VINCI-003, GPT-3.5-\nTURBO, CODE-DA VINCI-002, GPT-4Link,Node,Graph,Path,Pattern code link\nCollaborative Query Rewriting [94] opportunity test sets, guardrail test set Dolly V2 Conversational Understanding -\nWHEN AND WHY [26] OGBN-ARXIV , CORA, PUBMED, OGBN-\nPRODUCT, ARXIV-2023ChatGPT Node code link\nCR [35] FOLIO, LogiQA, ProofWriter, LogicalDe-\nductionGPT-3.5-turbo, GPT-4, LLaMA-13B,\nLLaMA-65BLogic reasoning code link\nSOCIALSENSE [95] RFPN, Twitter PLMs Response Forecasting code link\nDGTL [39] Cora, PubMed, Books-History Llama-2-13B Node -\nSHEGO [96] SGD, MultiWOZ 2.1 T5-small multi-domain DST -\nGraph of Thought(GoT) [34] individual data GPT3.5(frozen) Graph-formed reasoning code link\nGLEM [31] ogbnarxiv, ogbn-products,", "mimetype": "text/plain", "start_char_idx": 1014, "end_char_idx": 2581, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d20a4616-c53d-4257-9898-e11e238f14c4": {"__data__": {"id_": "d20a4616-c53d-4257-9898-e11e238f14c4", "embedding": null, "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d", "node_type": "4", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3c539cf5078c29c8cf999880849757af2113e736f676a053a9394364d4a70129", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdd846e1-cd86-4f33-a2c7-c0c278433cf8", "node_type": "1", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "daf72b25e3760925d352dcdea465782fd8e9456621dde52c699cf4d9300223b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "096a511e-ef7c-400a-a9e8-1dbd147f5fe3", "node_type": "1", "metadata": {}, "hash": "3d236cf9d95f845b85f2896551d020d9c917e410408ff06b37223897468451fc", "class_name": "RelatedNodeInfo"}}, "text": "CORA, PUBMED, OGBN-\nPRODUCT, ARXIV-2023ChatGPT Node code link\nCR [35] FOLIO, LogiQA, ProofWriter, LogicalDe-\nductionGPT-3.5-turbo, GPT-4, LLaMA-13B,\nLLaMA-65BLogic reasoning code link\nSOCIALSENSE [95] RFPN, Twitter PLMs Response Forecasting code link\nDGTL [39] Cora, PubMed, Books-History Llama-2-13B Node -\nSHEGO [96] SGD, MultiWOZ 2.1 T5-small multi-domain DST -\nGraph of Thought(GoT) [34] individual data GPT3.5(frozen) Graph-formed reasoning code link\nGLEM [31] ogbnarxiv, ogbn-products, ogbn-papers100M PLMs Node code link\nLPNL [77] OAG T5-base Link -\nSIMTEG [71] OGBN-Arxiv, OGBN-Products, OGBL-\nCitation2PLMs Node, link code link\nLlmrec [44] Netflix, MovieLens gpt-3.5-turbo-16k Recommendation code link\nENG [75] OGB gpt-3.5-turbo Node generation -\nOFA [32] OGBN-ARXIV , CORA PLMs Node, link, graph code link\nG-prompt [33] OGBN-ARXIV , Instagram, Reddit PLMs Representation -\nBeyond Text [74] OGBN-ARXIV , CORA, PubMed GPT-3.5, GPT-4 Node, link -\nGPT4GNAS [45] OGBN-ARXIV , CORA, PubMed, Citeseer GPT-4 Graph neural architecture search -\nGraphllm [64] NLGraph Llama2-7B, Llama2-13B Link, node, graph, path, pattern code link\nG2P2 [85] Cora, Amazon PLMs Representation code link\nChatGraph [97] Gradio GPT-4V , Next-GPT Link, node, graph, application -\nGraph Agent [76] Cora, PubMed GPT-4 Link, node, graph -\nGoT* [36] AQUA-RAT, ScienceQA T5-base Graph-formed reasoning code link\nKGP [93] HotpotQA, IIRC, 2WikiMQA, MuSiQue,\nPDFTriage, RankLlama KG+LLM code link\nHead-to-Tail [88] DBpredia, Movie, Book, Academics GPT-4 KG+LLM -\nGLaM [40] DBLP,", "mimetype": "text/plain", "start_char_idx": 2090, "end_char_idx": 3638, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "096a511e-ef7c-400a-a9e8-1dbd147f5fe3": {"__data__": {"id_": "096a511e-ef7c-400a-a9e8-1dbd147f5fe3", "embedding": null, "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d", "node_type": "4", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3c539cf5078c29c8cf999880849757af2113e736f676a053a9394364d4a70129", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d20a4616-c53d-4257-9898-e11e238f14c4", "node_type": "1", "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8d38ac36ceff04c1fcccd801b54daaf73ba66eec6abeb640b5abce8600099e0a", "class_name": "RelatedNodeInfo"}}, "text": "Citeseer GPT-4 Graph neural architecture search -\nGraphllm [64] NLGraph Llama2-7B, Llama2-13B Link, node, graph, path, pattern code link\nG2P2 [85] Cora, Amazon PLMs Representation code link\nChatGraph [97] Gradio GPT-4V , Next-GPT Link, node, graph, application -\nGraph Agent [76] Cora, PubMed GPT-4 Link, node, graph -\nGoT* [36] AQUA-RAT, ScienceQA T5-base Graph-formed reasoning code link\nKGP [93] HotpotQA, IIRC, 2WikiMQA, MuSiQue,\nPDFTriage, RankLlama KG+LLM code link\nHead-to-Tail [88] DBpredia, Movie, Book, Academics GPT-4 KG+LLM -\nGLaM [40] DBLP, UMLS Llama-7B KG+LLM -\nToG [41] CWQ, WebQSP, GrailQA, QALD10-en, etc. GPT-3.5, GPT-4, Llama-2 KG+LLM code link\nAutoalign [92] DBpedia, Wikidata ChatGPT, Claude KG+LLM code link\nGNP [42] ConceptNet, UMLS, OpenBookQA, etc. FLAN-T5 xlarge (3B), xxlarge (11B) KG+LLM code link\nRoG [43] WebQSP, CWQ, Freebase LLaMA2-7B KG+LLM code link\nKGLens [91] Wikidata GPT-3.5-turbo, GPT-4, Babbage-002,\nDavinci-002, Vicuna-33b-v1.3, Xwin-\nLM-13B-V0.2, Yi-34B-ChatKG+LLM -", "mimetype": "text/plain", "start_char_idx": 3085, "end_char_idx": 4094, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ee01a3e6-62e1-4644-bb17-7fa563be1b0d": {"__data__": {"id_": "ee01a3e6-62e1-4644-bb17-7fa563be1b0d", "embedding": null, "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9", "node_type": "4", "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2db035ddd363519e8aa4a3abdf1bade2c33cbd62ffbf4ded7ee5f3a8ea13452d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2b91e14b-7672-4a8f-ba39-914b9390036d", "node_type": "1", "metadata": {}, "hash": "73b3d437832f4d6a77ee355cf8ac8f688cf8c24da8a58defbb89d36871cfb689", "class_name": "RelatedNodeInfo"}}, "text": "TABLE VI: A summary of new datasets.\nNew Benchmark Link\nGPR [59] https://github.com/jwzhanggy/Graph Toolformer/tree/main/data\nGraphTMI [87] To be released\nLLM4DyG [25] To be released\nGraphQA [86] To be released\nNLGraph [27] https://github.com/Arthur-Heng/NLGraph/tree/main/NLGraph\nGraphextQA [98] https://huggingface.co/datasets/drt/graphext-qa\nCS-TAG [99] https://github.com/sktsherlock/TAG-Benchmark\nTABLE VII: Evaluations.\nTasks Metrics\nGraph structure understanding task Accuracy, ROUGE, BLEU, Time cost, Comprehension, Correctness, Fidelity, Rectification\nComprehension\nGraph learning task Accuracy, Macro-F1, Training Time, Tuned Parameters, GPU Occupy, Mismatch Rate,\nDenial Rate, Token Limit Fraction\nGraph resoning task Accuracy, F1-score, Precision, Recall, The Latency-V olume Trade-off, Number of errors\nand cost\nGraph representation depending on downstream tasks\nKG-based augmented retrieval Accuracy, F1-score, Precision, Recall,\nGraph-LLM-based applications depending on different tasks\nin this paper are conducted using GPT-3.5 turbo or GPT-4\nturbo.\n1) Graph structure understanding task.: Several metrics are\nusually used in graph structure understanding tasks: accuracy,\nROUGE [125], BLEU [126], Time cost, comprehension, cor-\nrectness, fidelity, and rectification comprehension. Accuracy,\nROUGE, BLEU, and time cost are viral metrics. Meanwhile,\ncomprehension, correctness, fidelity, and rectification compre-\nhension are new metrics [24] used to evaluate the ability\nof LLMs to understand graphs through natural language,\nthe accuracy of solving graph problems, and the level of\nconfidence in the answers provided.\n2) Graph learning task.: For graph learning tasks, when\nevaluating a model, various metrics are considered to deter-\nmine its effectiveness, efficiency, and computational demands.\nWhen assessing the effectiveness of a model, metrics such\nas accuracy, macro-F1, mismatch rate, and denial rate [87]\nare considered. In terms of efficiency, metrics like training\ntime and tuned parameters are assessed. For computational\ncosts, metrics such as GPU occupancy and token limit fraction\nare examined. Notably, the token limit fraction indicates the\nproportion of tokens used compared to the maximum allowed\nby the model\u2019s constraints and can be formed as follows:\nT =Number of usage tokens\nToken limit constraint for the model(6)\n3) Graph reasoning task.: When it comes to graph reason-\ning tasks, two main factors that are taken into consideration\nare effectiveness and efficiency.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2509, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2b91e14b-7672-4a8f-ba39-914b9390036d": {"__data__": {"id_": "2b91e14b-7672-4a8f-ba39-914b9390036d", "embedding": null, "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9", "node_type": "4", "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2db035ddd363519e8aa4a3abdf1bade2c33cbd62ffbf4ded7ee5f3a8ea13452d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ee01a3e6-62e1-4644-bb17-7fa563be1b0d", "node_type": "1", "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c4582010f000d769089a242a58e766e047b05a633d086a8a1855893ad0d02b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55473136-e48c-47ae-bab4-5e4b96fea556", "node_type": "1", "metadata": {}, "hash": "c5abacab745ef50191ffa1c17e2c1a4f733653f1e5a2f4f58dcc87440833c740", "class_name": "RelatedNodeInfo"}}, "text": "2) Graph learning task.: For graph learning tasks, when\nevaluating a model, various metrics are considered to deter-\nmine its effectiveness, efficiency, and computational demands.\nWhen assessing the effectiveness of a model, metrics such\nas accuracy, macro-F1, mismatch rate, and denial rate [87]\nare considered. In terms of efficiency, metrics like training\ntime and tuned parameters are assessed. For computational\ncosts, metrics such as GPU occupancy and token limit fraction\nare examined. Notably, the token limit fraction indicates the\nproportion of tokens used compared to the maximum allowed\nby the model\u2019s constraints and can be formed as follows:\nT =Number of usage tokens\nToken limit constraint for the model(6)\n3) Graph reasoning task.: When it comes to graph reason-\ning tasks, two main factors that are taken into consideration\nare effectiveness and efficiency. Several metrics are used to\nassess effectiveness, including accuracy, number of errors and\ncost, F1-score, precision, and recall [127]. On the other hand,\nefficiency is evaluated through metrics such as the Latency-\nV olume Trade-off.\n4) Graph representation.: The effectiveness of graph rep-\nresentation is typically judged based on the performance of\ndownstream tasks that use this graph representation.5) Knowledge graph-based augmented retrieval.: Tasks in\nthe KG-based augmented retrieval direction typically involve\nquestion-answering tasks. Evaluation metrics commonly used\ninclude accuracy, precision, recall, F1-score, Hits@k [128],\nEM [129], MSE, and for some generative tasks, human eval-\nuation may also be utilized.\nX. F UTURE DIRECTIONS\nThe above survey of the state-of-the-art LLM-GGA research\nreveals a promising and young research field. The following\nsection discusses exciting directions for future work.\nA. More Complex Graph Problems\nMore complex graph tasks. Can LLMs solve graph al-\ngorithm problems? Existing works on traditional graph tasks\nare based on fundamental graph problems such as shortest\npath, clustering coefficient computing, maximum flow, etc.\nHowever, can LLMs address NP problems such as community\nsearch, interactive graph problems, or even NP-hard problems,\nand if so, how can they tackle them? For graph learning tasks,\ncurrent research primarily focuses on simple node, edge, and\ngraph classification. Future work can focus on more complex\ngraph learning problems, such as the diverse classification\noutcomes arising from isomorphic and heterogeneous graphs.\nMore complex graph patterns. Graphs contain various\ngraph patterns, each with its explicit definition and unique\ncharacteristics, such as stars, triangles, cliques, butterflies, and\nmore. Therefore, recognizing graph patterns and utilizing their\ncharacteristics to solve downstream tasks can be highly advan-\ntageous.", "mimetype": "text/plain", "start_char_idx": 1635, "end_char_idx": 4430, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55473136-e48c-47ae-bab4-5e4b96fea556": {"__data__": {"id_": "55473136-e48c-47ae-bab4-5e4b96fea556", "embedding": null, "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9", "node_type": "4", "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "2db035ddd363519e8aa4a3abdf1bade2c33cbd62ffbf4ded7ee5f3a8ea13452d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2b91e14b-7672-4a8f-ba39-914b9390036d", "node_type": "1", "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "c324c11dc4443cbd442719d8b2620ac4968a8269809ed324a7dffedae9c32550", "class_name": "RelatedNodeInfo"}}, "text": "Can LLMs solve graph al-\ngorithm problems? Existing works on traditional graph tasks\nare based on fundamental graph problems such as shortest\npath, clustering coefficient computing, maximum flow, etc.\nHowever, can LLMs address NP problems such as community\nsearch, interactive graph problems, or even NP-hard problems,\nand if so, how can they tackle them? For graph learning tasks,\ncurrent research primarily focuses on simple node, edge, and\ngraph classification. Future work can focus on more complex\ngraph learning problems, such as the diverse classification\noutcomes arising from isomorphic and heterogeneous graphs.\nMore complex graph patterns. Graphs contain various\ngraph patterns, each with its explicit definition and unique\ncharacteristics, such as stars, triangles, cliques, butterflies, and\nmore. Therefore, recognizing graph patterns and utilizing their\ncharacteristics to solve downstream tasks can be highly advan-\ntageous. Currently, only limited works leverage the properties\nof stars, triangles, and cliques to solve problems.\nFurthermore, understanding graph data still remains a sig-\nnificant challenge for existing LLMs, limiting their ability to\ntackle more complex graph problems. Therefore, incorporating\nLLMs into the process is a promising direction for solving\nmore complex graph problems.", "mimetype": "text/plain", "start_char_idx": 3491, "end_char_idx": 4808, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4cc23ce9-d29a-44b8-a7e7-2b12a815cdb9": {"__data__": {"id_": "4cc23ce9-d29a-44b8-a7e7-2b12a815cdb9", "embedding": null, "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56af9903-7901-4a28-91b4-5f83b247405c", "node_type": "4", "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "84944ea4498acfe6593e573de1d58a73f6c76b96221d8112a2bf26d3bb1b3024", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ed060282-fc21-41f3-a532-6e6d3d518dd1", "node_type": "1", "metadata": {}, "hash": "604fb249b35e383da1f8f2273acee5700fc52ad0035149890ba313ab3428301c", "class_name": "RelatedNodeInfo"}}, "text": "B. LLM Exploration on Diverse Graphs\nMost existing work mainly focuses on static graphs, while\nthere exists a wide range of different graphs, including\nundirected, directed, cyclic, acyclic, isomorphic, heteroge-\nneous, dynamic, etc. Different types of graphs have significant\nstructural differences, such as static graphs, dynamic graphs,\ntemporal graphs, uncertain graphs, heterogeneous graphs, etc.\nSpecifically, unlike static graphs, dynamic graphs can be\nrepresented as ordered lists or asynchronous streams of timed\nevents, capturing patterns of temporal network evolution, such\nas the addition or removal of nodes and edges. Evaluating the\nability of LLMs to understand the spatio-temporal information\nof dynamic graphs is crucial for web applications. Evaluating\nwhether LLMs can determine when nodes are connected,\nidentify which nodes are connected to a given node at a\nspecific time, and find a chronological path by combining\ntemporal and spatial information is essential to assessing\nLLMs\u2019 understanding of dynamic graphs. Future work can\nfurther explore other types of graphs, such as dynamic graphs\nand temporal graphs, address problems like maximum flow,\nand predict the evolution of graphs.\nMoreover, existing studies have conflicting views on the\nLLM graph reasoning ability, with some presenting contradic-\ntory findings. This ambiguity could be due to various factors,\nincluding dataset selection, diverse prompt engineering tech-\nniques, the range of graph reasoning tasks, and the utilization\nof different LLM models.\nC. Better LLM-GNN Pipelines\nGNNs are designed to handle structural information by\ncontinuously learning information from surrounding subgraphs\nthrough aggregation functions. On the other hand, LLMs excel\nin processing textual information, text reasoning, semantic\nunderstanding, and more. The challenge lies in leveraging both\nadvantages to enable a pipeline that can effectively handle both\nattributed and pure graphs. If GNNs and LLMs are simply\nstacked, the parameter size of GNNs is notably smaller than\nthat of LLMs. This discrepancy may result in the issue of\nvanishing gradients during training, as mentioned in [130],\nwhich can impede the iterative updating process of GNNs.\nAdditionally, GNNs need to utilize the extensive knowledge\ncontained within LLMs fully, and they cannot effectively\nextract specific knowledge tailored for specific downstream\ntasks in different graphs.\nD. Graph Foundation Model\nLLM is undoubtedly the foundational model in NLP. Can\nwe draw inspiration from LLMs to train a graph foundation\nmodel? For example, can training strategies like instruction\ntuning and DPO be applied to tasks involving graphs? The\ncurrent research has primarily introduced graph foundation\nmodels in the form of LLM-GNN pipelines and graph-aware\ntuning LLMs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2809, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ed060282-fc21-41f3-a532-6e6d3d518dd1": {"__data__": {"id_": "ed060282-fc21-41f3-a532-6e6d3d518dd1", "embedding": null, "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56af9903-7901-4a28-91b4-5f83b247405c", "node_type": "4", "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "84944ea4498acfe6593e573de1d58a73f6c76b96221d8112a2bf26d3bb1b3024", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cc23ce9-d29a-44b8-a7e7-2b12a815cdb9", "node_type": "1", "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dbf94fe636e4e4caba4cd5fc5edc735b33eaa310504669c0d4c0334e8a261b6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0164bfc-b3c2-49ee-a7e8-e7a4f2bb4b5b", "node_type": "1", "metadata": {}, "hash": "6e6fb172a7a92888b07e403fdb39b55c33a2d9fdc989a2a49ad6584e3f62ed7c", "class_name": "RelatedNodeInfo"}}, "text": "If GNNs and LLMs are simply\nstacked, the parameter size of GNNs is notably smaller than\nthat of LLMs. This discrepancy may result in the issue of\nvanishing gradients during training, as mentioned in [130],\nwhich can impede the iterative updating process of GNNs.\nAdditionally, GNNs need to utilize the extensive knowledge\ncontained within LLMs fully, and they cannot effectively\nextract specific knowledge tailored for specific downstream\ntasks in different graphs.\nD. Graph Foundation Model\nLLM is undoubtedly the foundational model in NLP. Can\nwe draw inspiration from LLMs to train a graph foundation\nmodel? For example, can training strategies like instruction\ntuning and DPO be applied to tasks involving graphs? The\ncurrent research has primarily introduced graph foundation\nmodels in the form of LLM-GNN pipelines and graph-aware\ntuning LLMs. Future endeavors can focus on exploring graph\nfoundation models better suited for tasks involving graphs.E. Better Graph Prompts\nMost graph prompts are currently designed based on GNNs,\nwith only a few works focusing on LLMs. Graph prompts for\nLLMs have yet to be sufficiently explored.\nGraph Prompt for GNNs. The typical approach uses\nsimple concatenation, addition, or dot product operations with\ntrainable parameters. Some existing works have considered\nmore complex fusion methods, such as [82], which assumes\nthe structural features of graph prompts. However, compared\nto the combination of prompts and pretexts, the variety of\ngraph prompts and pre-graphs is still in the exploratory stage.\nGraph-enhanced Prompts for LLMs. Relying solely on\nmanual prompts and self-prompting has limited capabilities\nin improving model performance, as they only explore the\nexisting abilities of LLM. As shown in Section III-C, LLMs\ncan be trained as agents to utilize tools for graph tasks that are\nhard to solve, like API call prompt [59]. GoT [130] is also\na graph reasoning paradigm that enables LLMs to provide\ncorrect answers. Future work based on the graph reasoning\nparadigm can consider cost-effective approaches for GoT,\nsuch as pruning and tricks to reduce algorithm complexity.\nIn the future, it would be beneficial to explore simpler GoT\nparadigms that can improve the effectiveness of LLMs.\nF . Modal Alignment\nModal alignment refers to the alignment between two\nmodalities: text and graph. The input for LLMs is typically\nsequential data, often text. Graph and text are two different\nmodalities, and studying the alignment between these two\nmodalities for LLMs involves finding a shared mapping feature\nspace for graphs and text.", "mimetype": "text/plain", "start_char_idx": 1960, "end_char_idx": 4544, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c0164bfc-b3c2-49ee-a7e8-e7a4f2bb4b5b": {"__data__": {"id_": "c0164bfc-b3c2-49ee-a7e8-e7a4f2bb4b5b", "embedding": null, "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56af9903-7901-4a28-91b4-5f83b247405c", "node_type": "4", "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "84944ea4498acfe6593e573de1d58a73f6c76b96221d8112a2bf26d3bb1b3024", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ed060282-fc21-41f3-a532-6e6d3d518dd1", "node_type": "1", "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dda6fe4608bc059b1f344995587983efb97090df4923b9d526b734456e35ae1a", "class_name": "RelatedNodeInfo"}}, "text": "As shown in Section III-C, LLMs\ncan be trained as agents to utilize tools for graph tasks that are\nhard to solve, like API call prompt [59]. GoT [130] is also\na graph reasoning paradigm that enables LLMs to provide\ncorrect answers. Future work based on the graph reasoning\nparadigm can consider cost-effective approaches for GoT,\nsuch as pruning and tricks to reduce algorithm complexity.\nIn the future, it would be beneficial to explore simpler GoT\nparadigms that can improve the effectiveness of LLMs.\nF . Modal Alignment\nModal alignment refers to the alignment between two\nmodalities: text and graph. The input for LLMs is typically\nsequential data, often text. Graph and text are two different\nmodalities, and studying the alignment between these two\nmodalities for LLMs involves finding a shared mapping feature\nspace for graphs and text. The shared mapping space allows\nLLMs to understand graph data similarly to how they know\ntextual information if they comprehend text.\nG. Explainabilily\nGNNs are currently widely used for solving complex graph\nproblems. However, they need more interpretability, which\nhinders their practical application. On the other hand, LLMs\npossess reasoning capabilities and have succeeded in various\nnatural language processing tasks. The combination of LLMs\nand GNNs has the potential to offer a more transparent ap-\nproach to solving graph problems by leveraging the reasoning\nabilities of LLMs. If the combination of LLMs and GNNs\nis interpretable, it can be utilized for various tasks., including\nrecommendation systems, drug discovery, and fraud detection.\nThis combination can lead to the development of more reliable\nand efficient decision-making systems across various domains.\nH. Efficiency on Large-scale Graphs\nDue to the limited input length of LLM, the graph sizes\ninputted through prompts typically consist of dozens of nodes.\nHowever, for large graphs with tens of thousands of nodes and\nedges, how can LLMs with limited input length solve such\nlarge graphs? A larger input window is required in the case of\nattributed graphs, where both node and edge attributes need to\nbe considered along with the graph structure. How does LLM", "mimetype": "text/plain", "start_char_idx": 3701, "end_char_idx": 5878, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6a1cbdc7-4f67-4558-a2c6-99fc7bbc40f5": {"__data__": {"id_": "6a1cbdc7-4f67-4558-a2c6-99fc7bbc40f5", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5543203c-33c9-4995-83a3-18593cdef42c", "node_type": "1", "metadata": {}, "hash": "5af99134b8d9feedb452369f36345ea322416107e44bc8ad3aaaf121f35ebc5e", "class_name": "RelatedNodeInfo"}}, "text": "address this case? There are currently few effective methods\nto enable LLM to handle them.\nXI. C ONCLUSIONS\nLLM-GGA has emerged as a promising field that has\ngarnered significant attention from researchers. This paper\nintroduces a comprehensive structural taxonomy based on\nrecent research, which classifies LLM-GGA research into three\nmain directions: LLM-GQP, LLM-GIL, and graph-LLM-based\napplications. LLM-GQP encompasses graph understanding\nand KG-based augmented retrieval, while LLM-GIL involves\ngraph learning, graph-formed reasoning, and graph represen-\ntation. The motivation, challenges, and mainstream methods\nof each direction are thoroughly examined.\nFor the six mentioned directions, a comparison of various\nmethods was conducted to explore their potential in each\narea. It is observed that LLM shows preliminary capabilities\nin structural understanding, addressing issues like maximum\nflow and bipartite graph matching over small graphs. However,\nit is susceptible to factors such as node degree and graph\ndensity, leading to potential misjudgments in graph connec-\ntivity. Additionally, LLM proves beneficial for graph learning\ntasks due to its strong semantic understanding and reasoning\nabilities, coupled with learning from extensive corpora, which\ncan provide external knowledge to GNNs and aid in semantic\ninformation comprehension, learning, and reasoning. Thanks\nto LLM\u2019s semantic understanding capabilities, graph represen-\ntation can achieve deeper semantic embeddings. The discus-\nsion also delves into KG-based augmented retrieval to enhance\nLLMs retrieval and factual knowledge-answering abilities. The\npaper summarizes over 40 datasets, evaluation metrics for six\ndirections, and source code for over 30 mainstream methods in\nthese directions. It highlights the existing challenges in current\nmethods and proposes future directions to guide and motivate\nfurther research in the LLM-GGA field.\nREFERENCES\n[1] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester,\nN. Du, A. M. Dai, and Q. V . Le, \u201cFinetuned Language Models\nAre Zero-Shot Learners,\u201d Feb. 2022, arXiv:2109.01652 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2109.01652\n[2] B. Peng, C. Li, P. He, M. Galley, and J. Gao, \u201cInstruction Tuning\nwith GPT-4,\u201d Apr. 2023, arXiv:2304.03277 [cs]. [Online].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2296, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5543203c-33c9-4995-83a3-18593cdef42c": {"__data__": {"id_": "5543203c-33c9-4995-83a3-18593cdef42c", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a1cbdc7-4f67-4558-a2c6-99fc7bbc40f5", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "882a2b827ad4baa23630e1abd5f281dbdb0513ae4c4772d04e171023432372c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9aac336d-7b3f-4489-a2c0-9081dc0ca110", "node_type": "1", "metadata": {}, "hash": "57d49b36f5183bea2dbed0964408423dd9d68e1e50c264c9e8019986e9021f27", "class_name": "RelatedNodeInfo"}}, "text": "It highlights the existing challenges in current\nmethods and proposes future directions to guide and motivate\nfurther research in the LLM-GGA field.\nREFERENCES\n[1] J. Wei, M. Bosma, V . Y . Zhao, K. Guu, A. W. Yu, B. Lester,\nN. Du, A. M. Dai, and Q. V . Le, \u201cFinetuned Language Models\nAre Zero-Shot Learners,\u201d Feb. 2022, arXiv:2109.01652 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2109.01652\n[2] B. Peng, C. Li, P. He, M. Galley, and J. Gao, \u201cInstruction Tuning\nwith GPT-4,\u201d Apr. 2023, arXiv:2304.03277 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2304.03277\n[3] R. Rafailov, A. Sharma, E. Mitchell, C. D. Manning, S. Ermon,\nand C. Finn, \u201cDirect preference optimization: Your language\nmodel is secretly a reward model,\u201d in Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.\n[Online]. Available: http://papers.nips.cc/paper files/paper/2023/hash/\na85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html\n[4] L. Sun, Y . Huang, H. Wang, S. Wu, Q. Zhang, Y . Li, C. Gao, Y . Huang,\nW. Lyu, Y . Zhang, X. Li, Z. Liu, Y . Liu, Y .", "mimetype": "text/plain", "start_char_idx": 1773, "end_char_idx": 3017, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9aac336d-7b3f-4489-a2c0-9081dc0ca110": {"__data__": {"id_": "9aac336d-7b3f-4489-a2c0-9081dc0ca110", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5543203c-33c9-4995-83a3-18593cdef42c", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "34ef8fed5b934c685ee1781b8e8a12cc066f06478115f26ba8e58254dacce8d8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b3002362-6364-43f5-93e7-50920b1f4fc0", "node_type": "1", "metadata": {}, "hash": "a20b0926e641373b3a84ee27151693f80e12e9967bbaa7ff4f9f2267e287d506", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available: http://papers.nips.cc/paper files/paper/2023/hash/\na85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html\n[4] L. Sun, Y . Huang, H. Wang, S. Wu, Q. Zhang, Y . Li, C. Gao, Y . Huang,\nW. Lyu, Y . Zhang, X. Li, Z. Liu, Y . Liu, Y . Wang, Z. Zhang, B. Vidgen,\nB. Kailkhura, C. Xiong, C. Xiao, C. Li, E. Xing, F. Huang, H. Liu,\nH. Ji, H. Wang, H. Zhang, H. Yao, M. Kellis, M. Zitnik, M. Jiang,\nM. Bansal, J. Zou, J. Pei, J. Liu, J. Gao, J. Han, J. Zhao, J. Tang,\nJ. Wang, J. Vanschoren, J. Mitchell, K. Shu, K. Xu, K.-W. Chang,\nL. He, L. Huang, M. Backes, N. Z. Gong, P. S. Yu, P.-Y . Chen, Q. Gu,\nR. Xu, R. Ying, S. Ji, S. Jana, T. Chen, T. Liu, T. Zhou, W. Wang,\nX. Li, X. Zhang, X. Wang, X. Xie, X. Chen, X. Wang, Y . Liu,Y . Ye, Y . Cao, Y . Chen, and Y . Zhao, \u201cTrustLLM: Trustworthiness in\nLarge Language Models,\u201d Mar. 2024, arXiv:2401.05561 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2401.05561\n[5] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y . Babaei,\nN. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher,\nC. Canton-Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes,\nJ. Fu, W. Fu, B. Fuller, C. Gao, V . Goswami, N. Goyal, A. Hartshorn,\nS. Hosseini, R. Hou, H. Inan, M. Kardas, V .", "mimetype": "text/plain", "start_char_idx": 2765, "end_char_idx": 4015, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b3002362-6364-43f5-93e7-50920b1f4fc0": {"__data__": {"id_": "b3002362-6364-43f5-93e7-50920b1f4fc0", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9aac336d-7b3f-4489-a2c0-9081dc0ca110", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "920d8a90c02e21e7a454ee961d06bb7cf1cb275de934cd618877837476d21032", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b961c072-d993-40c0-a369-45a6efc6eeed", "node_type": "1", "metadata": {}, "hash": "b6e45b3a7a0599670dcbcb363231a2c4638a69b33bddd092a195d6373e902488", "class_name": "RelatedNodeInfo"}}, "text": "2024, arXiv:2401.05561 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2401.05561\n[5] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y . Babaei,\nN. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, D. Bikel, L. Blecher,\nC. Canton-Ferrer, M. Chen, G. Cucurull, D. Esiobu, J. Fernandes,\nJ. Fu, W. Fu, B. Fuller, C. Gao, V . Goswami, N. Goyal, A. Hartshorn,\nS. Hosseini, R. Hou, H. Inan, M. Kardas, V . Kerkez, M. Khabsa,\nI. Kloumann, A. Korenev, P. S. Koura, M. Lachaux, T. Lavril, J. Lee,\nD. Liskovich, Y . Lu, Y . Mao, X. Martinet, T. Mihaylov, P. Mishra,\nI. Molybog, Y . Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi,\nA. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan,\nB. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov,\nY . Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic,\nS. Edunov, and T. Scialom, \u201cLlama 2: Open foundation and fine-tuned\nchat models,\u201d CoRR , vol. abs/2307.09288, 2023. [Online].", "mimetype": "text/plain", "start_char_idx": 3609, "end_char_idx": 4570, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b961c072-d993-40c0-a369-45a6efc6eeed": {"__data__": {"id_": "b961c072-d993-40c0-a369-45a6efc6eeed", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b3002362-6364-43f5-93e7-50920b1f4fc0", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "cecb34116dcdefee144dfffaf2d454423b91f4e0fefc903a1560e3478495b7ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949", "node_type": "1", "metadata": {}, "hash": "2b920cbadd8ca2a90e5e1bcceab7cde5415f99fb336a7faaee0b9b9af7186573", "class_name": "RelatedNodeInfo"}}, "text": "Mao, X. Martinet, T. Mihaylov, P. Mishra,\nI. Molybog, Y . Nie, A. Poulton, J. Reizenstein, R. Rungta, K. Saladi,\nA. Schelten, R. Silva, E. M. Smith, R. Subramanian, X. E. Tan,\nB. Tang, R. Taylor, A. Williams, J. X. Kuan, P. Xu, Z. Yan, I. Zarov,\nY . Zhang, A. Fan, M. Kambadur, S. Narang, A. Rodriguez, R. Stojnic,\nS. Edunov, and T. Scialom, \u201cLlama 2: Open foundation and fine-tuned\nchat models,\u201d CoRR , vol. abs/2307.09288, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2307.09288\n[6] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright,\nP. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman,\nJ. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder,\nP. F. Christiano, J. Leike, and R. Lowe, \u201cTraining language\nmodels to follow instructions with human feedback,\u201d in Advances in\nNeural Information Processing Systems 35: Annual Conference on\nNeural Information Processing Systems 2022, NeurIPS 2022, New\nOrleans, LA, USA, November 28 - December 9, 2022 , S. Koyejo,\nS. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds.,\n2022. [Online]. Available: http://papers.nips.cc/paper files/paper/2022/\nhash/b1efde53be364a73914f58805a001731-Abstract-Conference.html\n[7] Y . Zhuang, Y .", "mimetype": "text/plain", "start_char_idx": 4130, "end_char_idx": 5350, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949": {"__data__": {"id_": "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b961c072-d993-40c0-a369-45a6efc6eeed", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "e45bb49ecf49dddab3997d15af943434e69d99a0991cd57d4cfb1bc378f8d240", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8acc20fe-d363-4276-af2a-3d44ecb8f466", "node_type": "1", "metadata": {}, "hash": "38686e2088a443072c769787b5d98d8bb1230679548c6e00d5de9d821b792246", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available: http://papers.nips.cc/paper files/paper/2022/\nhash/b1efde53be364a73914f58805a001731-Abstract-Conference.html\n[7] Y . Zhuang, Y . Yu, K. Wang, H. Sun, and C. Zhang, \u201cToolqa:\nA dataset for LLM question answering with external tools,\u201d in\nAdvances in Neural Information Processing Systems 36: Annual\nConference on Neural Information Processing Systems 2023, NeurIPS\n2023, New Orleans, LA, USA, December 10 - 16, 2023 , A. Oh,\nT. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine,\nEds., 2023. [Online]. Available: http://papers.nips.cc/paper files/paper/\n2023/hash/9cb2a7495900f8b602cb10159246a016-Abstract-Datasets\nand Benchmarks.html\n[8] Z. Li, S. Fan, Y . Gu, X. Li, Z. Duan, B. Dong, N. Liu, and J. Wang,\n\u201cFlexkbqa: A flexible llm-powered framework for few-shot knowledge\nbase question answering,\u201d in Proceedings of the AAAI Conference on\nArtificial Intelligence , vol. 38, no. 17, 2024, pp. 18 608\u201318 616.\n[9] B. Zhang, B. Haddow, and A. Birch, \u201cPrompting large language model\nfor machine translation: A case study,\u201d in International Conference on\nMachine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii,\nUSA, ser. Proceedings of Machine Learning Research, A. Krause,\nE. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,\nEds., vol. 202. PMLR, 2023, pp. 41 092\u201341 110. [Online]. Available:\nhttps://proceedings.mlr.press/v202/zhang23m.html\n[10] J. Liu, C. S. Xia, Y . Wang, and L. Zhang, \u201cIs your code\ngenerated by chatgpt really correct?", "mimetype": "text/plain", "start_char_idx": 5201, "end_char_idx": 6685, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8acc20fe-d363-4276-af2a-3d44ecb8f466": {"__data__": {"id_": "8acc20fe-d363-4276-af2a-3d44ecb8f466", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dc12391f0c62a3d2dec4f5325d4cbf6d46d424d7be1209ae00a6bd6ff20e44a6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6a2ec6a2-9e40-44fc-964d-5aaaf09a2282", "node_type": "1", "metadata": {}, "hash": "f3b7b077147c3523f71e38602c5a934f46dc1e84072347be6d74de7987dafb69", "class_name": "RelatedNodeInfo"}}, "text": "18 608\u201318 616.\n[9] B. Zhang, B. Haddow, and A. Birch, \u201cPrompting large language model\nfor machine translation: A case study,\u201d in International Conference on\nMachine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii,\nUSA, ser. Proceedings of Machine Learning Research, A. Krause,\nE. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,\nEds., vol. 202. PMLR, 2023, pp. 41 092\u201341 110. [Online]. Available:\nhttps://proceedings.mlr.press/v202/zhang23m.html\n[10] J. Liu, C. S. Xia, Y . Wang, and L. Zhang, \u201cIs your code\ngenerated by chatgpt really correct? rigorous evaluation of large\nlanguage models for code generation,\u201d in Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.\n[Online]. Available: http://papers.nips.cc/paper files/paper/2023/hash/\n43e9d647ccd3e4b7b5baab53f0368686-Abstract-Conference.html\n[11] A. Ni, S. Iyer, D. Radev, V . Stoyanov, W. Yih, S. I. Wang,\nand X. V . Lin, \u201cLEVER: learning to verify language-to-code\ngeneration with execution,\u201d in International Conference on Machine\nLearning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA ,\nser. Proceedings of Machine Learning Research, A. Krause,\nE. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,\nEds., vol. 202. PMLR, 2023, pp. 26 106\u201326 128. [Online]. Available:\nhttps://proceedings.mlr.press/v202/ni23b.html\n[12] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Gallagher, and\nT. Eliassi-Rad, \u201cCollective Classification in Network Data,\u201d AI\nMagazine , vol. 29, no. 3, pp. 93\u2013106, Sep. 2008. [Online].", "mimetype": "text/plain", "start_char_idx": 6121, "end_char_idx": 7825, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6a2ec6a2-9e40-44fc-964d-5aaaf09a2282": {"__data__": {"id_": "6a2ec6a2-9e40-44fc-964d-5aaaf09a2282", "embedding": null, "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9abf7f28-c822-46b6-88c9-199f460b10fe", "node_type": "4", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "94541d8f1ceb3be81e19e3c1f49c63525bcf5c05d84b6b694909fdb7e85a9bf4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8acc20fe-d363-4276-af2a-3d44ecb8f466", "node_type": "1", "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dfc5f2d99f1746b946e0865a6378f835bb08facd37b5de5cda9442611fe36008", "class_name": "RelatedNodeInfo"}}, "text": "Proceedings of Machine Learning Research, A. Krause,\nE. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett,\nEds., vol. 202. PMLR, 2023, pp. 26 106\u201326 128. [Online]. Available:\nhttps://proceedings.mlr.press/v202/ni23b.html\n[12] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Gallagher, and\nT. Eliassi-Rad, \u201cCollective Classification in Network Data,\u201d AI\nMagazine , vol. 29, no. 3, pp. 93\u2013106, Sep. 2008. [Online]. Available:\nhttps://onlinelibrary.wiley.com/doi/10.1609/aimag.v29i3.2157\n[13] W. L. Hamilton, Z. Ying, and J. Leskovec, \u201cInductive representation\nlearning on large graphs,\u201d in Advances in Neural Information\nProcessing Systems 30: Annual Conference on Neural Information\nProcessing Systems 2017, December 4-9, 2017, Long Beach, CA,\nUSA, I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach,", "mimetype": "text/plain", "start_char_idx": 7406, "end_char_idx": 8212, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "87a4b8a4-31cc-46d3-908d-f100b2442ed8": {"__data__": {"id_": "87a4b8a4-31cc-46d3-908d-f100b2442ed8", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0301fa88-a83b-4f56-aa8b-48c084c0fa77", "node_type": "1", "metadata": {}, "hash": "caa917b88a541d7731b47bc3afda70e1749d3fc67184b12312a7e93c42e2332f", "class_name": "RelatedNodeInfo"}}, "text": "R. Fergus, S. V . N. Vishwanathan, and R. Garnett, Eds., 2017, pp.\n1024\u20131034. [Online]. Available: https://proceedings.neurips.cc/paper/\n2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html\n[14] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S.\nPappu, K. Leswing, and V . Pande, \u201cMoleculenet: a benchmark for\nmolecular machine learning,\u201d Chemical science , vol. 9, no. 2, pp. 513\u2013\n530, 2018.\n[15] A. Broder, R. Kumar, F. Maghoul, P. Raghavan, S. Rajagopalan,\nR. Stata, A. Tomkins, and J. Wiener, \u201cGraph structure in the\nWeb,\u201d Computer Networks , vol. 33, no. 1-6, pp. 309\u2013320, Jun.\n2000. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/\nS1389128600000839\n[16] T. N. Kipf and M. Welling, \u201cSemi-supervised classification with graph\nconvolutional networks,\u201d in 5th International Conference on Learning\nRepresentations, ICLR 2017, Toulon, France, April 24-26, 2017,\nConference Track Proceedings . OpenReview.net, 2017. [Online].\nAvailable: https://openreview.net/forum?id=SJU4ayYgl\n[17] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Li `o,\nand Y . Bengio, \u201cGraph attention networks,\u201d in 6th International\nConference on Learning Representations, ICLR 2018, Vancouver, BC,\nCanada, April 30 - May 3, 2018, Conference Track Proceedings .\nOpenReview.net, 2018. [Online]. Available: https://openreview.net/\nforum?id=rJXMpikCZ\n[18] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,\n\u201cNeural message passing for quantum chemistry,\u201d in Proceedings\nof the 34th International Conference on Machine Learning, ICML\n2017, Sydney, NSW, Australia, 6-11 August 2017 , ser.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1617, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0301fa88-a83b-4f56-aa8b-48c084c0fa77": {"__data__": {"id_": "0301fa88-a83b-4f56-aa8b-48c084c0fa77", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "87a4b8a4-31cc-46d3-908d-f100b2442ed8", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "aa46721d2ca3a9609b6e46d637d62d7ac5b55e8b504bab76eb9f5e838ebae450", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9aa86cb5-8043-4dbe-84e2-7686b7fef05d", "node_type": "1", "metadata": {}, "hash": "4c1eb1980fbf049192449667164720e6c3b97024ed930ffc73450eb0126d3a2c", "class_name": "RelatedNodeInfo"}}, "text": "Bengio, \u201cGraph attention networks,\u201d in 6th International\nConference on Learning Representations, ICLR 2018, Vancouver, BC,\nCanada, April 30 - May 3, 2018, Conference Track Proceedings .\nOpenReview.net, 2018. [Online]. Available: https://openreview.net/\nforum?id=rJXMpikCZ\n[18] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,\n\u201cNeural message passing for quantum chemistry,\u201d in Proceedings\nof the 34th International Conference on Machine Learning, ICML\n2017, Sydney, NSW, Australia, 6-11 August 2017 , ser. Proceedings\nof Machine Learning Research, D. Precup and Y . W. Teh,\nEds., vol. 70. PMLR, 2017, pp. 1263\u20131272. [Online]. Available:\nhttp://proceedings.mlr.press/v70/gilmer17a.html\n[19] Y . Hong, J. W. Lam, and B. Z. Tang, \u201cAggregation-induced emission:\nphenomenon, mechanism and applications,\u201d Chemical communications ,\nno. 29, pp. 4332\u20134353, 2009.\n[20] W. Cong, M. Ramezani, and M. Mahdavi, \u201cOn provable benefits\nof depth in training graph convolutional networks,\u201d in Advances\nin Neural Information Processing Systems 34: Annual Conference\non Neural Information Processing Systems 2021, NeurIPS 2021,\nDecember 6-14, 2021, virtual , M. Ranzato, A. Beygelzimer, Y . N.\nDauphin, P. Liang, and J. W. Vaughan, Eds., 2021, pp. 9936\u2013\n9949. [Online]. Available: https://proceedings.neurips.cc/paper/2021/\nhash/524265e8b942930fbbe8a5d979d29205-Abstract.html\n[21] S. Fan, X. Wang, C. Shi, P. Cui, and B. Wang, \u201cGeneralizing Graph\nNeural Networks on Out-of-Distribution Graphs,\u201d IEEE Transactions\non Pattern Analysis and Machine Intelligence , vol. 46, no. 1, pp.\n322\u2013337, Jan. 2024. [Online]. Available: https://ieeexplore.ieee.org/\ndocument/10268633/\n[22] J. Liu, Z. Shen, Y .", "mimetype": "text/plain", "start_char_idx": 1091, "end_char_idx": 2785, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9aa86cb5-8043-4dbe-84e2-7686b7fef05d": {"__data__": {"id_": "9aa86cb5-8043-4dbe-84e2-7686b7fef05d", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0301fa88-a83b-4f56-aa8b-48c084c0fa77", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "dd92d32062b1ce9a721b02bb9a48b749d5865518b7f2e3c71b95babc2df784ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b46e3fd-4a3b-49a9-a814-b5db393236e4", "node_type": "1", "metadata": {}, "hash": "071e4fb58565bc0202572529c40817ae345e9401ae4e781290ed17a58586e94b", "class_name": "RelatedNodeInfo"}}, "text": "N.\nDauphin, P. Liang, and J. W. Vaughan, Eds., 2021, pp. 9936\u2013\n9949. [Online]. Available: https://proceedings.neurips.cc/paper/2021/\nhash/524265e8b942930fbbe8a5d979d29205-Abstract.html\n[21] S. Fan, X. Wang, C. Shi, P. Cui, and B. Wang, \u201cGeneralizing Graph\nNeural Networks on Out-of-Distribution Graphs,\u201d IEEE Transactions\non Pattern Analysis and Machine Intelligence , vol. 46, no. 1, pp.\n322\u2013337, Jan. 2024. [Online]. Available: https://ieeexplore.ieee.org/\ndocument/10268633/\n[22] J. Liu, Z. Shen, Y . He, X. Zhang, R. Xu, H. Yu, and P. Cui,\n\u201cTowards Out-Of-Distribution Generalization: A Survey,\u201d Jul. 2023,\narXiv:2108.13624 [cs]. [Online]. Available: http://arxiv.org/abs/2108.\n13624\n[23] J. Guo, L. Du, H. Liu, M. Zhou, X. He, and S. Han, \u201cGPT4Graph:\nCan Large Language Models Understand Graph Structured Data ? An\nEmpirical Evaluation and Benchmarking,\u201d Jul. 2023, arXiv:2305.15066\n[cs]. [Online]. Available: http://arxiv.org/abs/2305.15066\n[24] C. Liu and B. Wu, \u201cEvaluating Large Language Models on\nGraphs: Performance Insights and Comparative Analysis,\u201d Sep. 2023,\narXiv:2308.11224 [cs]. [Online]. Available: http://arxiv.org/abs/2308.\n11224\n[25] Z. Zhang, X. Wang, Z. Zhang, H. Li, Y . Qin, and W. Zhu,\n\u201cLLM4DyG: Can Large Language Models Solve Spatial-Temporal\nProblems on Dynamic Graphs?\u201d Mar. 2024, arXiv:2310.17110 [cs].\n[Online]. Available: http://arxiv.org/abs/2310.17110\n[26] J. Huang, X. Zhang, Q. Mei, and J. Ma, \u201cCan llms effectively\nleverage graph structural information: When and why,\u201d CoRR , vol.\nabs/2309.16595, 2023. [Online].", "mimetype": "text/plain", "start_char_idx": 2282, "end_char_idx": 3833, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b46e3fd-4a3b-49a9-a814-b5db393236e4": {"__data__": {"id_": "0b46e3fd-4a3b-49a9-a814-b5db393236e4", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9aa86cb5-8043-4dbe-84e2-7686b7fef05d", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "30bd912b3ffae99402ae856cc7a931563da02b980dff12a1a85b14ebcfa4cb97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ac3ae97-0054-4981-bd29-78503ad95039", "node_type": "1", "metadata": {}, "hash": "f167e8c722fc07be5d13e1b6c56d3b2b7a2e66b66d335cebb13f6d6029617c51", "class_name": "RelatedNodeInfo"}}, "text": "2023,\narXiv:2308.11224 [cs]. [Online]. Available: http://arxiv.org/abs/2308.\n11224\n[25] Z. Zhang, X. Wang, Z. Zhang, H. Li, Y . Qin, and W. Zhu,\n\u201cLLM4DyG: Can Large Language Models Solve Spatial-Temporal\nProblems on Dynamic Graphs?\u201d Mar. 2024, arXiv:2310.17110 [cs].\n[Online]. Available: http://arxiv.org/abs/2310.17110\n[26] J. Huang, X. Zhang, Q. Mei, and J. Ma, \u201cCan llms effectively\nleverage graph structural information: When and why,\u201d CoRR , vol.\nabs/2309.16595, 2023. [Online]. Available: https://doi.org/10.48550/\narXiv.2309.16595\n[27] H. Wang, S. Feng, T. He, Z. Tan, X. Han, and Y . Tsvetkov, \u201cCan\nLanguage Models Solve Graph Problems in Natural Language?\u201d Jan.\n2024, arXiv:2305.10037 [cs]. [Online]. Available: http://arxiv.org/abs/\n2305.10037\n[28] Q. Dong, L. Dong, K. Xu, G. Zhou, Y . Hao, Z. Sui, and\nF. Wei, \u201cLarge Language Model for Science: A Study on P\nvs. NP,\u201d Sep. 2023, arXiv:2309.05689 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2309.05689[29] L. Fan, W. Hua, L. Li, H. Ling, and Y . Zhang, \u201cNPHardEval:\nDynamic Benchmark on Reasoning Ability of Large Language Models\nvia Complexity Classes,\u201d Feb. 2024, arXiv:2312.14890 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2312.14890\n[30] X. He, X. Bresson, T. Laurent, A. Perold, Y . LeCun, and\nB. Hooi, \u201cHarnessing Explanations: LLM-to-LM Interpreter for\nEnhanced Text-Attributed Graph Representation Learning,\u201d Mar. 2024,\narXiv:2305.19523 [cs]. [Online]. Available: http://arxiv.org/abs/2305.", "mimetype": "text/plain", "start_char_idx": 3350, "end_char_idx": 4817, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ac3ae97-0054-4981-bd29-78503ad95039": {"__data__": {"id_": "3ac3ae97-0054-4981-bd29-78503ad95039", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0b46e3fd-4a3b-49a9-a814-b5db393236e4", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "806b50d6eb9da6c9de1dc3f9dacc7041eca932c60a0f4bdeb37aaafcd7832ee8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f359d3b-227c-48cc-9d26-cc2b10750cca", "node_type": "1", "metadata": {}, "hash": "2fd53d917a4747dbd07602c649592ed90a53ba78065448396f2eb42e144aeac4", "class_name": "RelatedNodeInfo"}}, "text": "Available:\nhttp://arxiv.org/abs/2309.05689[29] L. Fan, W. Hua, L. Li, H. Ling, and Y . Zhang, \u201cNPHardEval:\nDynamic Benchmark on Reasoning Ability of Large Language Models\nvia Complexity Classes,\u201d Feb. 2024, arXiv:2312.14890 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2312.14890\n[30] X. He, X. Bresson, T. Laurent, A. Perold, Y . LeCun, and\nB. Hooi, \u201cHarnessing Explanations: LLM-to-LM Interpreter for\nEnhanced Text-Attributed Graph Representation Learning,\u201d Mar. 2024,\narXiv:2305.19523 [cs]. [Online]. Available: http://arxiv.org/abs/2305.\n19523\n[31] J. Zhao, M. Qu, C. Li, H. Yan, Q. Liu, R. Li, X. Xie, and J. Tang,\n\u201cLearning on Large-scale Text-attributed Graphs via Variational\nInference,\u201d Mar. 2023, arXiv:2210.14709 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2210.14709\n[32] H. Liu, J. Feng, L. Kong, N. Liang, D. Tao, Y . Chen, and\nM. Zhang, \u201cOne for All: Towards Training One Graph Model for\nAll Classification Tasks,\u201d Dec. 2023, arXiv:2310.00149 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2310.00149\n[33] X. Huang, K. Han, D. Bao, Q. Tao, Z. Zhang, Y . Yang, and Q. Zhu,\n\u201cPrompt-based Node Feature Extractor for Few-shot Learning on\nText-Attributed Graphs,\u201d Sep. 2023, arXiv:2309.02848 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2309.02848\n[34] M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, M. Podstawski,\nL. Gianinazzi, J. Gajda, T. Lehmann, H. Niewiadomski, P. Nyczyk,\nand T. Hoefler, \u201cGraph of Thoughts: Solving Elaborate Problems with\nLarge Language Models,\u201d Proceedings of the AAAI Conference on\nArtificial Intelligence , vol. 38, no. 16, pp.", "mimetype": "text/plain", "start_char_idx": 4273, "end_char_idx": 5853, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f359d3b-227c-48cc-9d26-cc2b10750cca": {"__data__": {"id_": "4f359d3b-227c-48cc-9d26-cc2b10750cca", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ac3ae97-0054-4981-bd29-78503ad95039", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "abc83d2e3f4a56f9afc93944a97d5ce2622ff8dc6c4ee1afb5b97afe27427eb4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f5cc793-1438-4f32-a687-217142ef6457", "node_type": "1", "metadata": {}, "hash": "505db6d057a382bc902362d97170a3372953f1c759d1290bf8c30d1811d82ac8", "class_name": "RelatedNodeInfo"}}, "text": "Yang, and Q. Zhu,\n\u201cPrompt-based Node Feature Extractor for Few-shot Learning on\nText-Attributed Graphs,\u201d Sep. 2023, arXiv:2309.02848 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2309.02848\n[34] M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, M. Podstawski,\nL. Gianinazzi, J. Gajda, T. Lehmann, H. Niewiadomski, P. Nyczyk,\nand T. Hoefler, \u201cGraph of Thoughts: Solving Elaborate Problems with\nLarge Language Models,\u201d Proceedings of the AAAI Conference on\nArtificial Intelligence , vol. 38, no. 16, pp. 17 682\u201317 690, Mar. 2024,\narXiv:2308.09687 [cs]. [Online]. Available: http://arxiv.org/abs/2308.\n09687\n[35] Y . Zhang, J. Yang, Y . Yuan, and A. C.-C. Yao, \u201cCumulative Reasoning\nwith Large Language Models,\u201d Apr. 2024, arXiv:2308.04371 [cs].\n[Online]. Available: http://arxiv.org/abs/2308.04371\n[36] Y . Yao, Z. Li, and H. Zhao, \u201cBeyond Chain-of-Thought, Effective\nGraph-of-Thought Reasoning in Language Models,\u201d Mar. 2024,\narXiv:2305.16582 [cs]. [Online]. Available: http://arxiv.org/abs/2305.\n16582\n[37] J. Zhao, L. Zhuo, Y . Shen, M. Qu, K. Liu, M. Bronstein,\nZ. Zhu, and J. Tang, \u201cGraphText: Graph Reasoning in Text\nSpace,\u201d Oct. 2023, arXiv:2310.01089 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.01089\n[38] Y . Tan, Z. Zhou, H. Lv, W. Liu, and C. Yang,\n\u201cWalklm: A uniform language model fine-tuning framework for\nattributed graph embedding,\u201d in Advances in Neural Information\nProcessing Systems 36: Annual Conference on Neural Information\nProcessing Systems 2023, NeurIPS 2023, New Orleans, LA,\nUSA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023.", "mimetype": "text/plain", "start_char_idx": 5350, "end_char_idx": 6971, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f5cc793-1438-4f32-a687-217142ef6457": {"__data__": {"id_": "4f5cc793-1438-4f32-a687-217142ef6457", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f359d3b-227c-48cc-9d26-cc2b10750cca", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "815f03ca385277158c8f0efe90f06cb1200a32d15c2243cffada0f6af63534d8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "734cb5cc-7cc9-4cc9-b522-cf908e3db6f4", "node_type": "1", "metadata": {}, "hash": "1dc0e591d01384b53d4ab12b497fda5b5acd2f8fedd4593e70cc0050f5a187ee", "class_name": "RelatedNodeInfo"}}, "text": "2023, arXiv:2310.01089 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.01089\n[38] Y . Tan, Z. Zhou, H. Lv, W. Liu, and C. Yang,\n\u201cWalklm: A uniform language model fine-tuning framework for\nattributed graph embedding,\u201d in Advances in Neural Information\nProcessing Systems 36: Annual Conference on Neural Information\nProcessing Systems 2023, NeurIPS 2023, New Orleans, LA,\nUSA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023. [Online]. Available: http://papers.nips.cc/paper files/paper/2023/\nhash/2ac879d1865475a7abc8dfc7a9c15c27-Abstract-Conference.html\n[39] Y . Qin, X. Wang, Z. Zhang, and W. Zhu, \u201cDisentangled Representation\nLearning with Large Language Models for Text-Attributed Graphs,\u201d\nMar. 2024, arXiv:2310.18152 [cs]. [Online]. Available: http://arxiv.\norg/abs/2310.18152\n[40] S. Dernbach, K. Agarwal, A. Zuniga, M. Henry, and S. Choudhury,\n\u201cGLaM: Fine-Tuning Large Language Models for Domain Knowledge\nGraph Alignment via Neighborhood Partitioning and Generative\nSubgraph Encoding,\u201d Apr. 2024, arXiv:2402.06764 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2402.06764\n[41] J. Sun, C. Xu, L. Tang, S. Wang, C. Lin, Y . Gong, L. M. Ni,\nH.-Y . Shum, and J. Guo, \u201cThink-on-Graph: Deep and Responsible\nReasoning of Large Language Model on Knowledge Graph,\u201d Mar.\n2024, arXiv:2307.07697 [cs]. [Online]. Available: http://arxiv.org/abs/\n2307.07697\n[42] Y . Tian, H. Song, Z. Wang, H. Wang, Z. Hu, F. Wang, N. V .\nChawla, and P. Xu, \u201cGraph Neural Prompting with Large Language\nModels,\u201d Dec. 2023, arXiv:2309.15427 [cs]. [Online].", "mimetype": "text/plain", "start_char_idx": 6486, "end_char_idx": 8080, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "734cb5cc-7cc9-4cc9-b522-cf908e3db6f4": {"__data__": {"id_": "734cb5cc-7cc9-4cc9-b522-cf908e3db6f4", "embedding": null, "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29", "node_type": "4", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0166c55c870efd98553419be7b68a212c3bf5f713730cb802576709f08ed2611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f5cc793-1438-4f32-a687-217142ef6457", "node_type": "1", "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "489f8e79b3f9cc58901de7bafddcf5cfc8b2c7b8931b855faad2385d9b93c682", "class_name": "RelatedNodeInfo"}}, "text": "Available: http://arxiv.org/abs/2402.06764\n[41] J. Sun, C. Xu, L. Tang, S. Wang, C. Lin, Y . Gong, L. M. Ni,\nH.-Y . Shum, and J. Guo, \u201cThink-on-Graph: Deep and Responsible\nReasoning of Large Language Model on Knowledge Graph,\u201d Mar.\n2024, arXiv:2307.07697 [cs]. [Online]. Available: http://arxiv.org/abs/\n2307.07697\n[42] Y . Tian, H. Song, Z. Wang, H. Wang, Z. Hu, F. Wang, N. V .\nChawla, and P. Xu, \u201cGraph Neural Prompting with Large Language\nModels,\u201d Dec. 2023, arXiv:2309.15427 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2309.15427\n[43] L. Luo, Y .-F. Li, G. Haffari, and S. Pan, \u201cReasoning on Graphs:\nFaithful and Interpretable Large Language Model Reasoning,\u201d Feb.\n2024, arXiv:2310.01061 [cs]. [Online]. Available: http://arxiv.org/abs/\n2310.01061\n[44] W. Wei, X. Ren, J. Tang, Q. Wang, L. Su, S. Cheng, J. Wang,\nD. Yin, and C. Huang, \u201cLLMRec: Large Language Models with Graph\nAugmentation for Recommendation,\u201d Jan. 2024, arXiv:2311.00423\n[cs]. [Online]. Available: http://arxiv.org/abs/2311.00423", "mimetype": "text/plain", "start_char_idx": 7585, "end_char_idx": 8591, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6f7d7314-1ae3-427f-a146-460318c9335c": {"__data__": {"id_": "6f7d7314-1ae3-427f-a146-460318c9335c", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ace06032-54c2-4e81-91b0-404d8ad0c9b7", "node_type": "1", "metadata": {}, "hash": "3e32a3f9abbbae4d22ebe699fbec7aa504031d81f8a054cae2ee678ab41d68ed", "class_name": "RelatedNodeInfo"}}, "text": "[45] H. Wang, Y . Gao, X. Zheng, P. Zhang, H. Chen, J. Bu,\nand P. S. Yu, \u201cGraph Neural Architecture Search with GPT-\n4,\u201d Mar. 2024, arXiv:2310.01436 [cs]. [Online]. Available: http:\n//arxiv.org/abs/2310.01436\n[46] L. Wu, Z. Qiu, Z. Zheng, H. Zhu, and E. Chen, \u201cExploring\nlarge language model for graph data understanding in online job\nrecommendations,\u201d in Thirty-Eighth AAAI Conference on Artificial\nIntelligence, AAAI 2024, Thirty-Sixth Conference on Innovative\nApplications of Artificial Intelligence, IAAI 2024, Fourteenth\nSymposium on Educational Advances in Artificial Intelligence, EAAI\n2014, February 20-27, 2024, Vancouver, Canada , M. J. Wooldridge,\nJ. G. Dy, and S. Natarajan, Eds. AAAI Press, 2024, pp. 9178\u20139186.\n[Online]. Available: https://doi.org/10.1609/aaai.v38i8.28769\n[47] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . Min,\nB. Zhang, J. Zhang, Z. Dong, Y . Du, C. Yang, Y . Chen, Z. Chen,\nJ. Jiang, R. Ren, Y . Li, X. Tang, Z. Liu, P. Liu, J.-Y . Nie, and J.-R. Wen,\n\u201cA Survey of Large Language Models,\u201d Nov. 2023, arXiv:2303.18223\n[cs]. [Online]. Available: http://arxiv.org/abs/2303.18223\n[48] J. Yang, H. Jin, R. Tang, X. Han, Q. Feng, H. Jiang, B. Yin, and\nX. Hu, \u201cHarnessing the power of llms in practice: A survey on chatgpt\nand beyond,\u201d CoRR , vol. abs/2304.13712, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2304.13712\n[49] M. Himsolt, \u201cGml: A portable graph file format,\u201d Technical report,\nUniversitat Passau, Tech. Rep., 1997.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1482, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ace06032-54c2-4e81-91b0-404d8ad0c9b7": {"__data__": {"id_": "ace06032-54c2-4e81-91b0-404d8ad0c9b7", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6f7d7314-1ae3-427f-a146-460318c9335c", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "ddbe4bc70633c8ec52512176cf01877474658939581e5b4f526944234f6ccefb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "027908e7-c87d-4cba-8b44-341925a17360", "node_type": "1", "metadata": {}, "hash": "23c057f3472409566482381c753e42ebf8e1938d1819ad08515616956b9ad049", "class_name": "RelatedNodeInfo"}}, "text": "Nie, and J.-R. Wen,\n\u201cA Survey of Large Language Models,\u201d Nov. 2023, arXiv:2303.18223\n[cs]. [Online]. Available: http://arxiv.org/abs/2303.18223\n[48] J. Yang, H. Jin, R. Tang, X. Han, Q. Feng, H. Jiang, B. Yin, and\nX. Hu, \u201cHarnessing the power of llms in practice: A survey on chatgpt\nand beyond,\u201d CoRR , vol. abs/2304.13712, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2304.13712\n[49] M. Himsolt, \u201cGml: A portable graph file format,\u201d Technical report,\nUniversitat Passau, Tech. Rep., 1997.\n[50] U. Brandes, M. Eiglsperger, J. Lerner, and C. Pich, \u201cGraph markup lan-\nguage (graphml),\u201d in Handbook on Graph Drawing and Visualization ,\nR. Tamassia, Ed. Chapman and Hall/CRC, 2013, pp. 517\u2013541.\n[51] N. Francis, A. Green, P. Guagliardo, L. Libkin, T. Lindaaker,\nV . Marsault, S. Plantikow, M. Rydberg, P. Selmer, and A. Taylor,\n\u201cCypher: An Evolving Query Language for Property Graphs,\u201d in\nProceedings of the 2018 International Conference on Management of\nData . Houston TX USA: ACM, May 2018, pp. 1433\u20131445. [Online].\nAvailable: https://dl.acm.org/doi/10.1145/3183713.3190657\n[52] M. A. Rodriguez, \u201cThe Gremlin graph traversal machine and language\n(invited talk),\u201d in Proceedings of the 15th Symposium on Database\nProgramming Languages . Pittsburgh PA USA: ACM, Oct. 2015,\npp. 1\u201310. [Online]. Available: https://dl.acm.org/doi/10.1145/2815072.\n2815073\n[53] J. P \u00b4erez, M. Arenas, and C. Gutierrez, \u201cSemantics and complexity of\nSPARQL,\u201d ACM Transactions on Database Systems , vol. 34, no. 3,\npp. 1\u201345, Aug. 2009. [Online]. Available: https://dl.acm.org/doi/10.", "mimetype": "text/plain", "start_char_idx": 979, "end_char_idx": 2548, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "027908e7-c87d-4cba-8b44-341925a17360": {"__data__": {"id_": "027908e7-c87d-4cba-8b44-341925a17360", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ace06032-54c2-4e81-91b0-404d8ad0c9b7", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "b43798f0770b8b2af7ba36f9a50e921a35b6bc68d661c83526c51c6bded80119", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6bb529c-30f0-4df9-8547-6e9c9cbc482d", "node_type": "1", "metadata": {}, "hash": "76d6b3173e0f59b3acf33e69a0896bbfefb10df6e5e7f32261a901ddbfc92776", "class_name": "RelatedNodeInfo"}}, "text": "[Online].\nAvailable: https://dl.acm.org/doi/10.1145/3183713.3190657\n[52] M. A. Rodriguez, \u201cThe Gremlin graph traversal machine and language\n(invited talk),\u201d in Proceedings of the 15th Symposium on Database\nProgramming Languages . Pittsburgh PA USA: ACM, Oct. 2015,\npp. 1\u201310. [Online]. Available: https://dl.acm.org/doi/10.1145/2815072.\n2815073\n[53] J. P \u00b4erez, M. Arenas, and C. Gutierrez, \u201cSemantics and complexity of\nSPARQL,\u201d ACM Transactions on Database Systems , vol. 34, no. 3,\npp. 1\u201345, Aug. 2009. [Online]. Available: https://dl.acm.org/doi/10.\n1145/1567274.1567278\n[54] B. Wang, R. Shin, X. Liu, O. Polozov, and M. Richardson, \u201cRAT-\nSQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL\nParsers,\u201d Aug. 2021, arXiv:1911.04942 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/1911.04942\n[55] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig,\n\u201cPre-train, Prompt, and Predict: A Systematic Survey of Prompting\nMethods in Natural Language Processing,\u201d ACM Computing Surveys ,\nvol. 55, no. 9, pp. 1\u201335, Sep. 2023. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3560815\n[56] W. Hu, M. Fey, M. Zitnik, Y . Dong, H. Ren, B. Liu, M. Catasta,\nand J. Leskovec, \u201cOpen graph benchmark: Datasets for machine\nlearning on graphs,\u201d in Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information Processing\nSystems 2020, NeurIPS 2020, December 6-12, 2020, virtual ,\nH. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds.,\n2020. [Online].", "mimetype": "text/plain", "start_char_idx": 1997, "end_char_idx": 3495, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6bb529c-30f0-4df9-8547-6e9c9cbc482d": {"__data__": {"id_": "c6bb529c-30f0-4df9-8547-6e9c9cbc482d", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "027908e7-c87d-4cba-8b44-341925a17360", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "1c8276e28c4ac9dc5cc6679f0bf74a86b01e061b9d4fc15adea29a11cae4c05c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da7918bb-d065-4ee6-96e3-0a49a93cf873", "node_type": "1", "metadata": {}, "hash": "74ccd29efa05334e87c600a8ef7e98a1a8f65591381ead1e1d2f3a8d283d065f", "class_name": "RelatedNodeInfo"}}, "text": "55, no. 9, pp. 1\u201335, Sep. 2023. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3560815\n[56] W. Hu, M. Fey, M. Zitnik, Y . Dong, H. Ren, B. Liu, M. Catasta,\nand J. Leskovec, \u201cOpen graph benchmark: Datasets for machine\nlearning on graphs,\u201d in Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information Processing\nSystems 2020, NeurIPS 2020, December 6-12, 2020, virtual ,\nH. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds.,\n2020. [Online]. Available: https://proceedings.neurips.cc/paper/2020/\nhash/fb60d411a5c5b72b2e7d3527cfc84fd0-Abstract.html\n[57] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su,\n\u201cArnetMiner: extraction and mining of academic social networks,\u201d\ninProceedings of the 14th ACM SIGKDD international conference\non Knowledge discovery and data mining . Las Vegas Nevada\nUSA: ACM, Aug. 2008, pp. 990\u2013998. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/1401890.1402008\n[58] T. Schick, J. Dwivedi-Yu, R. Dess `\u0131, R. Raileanu, M. Lomeli,\nE. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom,\n\u201cToolformer: Language models can teach themselves to use tools,\u201d\ninAdvances in Neural Information Processing Systems 36: Annual\nConference on Neural Information Processing Systems 2023, NeurIPS\n2023, New Orleans, LA, USA, December 10 - 16, 2023 , A. Oh,\nT. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023. [Online].", "mimetype": "text/plain", "start_char_idx": 3001, "end_char_idx": 4410, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "da7918bb-d065-4ee6-96e3-0a49a93cf873": {"__data__": {"id_": "da7918bb-d065-4ee6-96e3-0a49a93cf873", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6bb529c-30f0-4df9-8547-6e9c9cbc482d", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "8d2c6e794888a13839122994ee3cdbbdc9ebe3b0ad61be5a8840e7789db9f0b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ab1a388-1eff-4adb-9fc1-d11b99b4726c", "node_type": "1", "metadata": {}, "hash": "df72d3f6c53798747887803f09ce6b8917cf663ba1047e134d013c6e54402c11", "class_name": "RelatedNodeInfo"}}, "text": "990\u2013998. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/1401890.1402008\n[58] T. Schick, J. Dwivedi-Yu, R. Dess `\u0131, R. Raileanu, M. Lomeli,\nE. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom,\n\u201cToolformer: Language models can teach themselves to use tools,\u201d\ninAdvances in Neural Information Processing Systems 36: Annual\nConference on Neural Information Processing Systems 2023, NeurIPS\n2023, New Orleans, LA, USA, December 10 - 16, 2023 , A. Oh,\nT. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023. [Online]. Available: http://papers.nips.cc/paper files/paper/2023/\nhash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html[59] J. Zhang, \u201cGraph-ToolFormer: To Empower LLMs with Graph\nReasoning Ability via Prompt Augmented by ChatGPT,\u201d May 2023,\narXiv:2304.11116 [cs]. [Online]. Available: http://arxiv.org/abs/2304.\n11116\n[60] H. Face, \u201chivemind/gpt-j-6b-8bit.\u201d\n[61] B. Wang and A. Komatsuzaki, \u201cGpt-j-6b: A 6 billion parameter\nautoregressive language model,\u201d 2021.\n[62] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez,\nA. Joulin, E. Grave, and G. Lample, \u201cLLaMA: Open and Efficient\nFoundation Language Models,\u201d 2023, publisher: [object Object]\nVersion Number: 1. [Online]. Available: https://arxiv.org/abs/2302.\n13971\n[63] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang,\nand W. Chen, \u201cLoRA: Low-Rank Adaptation of Large Language\nModels,\u201d Oct. 2021, arXiv:2106.09685 [cs]. [Online].", "mimetype": "text/plain", "start_char_idx": 3872, "end_char_idx": 5398, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ab1a388-1eff-4adb-9fc1-d11b99b4726c": {"__data__": {"id_": "7ab1a388-1eff-4adb-9fc1-d11b99b4726c", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da7918bb-d065-4ee6-96e3-0a49a93cf873", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "68e91f10ace0123ee2a5445d6f89cdce7fe419eb5aafe1fcf3c450eb8666f6d7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7c275b6-176d-4638-b5dc-7aaad1410237", "node_type": "1", "metadata": {}, "hash": "eebb65b0a6e07381c0e9e47d23e80ad68f3e597f00a6e557aa4548272d370cc9", "class_name": "RelatedNodeInfo"}}, "text": "Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez,\nA. Joulin, E. Grave, and G. Lample, \u201cLLaMA: Open and Efficient\nFoundation Language Models,\u201d 2023, publisher: [object Object]\nVersion Number: 1. [Online]. Available: https://arxiv.org/abs/2302.\n13971\n[63] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang,\nand W. Chen, \u201cLoRA: Low-Rank Adaptation of Large Language\nModels,\u201d Oct. 2021, arXiv:2106.09685 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2106.09685\n[64] Z. Chai, T. Zhang, L. Wu, K. Han, X. Hu, X. Huang, and Y . Yang,\n\u201cGraphLLM: Boosting Graph Reasoning Ability of Large Language\nModel,\u201d Oct. 2023, arXiv:2310.05845 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.05845\n[65] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,\nE. H. Chi, Q. V . Le, and D. Zhou, \u201cChain-of-thought prompting\nelicits reasoning in large language models,\u201d in Advances in Neural\nInformation Processing Systems 35: Annual Conference on Neural\nInformation Processing Systems 2022, NeurIPS 2022, New Orleans,\nLA, USA, November 28 - December 9, 2022 , S. Koyejo, S. Mohamed,\nA. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., 2022.\n[Online]. Available: http://papers.nips.cc/paper files/paper/2022/hash/\n9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html\n[66] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowd-\nhery, and D. Zhou, \u201cSelf-Consistency Improves Chain of Thought\nReasoning in Language Models,\u201d Mar. 2023, arXiv:2203.11171 [cs].\n[Online].", "mimetype": "text/plain", "start_char_idx": 4933, "end_char_idx": 6453, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d7c275b6-176d-4638-b5dc-7aaad1410237": {"__data__": {"id_": "d7c275b6-176d-4638-b5dc-7aaad1410237", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7ab1a388-1eff-4adb-9fc1-d11b99b4726c", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "346e723346b7e15f9d9d63900ddceb58106e508194407912b74de77a424490bd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4dbfd63d-c564-49da-ad73-3e20e13ddd76", "node_type": "1", "metadata": {}, "hash": "2a798179ba7027faffcb0751f5c5cc9026c7848b48170c378096a0f1cab44ec0", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available: http://papers.nips.cc/paper files/paper/2022/hash/\n9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html\n[66] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowd-\nhery, and D. Zhou, \u201cSelf-Consistency Improves Chain of Thought\nReasoning in Language Models,\u201d Mar. 2023, arXiv:2203.11171 [cs].\n[Online]. Available: http://arxiv.org/abs/2203.11171\n[67] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu,\nL. Li, and Z. Sui, \u201cA Survey on In-context Learning,\u201d Jun. 2023,\narXiv:2301.00234 [cs]. [Online]. Available: http://arxiv.org/abs/2301.\n00234\n[68] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \u201cProx-\nimal Policy Optimization Algorithms,\u201d Aug. 2017, arXiv:1707.06347\n[cs]. [Online]. Available: http://arxiv.org/abs/1707.06347\n[69] H. Dong, W. Xiong, D. Goyal, Y . Zhang, W. Chow, R. Pan,\nS. Diao, J. Zhang, K. Shum, and T. Zhang, \u201cRAFT: Reward\nrAnked FineTuning for Generative Foundation Model Alignment,\u201d\nDec. 2023, arXiv:2304.06767 [cs, stat]. [Online]. Available: http:\n//arxiv.org/abs/2304.06767\n[70] F. Song, B. Yu, M. Li, H. Yu, F. Huang, Y . Li, and H. Wang, \u201cPreference\nRanking Optimization for Human Alignment,\u201d Proceedings of the\nAAAI Conference on Artificial Intelligence , vol. 38, no. 17, pp.\n18 990\u201318 998, Mar. 2024. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/29865\n[71] K. Duan, Q. Liu, T.-S.", "mimetype": "text/plain", "start_char_idx": 6113, "end_char_idx": 7521, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4dbfd63d-c564-49da-ad73-3e20e13ddd76": {"__data__": {"id_": "4dbfd63d-c564-49da-ad73-3e20e13ddd76", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d7c275b6-176d-4638-b5dc-7aaad1410237", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "7f13d16706ac5a3ffbc0a99817f2c677bb17fcd7865d3ba7c964c5961668fbad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "28498651-e607-421d-b77b-a3ec19b45639", "node_type": "1", "metadata": {}, "hash": "dbbda3b34f1a5f7eb0b01ae310d044329278e9f8604f808daffa74341eb2f0af", "class_name": "RelatedNodeInfo"}}, "text": "2023, arXiv:2304.06767 [cs, stat]. [Online]. Available: http:\n//arxiv.org/abs/2304.06767\n[70] F. Song, B. Yu, M. Li, H. Yu, F. Huang, Y . Li, and H. Wang, \u201cPreference\nRanking Optimization for Human Alignment,\u201d Proceedings of the\nAAAI Conference on Artificial Intelligence , vol. 38, no. 17, pp.\n18 990\u201318 998, Mar. 2024. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/29865\n[71] K. Duan, Q. Liu, T.-S. Chua, S. Yan, W. T. Ooi, Q. Xie, and J. He,\n\u201cSimTeG: A Frustratingly Simple Approach Improves Textual Graph\nLearning,\u201d Aug. 2023, arXiv:2308.02565 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2308.02565\n[72] Z. Chen, H. Mao, H. Wen, H. Han, W. Jin, H. Zhang, H. Liu, and\nJ. Tang, \u201cLabel-free node classification on graphs with large language\nmodels (LLMS),\u201d CoRR , vol. abs/2310.04668, 2023. [Online].\nAvailable: https://doi.org/10.48550/arXiv.2310.04668\n[73] Z. Chen, H. Mao, H. Li, W. Jin, H. Wen, X. Wei, S. Wang,\nD. Yin, W. Fan, H. Liu, and J. Tang, \u201cExploring the Potential of\nLarge Language Models (LLMs) in Learning on Graphs,\u201d Jan. 2024,\narXiv:2307.03393 [cs]. [Online]. Available: http://arxiv.org/abs/2307.\n03393\n[74] Y . Hu, Z. Zhang, and L. Zhao, \u201cBeyond Text: A Deep Dive\ninto Large Language Models\u2019 Ability on Understanding Graph\nData,\u201d Oct. 2023, arXiv:2310.04944 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.04944\n[75] J. Yu, Y . Ren, C. Gong, J. Tan, X. Li, and X. Zhang, \u201cEmpower\nText-Attributed Graphs Learning with Large Language Models\n(LLMs),\u201d Oct. 2023, arXiv:2310.09872 [cs].", "mimetype": "text/plain", "start_char_idx": 7096, "end_char_idx": 8632, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28498651-e607-421d-b77b-a3ec19b45639": {"__data__": {"id_": "28498651-e607-421d-b77b-a3ec19b45639", "embedding": null, "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329", "node_type": "4", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "03c45128bc99ad4ed558ba22723705e9a6bcd77653422d6631f92cf44852818f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4dbfd63d-c564-49da-ad73-3e20e13ddd76", "node_type": "1", "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "86eee2140828411138238bb50d1eff59c3cf02de4cc51b6631b5c834f70a8af1", "class_name": "RelatedNodeInfo"}}, "text": "2024,\narXiv:2307.03393 [cs]. [Online]. Available: http://arxiv.org/abs/2307.\n03393\n[74] Y . Hu, Z. Zhang, and L. Zhao, \u201cBeyond Text: A Deep Dive\ninto Large Language Models\u2019 Ability on Understanding Graph\nData,\u201d Oct. 2023, arXiv:2310.04944 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.04944\n[75] J. Yu, Y . Ren, C. Gong, J. Tan, X. Li, and X. Zhang, \u201cEmpower\nText-Attributed Graphs Learning with Large Language Models\n(LLMs),\u201d Oct. 2023, arXiv:2310.09872 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.09872\n[76] Q. Wang, Z. Gao, and R. Xu, \u201cGraph agent: Explicit reasoning agent", "mimetype": "text/plain", "start_char_idx": 8165, "end_char_idx": 8757, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49be2be8-205e-4523-a4e4-12e608a7cd96": {"__data__": {"id_": "49be2be8-205e-4523-a4e4-12e608a7cd96", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec8200b0-4737-40db-8337-3f8500eb9a7f", "node_type": "1", "metadata": {}, "hash": "7bd8dc672e0d8df0e94e19984ff1c3279f1f93c884e12f14ef157e61386cf146", "class_name": "RelatedNodeInfo"}}, "text": "for graphs,\u201d CoRR , vol. abs/2310.16421, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2310.16421\n[77] B. Bi, S. Liu, Y . Wang, L. Mei, and X. Cheng, \u201cLPNL: Scalable Link\nPrediction with Large Language Models,\u201d Feb. 2024, arXiv:2401.13227\n[cs]. [Online]. Available: http://arxiv.org/abs/2401.13227\n[78] R. Ye, C. Zhang, R. Wang, S. Xu, and Y . Zhang, \u201cLanguage is All a\nGraph Needs,\u201d Feb. 2024, arXiv:2308.07134 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2308.07134\n[79] J. Tang, Y . Yang, W. Wei, L. Shi, L. Su, S. Cheng, D. Yin, and\nC. Huang, \u201cGraphGPT: Graph Instruction Tuning for Large Language\nModels,\u201d Dec. 2023, arXiv:2310.13023 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.13023\n[80] M. Sun, K. Zhou, X. He, Y . Wang, and X. Wang, \u201cGPPT:\nGraph Pre-training and Prompt Tuning to Generalize Graph Neural\nNetworks,\u201d in Proceedings of the 28th ACM SIGKDD Conference\non Knowledge Discovery and Data Mining . Washington DC\nUSA: ACM, Aug. 2022, pp. 1717\u20131727. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/3534678.3539249\n[81] Z. Liu, X. Yu, Y . Fang, and X. Zhang, \u201cGraphPrompt: Unifying\nPre-Training and Downstream Tasks for Graph Neural Networks,\u201d\ninProceedings of the ACM Web Conference 2023 . Austin\nTX USA: ACM, Apr. 2023, pp. 417\u2013428. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/3543507.3583386\n[82] X. Sun, H. Cheng, J. Li, B. Liu, and J. Guan, \u201cAll in One: Multi-Task\nPrompting for Graph Neural Networks,\u201d in Proceedings of the 29th\nACM SIGKDD Conference on Knowledge Discovery and Data Mining .\nLong Beach CA USA: ACM, Aug. 2023, pp.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1584, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec8200b0-4737-40db-8337-3f8500eb9a7f": {"__data__": {"id_": "ec8200b0-4737-40db-8337-3f8500eb9a7f", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49be2be8-205e-4523-a4e4-12e608a7cd96", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "39cd4862af46a50734fe16a486e46e9d5e01ba59b74565f6097536d10851f040", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "939627df-1bd1-455b-848b-43aa27a3aaf0", "node_type": "1", "metadata": {}, "hash": "0253396e093da8d82bb7e7c6b2b8a59dc1427ff032767dae72dc345d5befefc0", "class_name": "RelatedNodeInfo"}}, "text": "Fang, and X. Zhang, \u201cGraphPrompt: Unifying\nPre-Training and Downstream Tasks for Graph Neural Networks,\u201d\ninProceedings of the ACM Web Conference 2023 . Austin\nTX USA: ACM, Apr. 2023, pp. 417\u2013428. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/3543507.3583386\n[82] X. Sun, H. Cheng, J. Li, B. Liu, and J. Guan, \u201cAll in One: Multi-Task\nPrompting for Graph Neural Networks,\u201d in Proceedings of the 29th\nACM SIGKDD Conference on Knowledge Discovery and Data Mining .\nLong Beach CA USA: ACM, Aug. 2023, pp. 2120\u20132131. [Online].\nAvailable: https://dl.acm.org/doi/10.1145/3580305.3599256\n[83] L. Cao, \u201cGraphReason: Enhancing Reasoning Capabilities of Large\nLanguage Models through A Graph-Based Verification Approach,\u201d\nApr. 2024, arXiv:2308.09267 [cs]. [Online]. Available: http://arxiv.\norg/abs/2308.09267\n[84] J. Park, A. Patel, O. Z. Khan, H. J. Kim, and J.-K. Kim, \u201cGraph-\nGuided Reasoning for Multi-Hop Question Answering in Large\nLanguage Models,\u201d Nov. 2023, arXiv:2311.09762 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2311.09762\n[85] Z. Wen and Y . Fang, \u201cAugmenting Low-Resource Text Classification\nwith Graph-Grounded Pre-training and Prompting,\u201d in Proceedings\nof the 46th International ACM SIGIR Conference on Research\nand Development in Information Retrieval , Jul. 2023, pp. 506\u2013516,\narXiv:2305.03324 [cs]. [Online]. Available: http://arxiv.org/abs/2305.\n03324\n[86] B. Fatemi, J. Halcrow, and B. Perozzi, \u201cTalk like a Graph: Encoding\nGraphs for Large Language Models,\u201d Oct. 2023, arXiv:2310.04560\n[cs]. [Online]. Available: http://arxiv.org/abs/2310.04560\n[87] D. Das, I. Gupta, J. Srivastava, and D. Kang, \u201cWhich Modality\nshould I use \u2013 Text, Motif, or Image? : Understanding Graphs with\nLarge Language Models,\u201d Mar.", "mimetype": "text/plain", "start_char_idx": 1079, "end_char_idx": 2811, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "939627df-1bd1-455b-848b-43aa27a3aaf0": {"__data__": {"id_": "939627df-1bd1-455b-848b-43aa27a3aaf0", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec8200b0-4737-40db-8337-3f8500eb9a7f", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "84ecfd3dc4533e71c5be4998b44a4f30de74367e32b900c5094a5afe1d6208be", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "95a8130f-647b-45d4-8c8f-1e5709ba95e0", "node_type": "1", "metadata": {}, "hash": "02cf0d76442edbaf0a85af603975273283e27246f5dbdac7c78d1c618dfb41cd", "class_name": "RelatedNodeInfo"}}, "text": "2023, pp. 506\u2013516,\narXiv:2305.03324 [cs]. [Online]. Available: http://arxiv.org/abs/2305.\n03324\n[86] B. Fatemi, J. Halcrow, and B. Perozzi, \u201cTalk like a Graph: Encoding\nGraphs for Large Language Models,\u201d Oct. 2023, arXiv:2310.04560\n[cs]. [Online]. Available: http://arxiv.org/abs/2310.04560\n[87] D. Das, I. Gupta, J. Srivastava, and D. Kang, \u201cWhich Modality\nshould I use \u2013 Text, Motif, or Image? : Understanding Graphs with\nLarge Language Models,\u201d Mar. 2024, arXiv:2311.09862 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2311.09862\n[88] K. Sun, Y . E. Xu, H. Zha, Y . Liu, and X. L. Dong, \u201cHead-to-Tail: How\nKnowledgeable are Large Language Models (LLMs)? A.K.A. Will\nLLMs Replace Knowledge Graphs?\u201d Apr. 2024, arXiv:2308.10168\n[cs]. [Online]. Available: http://arxiv.org/abs/2308.10168\n[89] L. Yang, H. Chen, Z. Li, X. Ding, and X. Wu, \u201cGive us the facts:\nEnhancing large language models with knowledge graphs for fact-\naware language modeling,\u201d IEEE Transactions on Knowledge and Data\nEngineering , 2024.\n[90] S. Pan, L. Luo, Y . Wang, C. Chen, J. Wang, and X. Wu, \u201cUnifying\nlarge language models and knowledge graphs: A roadmap,\u201d CoRR ,\nvol. abs/2306.08302, 2023. [Online]. Available: https://doi.org/10.\n48550/arXiv.2306.08302\n[91] S. Zheng, H. Bai, Y . Zhang, Y . Su, X. Niu, and N. Jaitly, \u201cKGLens:\nA Parameterized Knowledge Graph Solution to Assess What an LLM\nDoes and Doesn\u2019t Know,\u201d Feb. 2024, arXiv:2312.11539 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2312.11539\n[92] R. Zhang, Y .", "mimetype": "text/plain", "start_char_idx": 2359, "end_char_idx": 3859, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "95a8130f-647b-45d4-8c8f-1e5709ba95e0": {"__data__": {"id_": "95a8130f-647b-45d4-8c8f-1e5709ba95e0", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "939627df-1bd1-455b-848b-43aa27a3aaf0", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "ce9341be27c1f8151d0311955aa3f4938d1b990594a30de426ced77ae5bb81f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "210071f2-2831-46db-ba63-4edfb9c25d5c", "node_type": "1", "metadata": {}, "hash": "3e47d19b1634fe220ea0d6b06e9700a21c599444046ed161c69084681d87b602", "class_name": "RelatedNodeInfo"}}, "text": "[90] S. Pan, L. Luo, Y . Wang, C. Chen, J. Wang, and X. Wu, \u201cUnifying\nlarge language models and knowledge graphs: A roadmap,\u201d CoRR ,\nvol. abs/2306.08302, 2023. [Online]. Available: https://doi.org/10.\n48550/arXiv.2306.08302\n[91] S. Zheng, H. Bai, Y . Zhang, Y . Su, X. Niu, and N. Jaitly, \u201cKGLens:\nA Parameterized Knowledge Graph Solution to Assess What an LLM\nDoes and Doesn\u2019t Know,\u201d Feb. 2024, arXiv:2312.11539 [cs]. [Online].\nAvailable: http://arxiv.org/abs/2312.11539\n[92] R. Zhang, Y . Su, B. D. Trisedya, X. Zhao, M. Yang, H. Cheng,\nand J. Qi, \u201cAutoAlign: Fully Automatic and Effective Knowledge\nGraph Alignment enabled by Large Language Models,\u201d Nov. 2023,\narXiv:2307.11772 [cs]. [Online]. Available: http://arxiv.org/abs/2307.\n11772\n[93] Y . Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and\nT. Derr, \u201cKnowledge Graph Prompting for Multi-Document Question\nAnswering,\u201d Dec. 2023, arXiv:2308.11730 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2308.11730[94] Z. Chen, Z. Jiang, F. Yang, E. Cho, X. Fan, X. Huang, Y . Lu,\nand A. Galstyan, \u201cGraph Meets LLM: A Novel Approach to\nCollaborative Filtering for Robust Conversational Understanding,\u201d\nJun. 2023, arXiv:2305.14449 [cs]. [Online]. Available: http://arxiv.org/\nabs/2305.14449\n[95] C. Sun, J. Li, Y . R. Fung, H. P. Chan, T. Abdelzaher, C. Zhai, and\nH. Ji, \u201cDecoding the Silent Majority: Inducing Belief Augmented\nSocial Graph with Large Language Model for Response Forecasting,\u201d\nOct. 2023, arXiv:2310.13297 [cs]. [Online]. Available: http://arxiv.org/\nabs/2310.13297\n[96] R. Su, T.-W. Wu, and B.-H.", "mimetype": "text/plain", "start_char_idx": 3369, "end_char_idx": 4930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "210071f2-2831-46db-ba63-4edfb9c25d5c": {"__data__": {"id_": "210071f2-2831-46db-ba63-4edfb9c25d5c", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "95a8130f-647b-45d4-8c8f-1e5709ba95e0", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0f90d9c024f262ad4f92ea729685a088312fb14d50727173c926c2ae2e202fee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c758fb51-55e3-4428-8050-9cc2a4174e60", "node_type": "1", "metadata": {}, "hash": "9a85f471ad55c26e46af0990d84b8a763a1221dfd6a0c062e2bfabf3eeaa1a5f", "class_name": "RelatedNodeInfo"}}, "text": "2023, arXiv:2305.14449 [cs]. [Online]. Available: http://arxiv.org/\nabs/2305.14449\n[95] C. Sun, J. Li, Y . R. Fung, H. P. Chan, T. Abdelzaher, C. Zhai, and\nH. Ji, \u201cDecoding the Silent Majority: Inducing Belief Augmented\nSocial Graph with Large Language Model for Response Forecasting,\u201d\nOct. 2023, arXiv:2310.13297 [cs]. [Online]. Available: http://arxiv.org/\nabs/2310.13297\n[96] R. Su, T.-W. Wu, and B.-H. Juang, \u201cSchema Graph-Guided Prompt for\nMulti-Domain Dialogue State Tracking,\u201d Nov. 2023, arXiv:2311.06345\n[cs]. [Online]. Available: http://arxiv.org/abs/2311.06345\n[97] Y . Peng, S. Lin, Q. Chen, L. Xu, X. Ren, Y . Li, and J. Xu,\n\u201cChatGraph: Chat with Your Graphs,\u201d Jan. 2024, arXiv:2401.12672\n[cs]. [Online]. Available: http://arxiv.org/abs/2401.12672\n[98] Y . Shen, R. Liao, Z. Han, Y . Ma, and V . Tresp, \u201cGraphextQA:\nA Benchmark for Evaluating Graph-Enhanced Large Language\nModels,\u201d Oct. 2023, arXiv:2310.08487 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2310.08487\n[99] H. Yan, C. Li, R. Long, C. Yan, J. Zhao, W. Zhuang, J. Yin,\nP. Zhang, W. Han, H. Sun, W. Deng, Q. Zhang, L. Sun,\nX. Xie, and S. Wang, \u201cA comprehensive study on text-attributed\ngraphs: Benchmarking and rethinking,\u201d in Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023. [Online].", "mimetype": "text/plain", "start_char_idx": 4525, "end_char_idx": 5998, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c758fb51-55e3-4428-8050-9cc2a4174e60": {"__data__": {"id_": "c758fb51-55e3-4428-8050-9cc2a4174e60", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "210071f2-2831-46db-ba63-4edfb9c25d5c", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "9c0a18970f78cc12e7c9b6d9982de2ca3f62e5bd72e42de4221d64b357ce2e5e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b60e597e-a3ca-4151-afe2-3da552c920c8", "node_type": "1", "metadata": {}, "hash": "60c733384da410353a76eb5f82c8d393e3aad55031fb604ccddbafe5e01d6fa8", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available:\nhttp://arxiv.org/abs/2310.08487\n[99] H. Yan, C. Li, R. Long, C. Yan, J. Zhao, W. Zhuang, J. Yin,\nP. Zhang, W. Han, H. Sun, W. Deng, Q. Zhang, L. Sun,\nX. Xie, and S. Wang, \u201cA comprehensive study on text-attributed\ngraphs: Benchmarking and rethinking,\u201d in Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds.,\n2023. [Online]. Available: http://papers.nips.cc/paper files/paper/2023/\nhash/37d00f567a18b478065f1a91b95622a0-Abstract-Datasets and\nBenchmarks.html\n[100] A. McCallum, K. Nigam, J. Rennie, and K. Seymore, \u201cAutomating\nthe construction of internet portals with machine learning,\u201d Inf.\nRetr., vol. 3, no. 2, pp. 127\u2013163, 2000. [Online]. Available:\nhttps://doi.org/10.1023/A:1009953814988\n[101] C. L. Giles, K. D. Bollacker, and S. Lawrence, \u201cCiteSeer: an\nautomatic citation indexing system,\u201d in Proceedings of the third ACM\nconference on Digital libraries - DL \u201998 . Pittsburgh, Pennsylvania,\nUnited States: ACM Press, 1998, pp. 89\u201398. [Online]. Available:\nhttp://portal.acm.org/citation.cfm?doid=276675.276685\n[102] Y . Zhang, H. Dai, Z. Kozareva, A. Smola, and L. Song,\n\u201cVariational Reasoning for Question Answering With Knowledge\nGraph,\u201d Proceedings of the AAAI Conference on Artificial Intelligence ,\nvol. 32, no. 1, Apr. 2018. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/12057\n[103] X. Wang, T. Gao, Z. Zhu, Z. Zhang, Z. Liu, J. Li, and\nJ. Tang, \u201cKEPLER: A unified model for knowledge embedding\nand pre-trained language representation,\u201d Trans. Assoc. Comput.\nLinguistics , vol.", "mimetype": "text/plain", "start_char_idx": 5453, "end_char_idx": 7189, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b60e597e-a3ca-4151-afe2-3da552c920c8": {"__data__": {"id_": "b60e597e-a3ca-4151-afe2-3da552c920c8", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c758fb51-55e3-4428-8050-9cc2a4174e60", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "4615d83a46bdbd0154b55598a42b8263d37a96525113104df1b75cf7bc631a83", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1247a8fd-38b6-474a-b730-a7154a99668c", "node_type": "1", "metadata": {}, "hash": "b2991c5d5662d987cac7a7546281ca8bfaa3b5c39bb23f334ab9847aadbe94d0", "class_name": "RelatedNodeInfo"}}, "text": "89\u201398. [Online]. Available:\nhttp://portal.acm.org/citation.cfm?doid=276675.276685\n[102] Y . Zhang, H. Dai, Z. Kozareva, A. Smola, and L. Song,\n\u201cVariational Reasoning for Question Answering With Knowledge\nGraph,\u201d Proceedings of the AAAI Conference on Artificial Intelligence ,\nvol. 32, no. 1, Apr. 2018. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/12057\n[103] X. Wang, T. Gao, Z. Zhu, Z. Zhang, Z. Liu, J. Li, and\nJ. Tang, \u201cKEPLER: A unified model for knowledge embedding\nand pre-trained language representation,\u201d Trans. Assoc. Comput.\nLinguistics , vol. 9, pp. 176\u2013194, 2021. [Online]. Available: https:\n//doi.org/10.1162/tacl a00360\n[104] K. M. Borgwardt, C. S. Ong, S. Schonauer, S. V . N. Vishwanathan,\nA. J. Smola, and H.-P. Kriegel, \u201cProtein function prediction via\ngraph kernels,\u201d Bioinformatics , vol. 21, no. Suppl 1, pp. i47\u2013i56, Jun.\n2005. [Online]. Available: https://academic.oup.com/bioinformatics/\narticle-lookup/doi/10.1093/bioinformatics/bti1007\n[105] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shuster-\nman, and C. Hansch, \u201cStructure-activity relationship of mutagenic aro-\nmatic and heteroaromatic nitro compounds. correlation with molecular\norbital energies and hydrophobicity,\u201d Journal of medicinal chemistry ,\nvol. 34, no. 2, pp. 786\u2013797, 1991.\n[106] N. Wale, I. A. Watson, and G. Karypis, \u201cComparison\nof descriptor spaces for chemical compound retrieval and\nclassification,\u201d Knowledge and Information Systems , vol. 14,\nno. 3, pp. 347\u2013375, Mar. 2008. [Online].", "mimetype": "text/plain", "start_char_idx": 6609, "end_char_idx": 8133, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1247a8fd-38b6-474a-b730-a7154a99668c": {"__data__": {"id_": "1247a8fd-38b6-474a-b730-a7154a99668c", "embedding": null, "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0", "node_type": "4", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f6edd3464b50d5e3ce7a1f2c88006f298ab13725f1e72e0a76e8c60ce1551b93", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b60e597e-a3ca-4151-afe2-3da552c920c8", "node_type": "1", "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "463c8411e0764d0df1aa6f7cb7d26b9a01ef81d2941bef2343939b754741521d", "class_name": "RelatedNodeInfo"}}, "text": "correlation with molecular\norbital energies and hydrophobicity,\u201d Journal of medicinal chemistry ,\nvol. 34, no. 2, pp. 786\u2013797, 1991.\n[106] N. Wale, I. A. Watson, and G. Karypis, \u201cComparison\nof descriptor spaces for chemical compound retrieval and\nclassification,\u201d Knowledge and Information Systems , vol. 14,\nno. 3, pp. 347\u2013375, Mar. 2008. [Online]. Available:\nhttp://link.springer.com/10.1007/s10115-007-0103-5\n[107] H. Toivonen, A. Srinivasan, R. D. King, S. Kramer,\nand C. Helma, \u201cStatistical evaluation of the Predictive\nToxicologyChallenge 2000\u20132001,\u201d Bioinformatics , vol. 19,\nno. 10, pp. 1183\u20131193, Jul. 2003. [Online]. Available:\nhttps://academic.oup.com/bioinformatics/article/19/10/1183/184239\n[108] X. Kong, J. Zhang, and P. S. Yu, \u201cInferring anchor links\nacross multiple heterogeneous social networks,\u201d in Proceedings\nof the 22nd ACM international conference on Conference on\ninformation & knowledge management - CIKM \u201913 . San Francisco,", "mimetype": "text/plain", "start_char_idx": 7784, "end_char_idx": 8734, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "66cfa6e3-b60f-4469-acb4-8a05abfcf73f": {"__data__": {"id_": "66cfa6e3-b60f-4469-acb4-8a05abfcf73f", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d10c7e39-872e-4002-8f91-e817750e97bf", "node_type": "1", "metadata": {}, "hash": "dc8b1e648fd9afdfd4df7deeef754b25f1bc1a0a1327d5eec9cd2ccb21360ca2", "class_name": "RelatedNodeInfo"}}, "text": "California, USA: ACM Press, 2013, pp. 179\u2013188. [Online]. Available:\nhttp://dl.acm.org/citation.cfm?doid=2505515.2505531\n[109] M. Wan and J. McAuley, \u201cItem recommendation on monotonic\nbehavior chains,\u201d in Proceedings of the 12th ACM Conference on\nRecommender Systems . Vancouver British Columbia Canada: ACM,\nSep. 2018, pp. 86\u201394. [Online]. Available: https://dl.acm.org/doi/10.\n1145/3240323.3240369\n[110] J. Ni, J. Li, and J. McAuley, \u201cJustifying Recommendations\nusing Distantly-Labeled Reviews and Fine-Grained Aspects,\u201d in\nProceedings of the 2019 Conference on Empirical Methods in Natural\nLanguage Processing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP) . Hong Kong,\nChina: Association for Computational Linguistics, 2019, pp. 188\u2013197.\n[Online]. Available: https://www.aclweb.org/anthology/D19-1018\n[111] W. L. Hamilton, Z. Ying, and J. Leskovec, \u201cInductive representation\nlearning on large graphs,\u201d in Advances in Neural Information\nProcessing Systems 30: Annual Conference on Neural Information\nProcessing Systems 2017, December 4-9, 2017, Long Beach, CA,\nUSA, I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach,\nR. Fergus, S. V . N. Vishwanathan, and R. Garnett, Eds., 2017, pp.\n1024\u20131034. [Online]. Available: https://proceedings.neurips.cc/paper/\n2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html\n[112] A. Bojchevski and S. G \u00a8unnemann, \u201cDeep Gaussian Embedding of\nGraphs: Unsupervised Inductive Learning via Ranking,\u201d Feb. 2018,\narXiv:1707.03815 [cs, stat]. [Online]. Available: http://arxiv.org/abs/\n1707.03815\n[113] O. Shchur, M. Mumme, A. Bojchevski, and S. G \u00a8unnemann, \u201cPitfalls\nof Graph Neural Network Evaluation,\u201d Jun. 2019, arXiv:1811.05868\n[cs, stat]. [Online].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1730, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d10c7e39-872e-4002-8f91-e817750e97bf": {"__data__": {"id_": "d10c7e39-872e-4002-8f91-e817750e97bf", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "66cfa6e3-b60f-4469-acb4-8a05abfcf73f", "node_type": "1", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "f4803cbdcbb4d4b867db098af048997e17935c60097807c693c3c87697f141c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "44d6e25a-4eb3-4ec5-9e27-14da843a43b6", "node_type": "1", "metadata": {}, "hash": "ad7147cbbec497fff9b11c0a97f6890ee846b21216bc965c7e414fa6098519b9", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available: https://proceedings.neurips.cc/paper/\n2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html\n[112] A. Bojchevski and S. G \u00a8unnemann, \u201cDeep Gaussian Embedding of\nGraphs: Unsupervised Inductive Learning via Ranking,\u201d Feb. 2018,\narXiv:1707.03815 [cs, stat]. [Online]. Available: http://arxiv.org/abs/\n1707.03815\n[113] O. Shchur, M. Mumme, A. Bojchevski, and S. G \u00a8unnemann, \u201cPitfalls\nof Graph Neural Network Evaluation,\u201d Jun. 2019, arXiv:1811.05868\n[cs, stat]. [Online]. Available: http://arxiv.org/abs/1811.05868\n[114] R. Rossi and N. Ahmed, \u201cThe Network Data Repository with\nInteractive Graph Analytics and Visualization,\u201d Proceedings of the\nAAAI Conference on Artificial Intelligence , vol. 29, no. 1, Mar.\n2015. [Online]. Available: https://ojs.aaai.org/index.php/AAAI/article/\nview/9277\n[115] H. Huang, H. Wang, and X. Wang, \u201cAn analysis framework\nof research frontiers based on the large-scale open academic\ngraph,\u201d Proceedings of the Association for Information Science and\nTechnology , vol. 57, no. 1, p. e307, Oct. 2020. [Online]. Available:\nhttps://asistdl.onlinelibrary.wiley.com/doi/10.1002/pra2.307\n[116] K. Cobbe, V . Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,\nM. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and\nJ. Schulman, \u201cTraining Verifiers to Solve Math Word Problems,\u201d Nov.\n2021, arXiv:2110.14168 [cs]. [Online]. Available: http://arxiv.org/abs/\n2110.14168\n[117] A. Patel, S. Bhattamishra, and N. Goyal, \u201cAre NLP Models really able\nto Solve Simple Math Word Problems?\u201d Apr. 2021, arXiv:2103.07191\n[cs]. [Online]. Available: http://arxiv.org/abs/2103.07191\n[118] S. Han, H. Schoelkopf, Y .", "mimetype": "text/plain", "start_char_idx": 1240, "end_char_idx": 2885, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "44d6e25a-4eb3-4ec5-9e27-14da843a43b6": {"__data__": {"id_": "44d6e25a-4eb3-4ec5-9e27-14da843a43b6", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d10c7e39-872e-4002-8f91-e817750e97bf", "node_type": "1", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "0582ef2793d05fccff041467560b72fdfab4560a06154323ba31e519745e469d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf", "node_type": "1", "metadata": {}, "hash": "92df8cb70eb56eba0cf8557e39ec144ba1fea5a40f5a3ad7628d3bc4f9b649df", "class_name": "RelatedNodeInfo"}}, "text": "Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser,\nM. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and\nJ. Schulman, \u201cTraining Verifiers to Solve Math Word Problems,\u201d Nov.\n2021, arXiv:2110.14168 [cs]. [Online]. Available: http://arxiv.org/abs/\n2110.14168\n[117] A. Patel, S. Bhattamishra, and N. Goyal, \u201cAre NLP Models really able\nto Solve Simple Math Word Problems?\u201d Apr. 2021, arXiv:2103.07191\n[cs]. [Online]. Available: http://arxiv.org/abs/2103.07191\n[118] S. Han, H. Schoelkopf, Y . Zhao, Z. Qi, M. Riddell, L. Benson,\nL. Sun, E. Zubova, Y . Qiao, M. Burtell, D. Peng, J. Fan, Y . Liu,\nB. Wong, M. Sailor, A. Ni, L. Nan, J. Kasai, T. Yu, R. Zhang,\nS. Joty, A. R. Fabbri, W. Kryscinski, X. V . Lin, C. Xiong, and\nD. Radev, \u201cFOLIO: Natural Language Reasoning with First-Order\nLogic,\u201d Sep. 2022, arXiv:2209.00840 [cs]. [Online]. Available:\nhttp://arxiv.org/abs/2209.00840\n[119] Y . Zhang, B. Jin, Q. Zhu, Y . Meng, and J. Han, \u201cThe effect of metadata\non scientific literature tagging: A cross-field cross-model study,\u201d in\nProceedings of the ACM Web Conference 2023 , 2023, pp. 1626\u20131637.\n[120] A. Johnson, T. Pollard, and R. Mark, \u201cMIMIC-III Clinical Database,\u201d\n2015. [Online]. Available: https://physionet.org/content/mimiciii/1.4/\n[121] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor,\n\u201cFreebase: a collaboratively created graph database for structuring\nhuman knowledge,\u201d in Proceedings of the 2008 ACM SIGMOD\ninternational conference on Management of data . Vancouver\nCanada: ACM, Jun. 2008, pp. 1247\u20131250. [Online].", "mimetype": "text/plain", "start_char_idx": 2392, "end_char_idx": 3933, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf": {"__data__": {"id_": "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "44d6e25a-4eb3-4ec5-9e27-14da843a43b6", "node_type": "1", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "48c934bc3933191cc25aaa37db76e476fc5fba5f0c58db9db91aea16394a4cfb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "764e22a7-3ea2-4cf9-80b7-8fb61603fdee", "node_type": "1", "metadata": {}, "hash": "f77a5bab8ef7f98a7232b17b513773d9ce0f8a58b1f2f555e334897ab3eb899b", "class_name": "RelatedNodeInfo"}}, "text": "Meng, and J. Han, \u201cThe effect of metadata\non scientific literature tagging: A cross-field cross-model study,\u201d in\nProceedings of the ACM Web Conference 2023 , 2023, pp. 1626\u20131637.\n[120] A. Johnson, T. Pollard, and R. Mark, \u201cMIMIC-III Clinical Database,\u201d\n2015. [Online]. Available: https://physionet.org/content/mimiciii/1.4/\n[121] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor,\n\u201cFreebase: a collaboratively created graph database for structuring\nhuman knowledge,\u201d in Proceedings of the 2008 ACM SIGMOD\ninternational conference on Management of data . Vancouver\nCanada: ACM, Jun. 2008, pp. 1247\u20131250. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/1376616.1376746\n[122] K. Toutanova and D. Chen, \u201cObserved versus latent features\nfor knowledge base and text inference,\u201d in Proceedings of the\n3rd Workshop on Continuous Vector Space Models and their\nCompositionality . Beijing, China: Association for Computational\nLinguistics, 2015, pp. 57\u201366. [Online]. Available: http://aclweb.org/\nanthology/W15-4007\n[123] W. Yih, M. Richardson, C. Meek, M. Chang, and J. Suh, \u201cThe\nvalue of semantic parse labeling for knowledge base question\nanswering,\u201d in Proceedings of the 54th Annual Meeting of theAssociation for Computational Linguistics, ACL 2016, August\n7-12, 2016, Berlin, Germany, Volume 2: Short Papers . The\nAssociation for Computer Linguistics, 2016. [Online]. Available:\nhttps://doi.org/10.18653/v1/p16-2033\n[124] A. Talmor and J. Berant, \u201cThe Web as a Knowledge-base for\nAnswering Complex Questions,\u201d Mar. 2018, arXiv:1803.06643 [cs].\n[Online]. Available: http://arxiv.org/abs/1803.06643\n[125] C.-Y . Lin, \u201cRouge: A package for automatic evaluation of summaries,\u201d\ninText summarization branches out , 2004, pp. 74\u201381.\n[126] K. Papineni, S. Roukos, T. Ward, and W.-J.", "mimetype": "text/plain", "start_char_idx": 3309, "end_char_idx": 5094, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "764e22a7-3ea2-4cf9-80b7-8fb61603fdee": {"__data__": {"id_": "764e22a7-3ea2-4cf9-80b7-8fb61603fdee", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf", "node_type": "1", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "15268c6e1acbe18419b2a836c961740c5249d7ba5abf14fbf4f0b8a123d8cd7c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ddff084-0d81-4436-83d5-cb9521cfd0bb", "node_type": "1", "metadata": {}, "hash": "f23ddd33eb6d5c138421d8c75c313713c13d952102013e56e57fba835f0fb479", "class_name": "RelatedNodeInfo"}}, "text": "The\nAssociation for Computer Linguistics, 2016. [Online]. Available:\nhttps://doi.org/10.18653/v1/p16-2033\n[124] A. Talmor and J. Berant, \u201cThe Web as a Knowledge-base for\nAnswering Complex Questions,\u201d Mar. 2018, arXiv:1803.06643 [cs].\n[Online]. Available: http://arxiv.org/abs/1803.06643\n[125] C.-Y . Lin, \u201cRouge: A package for automatic evaluation of summaries,\u201d\ninText summarization branches out , 2004, pp. 74\u201381.\n[126] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \u201cBLEU: a method\nfor automatic evaluation of machine translation,\u201d in Proceedings\nof the 40th Annual Meeting on Association for Computational\nLinguistics - ACL \u201902 . Philadelphia, Pennsylvania: Association\nfor Computational Linguistics, 2001, p. 311. [Online]. Available:\nhttp://portal.acm.org/citation.cfm?doid=1073083.1073135\n[127] C. Goutte and \u00b4E. Gaussier, \u201cA probabilistic interpretation of precision,\nrecall and F-score, with implication for evaluation,\u201d in Advances in\nInformation Retrieval, 27th European Conference on IR Research,\nECIR 2005, Santiago de Compostela, Spain, March 21-23, 2005,\nProceedings , ser. Lecture Notes in Computer Science, D. E. Losada and\nJ. M. Fern \u00b4andez-Luna, Eds., vol. 3408. Springer, 2005, pp. 345\u2013359.\n[Online]. Available: https://doi.org/10.1007/978-3-540-31865-1 25\n[128] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and\nA. Tomkins, \u201cThe web as a graph: Measurements, models,\nand methods,\u201d in Computing and Combinatorics, 5th Annual\nInternational Conference, COCOON \u201999, Tokyo, Japan, July 26-\n28, 1999, Proceedings , ser. Lecture Notes in Computer Science,\nT. Asano, H. Imai, D. T. Lee, S. Nakano, and T. Tokuyama,\nEds., vol. 1627. Springer, 1999, pp. 1\u201317. [Online].", "mimetype": "text/plain", "start_char_idx": 4630, "end_char_idx": 6321, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ddff084-0d81-4436-83d5-cb9521cfd0bb": {"__data__": {"id_": "7ddff084-0d81-4436-83d5-cb9521cfd0bb", "embedding": null, "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52", "node_type": "4", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "3020a2103f31d68c3c490cf1572350e5996196b28647745b917e3207b7d8f4f0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "764e22a7-3ea2-4cf9-80b7-8fb61603fdee", "node_type": "1", "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}, "hash": "e55cbcdbb019e13b964ad28b2119925fae9ef20cfb5b01f9389e27e054532c24", "class_name": "RelatedNodeInfo"}}, "text": "3408. Springer, 2005, pp. 345\u2013359.\n[Online]. Available: https://doi.org/10.1007/978-3-540-31865-1 25\n[128] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and\nA. Tomkins, \u201cThe web as a graph: Measurements, models,\nand methods,\u201d in Computing and Combinatorics, 5th Annual\nInternational Conference, COCOON \u201999, Tokyo, Japan, July 26-\n28, 1999, Proceedings , ser. Lecture Notes in Computer Science,\nT. Asano, H. Imai, D. T. Lee, S. Nakano, and T. Tokuyama,\nEds., vol. 1627. Springer, 1999, pp. 1\u201317. [Online]. Available:\nhttps://doi.org/10.1007/3-540-48686-0 1\n[129] S. M. Iacus, G. King, and G. Porro, \u201cCausal inference without balance\nchecking: Coarsened exact matching,\u201d Political analysis , vol. 20, no. 1,\npp. 1\u201324, 2012.\n[130] H. Zhao, S. Liu, C. Ma, H. Xu, J. Fu, Z. Deng, L. Kong, and\nQ. Liu, \u201cGIMLET: A unified graph-text model for instruction-\nbased molecule zero-shot learning,\u201d in Advances in Neural\nInformation Processing Systems 36: Annual Conference on Neural\nInformation Processing Systems 2023, NeurIPS 2023, New Orleans,\nLA, USA, December 10 - 16, 2023 , A. Oh, T. Naumann,\nA. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., 2023.\n[Online]. Available: http://papers.nips.cc/paper files/paper/2023/hash/\n129033c7c08be683059559e8d6bfd460-Abstract-Conference.html", "mimetype": "text/plain", "start_char_idx": 5807, "end_char_idx": 7095, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"75881486-77b2-4239-8b63-75994378a112": {"doc_hash": "457b1147c1043aacc758a84c112b6a4765f74ea050e2779a3cd63772cb9b70fb", "ref_doc_id": "6cd0addb-54a2-401c-9293-89abce52365c"}, "f428f706-deda-42ae-902c-bb4f58b4bed8": {"doc_hash": "90bc213ac22ca2b068f9d8c9a540c2819b3a2b7db4517fa0488f547601996b1b", "ref_doc_id": "6cd0addb-54a2-401c-9293-89abce52365c"}, "57cbc7a7-66aa-40cf-ae44-8431c6df11ec": {"doc_hash": "528b90342e571c997863fa4ba90f32a75be10f8ba4dc7f1e721c44fcff5c5ead", "ref_doc_id": "6cd0addb-54a2-401c-9293-89abce52365c"}, "51127c00-5ceb-467a-b0a3-caa85af34564": {"doc_hash": "2a2fce7e88dd2b67eb2c491e79a83fbdce5506a8c6c0adb75612bcecfd4313a5", "ref_doc_id": "7bc5d992-276b-4dce-af34-5555472105c1"}, "42e86d8c-6918-49fe-8626-7b082fdaea39": {"doc_hash": "2d1ed08c8ca005fa465688e2f5bded7d81d3fc6aeace5c1b7a0278254a0f8799", "ref_doc_id": "7bc5d992-276b-4dce-af34-5555472105c1"}, "7d908595-7577-4425-b9a3-a9fb508ef678": {"doc_hash": "be63dce0d73a305dbeaf33c20d2f8ab1f002b5779572fa95b67d1975ce4efbcf", "ref_doc_id": "7bc5d992-276b-4dce-af34-5555472105c1"}, "5bb2c668-41e4-478d-97ba-8ac4c86c1102": {"doc_hash": "604ddfdf3481ee9e05951272dbb9480dd32852e842b4a41e5fad1fb67ecd8376", "ref_doc_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef"}, "e67eba12-fb45-4fa3-be1f-486d887e2bb5": {"doc_hash": "3cbf2ec10e593a86ab82fbd29e2f9785df0f7e3d2554302bbd1193311e40859d", "ref_doc_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef"}, "fb56eed8-d7d1-493e-acef-36c00ce3f746": {"doc_hash": "89e32f26b07b0d3b79f8b004dc8ed81e277b58d9e3ce3a1962287d7cda24fc7f", "ref_doc_id": "ad511b3a-3493-4365-b748-5f2416f1d3ef"}, "083c5355-3822-4dac-bc58-cb1441b6d345": {"doc_hash": "27fb6c39e40b597e109c713711efc99d310c1bfcce67e38d3de79afa5011053d", "ref_doc_id": "66598fac-9327-4310-81ba-8884891fb43e"}, "2e39ae4c-8895-4bc7-b47d-5dd231a7c694": {"doc_hash": "ef3cc905e9fa68414f52aab08c2668023aacad2bd625e601f6fbafe04d7b629b", "ref_doc_id": "66598fac-9327-4310-81ba-8884891fb43e"}, "6b73c03a-7057-4816-b22b-44b2473f6408": {"doc_hash": "1c57f25927105a7d1ee50450b910a7e99a3973b1521a38d90f34180cbd8762fe", "ref_doc_id": "66598fac-9327-4310-81ba-8884891fb43e"}, "7817e635-6610-4f17-a01d-1817b4c707bb": {"doc_hash": "919cf53b3df8a8d10c84c6b45ccff7ad9238f29c8cf4dfb6c10e71de9d3f9307", "ref_doc_id": "66598fac-9327-4310-81ba-8884891fb43e"}, "77d06247-7c8e-472f-aee9-e7b66e777805": {"doc_hash": "7b76258c948ed23ae0d3b87cf55c2cf25e7c0c432580045c3325f3731e60460b", "ref_doc_id": "574f9694-51c7-47c9-bd44-b78161bc75c0"}, "f2bdf622-04df-4aa2-a512-39c9ef57f172": {"doc_hash": "8dca356684f6ee43b00f68218e581343e63fca5238d8493224a75d8ea3c57d8f", "ref_doc_id": "574f9694-51c7-47c9-bd44-b78161bc75c0"}, "13ab9919-3750-4d34-a1c5-20e16355554a": {"doc_hash": "0d8e6e8478cf10106943ddcf90254f02a102c5c44be91d754f8dc4ba323db26f", "ref_doc_id": "574f9694-51c7-47c9-bd44-b78161bc75c0"}, "09d097f3-96ed-483d-a67a-7816d9204eb7": {"doc_hash": "687edfc0fbdb226a5fc26d983c9cfaa5059fe018d8dd4472848c073c6059942b", "ref_doc_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4"}, "4a036dc9-a064-410e-89b7-6a339245b223": {"doc_hash": "36924922ec09194738c63f4e8929c46b30dcb9efba03a46fec01c1dcf9b11fee", "ref_doc_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4"}, "3fbeeb20-c298-4836-ad21-9af69c034820": {"doc_hash": "d5af3eeb5d5ba5a00b2de449826b27a7dd730cf1ca95da511437c5bedc7e359f", "ref_doc_id": "210d1b6c-8484-43e3-b221-5e0462ad4cc4"}, "9910a34a-1acf-41cb-81d1-6b52b1132055": {"doc_hash": "3f330b601a605fa1aa11b6542f01a7e62d79ea5c6b58104a2650e0671d043702", "ref_doc_id": "e642579e-94d1-4167-bd49-35a00b42755f"}, "3e6e083a-4c82-4144-998f-04eb09eb2845": {"doc_hash": "5cc33f7040d3cbc6f81c1dd8791d70f23173f4f6795349ce493475f830f26898", "ref_doc_id": "e642579e-94d1-4167-bd49-35a00b42755f"}, "473267cb-b912-4ce8-96fc-9275f8ca408c": {"doc_hash": "779d694185f1a2160a6ee8c88713818a569cb3761439174f031f30ae0569e80e", "ref_doc_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987"}, "1365f001-2798-45be-9a09-b2ce3e137ad5": {"doc_hash": "eacb6d022ed2f4e184d65d6dea6384e09ef5c66f1d4ce27558000447f4619802", "ref_doc_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987"}, "d715779d-3df4-409e-adea-c4aa1b274b71": {"doc_hash": "5576dd2054dd4e3804dd91d48b63232af1113253cd09a2b5c0498e918c545fc2", "ref_doc_id": "8c6a0fd5-ba63-4f29-abc4-54384b714987"}, "ac154c45-0153-4bd7-a193-7a585b69b8f8": {"doc_hash": "587325470fc2f33135acae1b73c1f081de9414f8d31329ef9485755539ca78e2", "ref_doc_id": "73b1775f-5c5d-4d04-9781-24eeffc77174"}, "16f45661-8e39-47b5-b369-5dcde8079e86": {"doc_hash": "98eed3a692f36616d6019e9796b583e8e296f9802e0ecc7fd1e9ccbee084ee5e", "ref_doc_id": "73b1775f-5c5d-4d04-9781-24eeffc77174"}, "662f975b-3b80-44ef-a9e2-6b27ab361ad3": {"doc_hash": "b2094eb9c0a77586e12021015518e8626c35c099f6c7cd3fca54bc8cd1bdba69", "ref_doc_id": "73b1775f-5c5d-4d04-9781-24eeffc77174"}, "ef098096-5368-453c-8f3c-a65e61b8d0da": {"doc_hash": "aad8f5f8fa751db1642576873ce36e42c1b731ab7648d2485e81da201a2417df", "ref_doc_id": "68dff32f-927c-4c17-855c-9a312571a7a6"}, "e23b7d11-8522-45fa-b836-b617cb14a48c": {"doc_hash": "2ab5f37cdbab317bebede7d3fd7d8bf30ba1d5bea294f35f0eb8ea4c0f2233f1", "ref_doc_id": "68dff32f-927c-4c17-855c-9a312571a7a6"}, "22e35448-1073-4be6-ba5b-8a8fa5b71cbb": {"doc_hash": "9e521874667a18aec64842ba6e8f3c6743443df40f8d370170d98fc53cbbfb1c", "ref_doc_id": "68dff32f-927c-4c17-855c-9a312571a7a6"}, "fd6be985-59f8-4c74-aa36-87ab035a8ec7": {"doc_hash": "b99c3dff15c992ea8ea8110a7a30614e0b8cc45237365bd6d8387eb93d727a80", "ref_doc_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed"}, "658f33cd-d755-4d81-ac05-effd5fb8cee7": {"doc_hash": "d9b4d6628924f5c9aaaaa84e33f23b9fc604bc7ed18340137a05f0ca2055c051", "ref_doc_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed"}, "7129a5f0-2cff-4e87-be92-466b1e2f738c": {"doc_hash": "7b948bbe2029688a13b5b5c878a64011598cc70301c34b770f813fac4bd7f2a8", "ref_doc_id": "b2b98e6d-9e95-470a-a61c-6cffd53965ed"}, "1c23dcb4-26f5-47cb-9f56-ee9ac2bc66fa": {"doc_hash": "f160556e1c58a533eaed11d8dfd13b1c81ac38259fbce96839d37db9c952a48e", "ref_doc_id": "08d53ae4-bf38-4160-96cd-5714cb401e7e"}, "c261c705-1f41-4272-9cde-7d78eb378419": {"doc_hash": "084778b24913ea49930228e56ad7b5a33468d2ea8a32bb5098d49a97cb797cc9", "ref_doc_id": "08d53ae4-bf38-4160-96cd-5714cb401e7e"}, "2364dff8-cb51-4d62-bf6b-192430b80a39": {"doc_hash": "5f8c98b30669d7953b091bdd337bcca2bf004fe196011a4fafc2d55f041dcdfc", "ref_doc_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982"}, "f09384d9-35d4-4fde-ba8f-ce23f412e0d8": {"doc_hash": "33d6e628a89aa8da7a18f57e61b013ff91d44d7a15ef958e405d594814837fbd", "ref_doc_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982"}, "20fd018e-7887-4920-ba4d-751e6f972ec5": {"doc_hash": "716c5d6326b8d424195a57550ef4e88351c33ca32926f84f4ca504227f49fd24", "ref_doc_id": "3e605c8a-6fb8-4d4a-aaac-dd74db20b982"}, "97fbe4a2-1747-4cb6-bc19-1afc1299fba9": {"doc_hash": "76b91675b5084a0e566f32ac833d69b3c3ac7cc5923a5e7b19837b6df0a321eb", "ref_doc_id": "f085d5e4-0b19-4a6c-a7ae-2a7dc1808050"}, "8a2d87bd-651a-4cdf-9765-22ee0f97fc4e": {"doc_hash": "816d9c3ff86c4c81533de28a8e723e1d9bff75844b72e3f5a51be2471ef6f7c5", "ref_doc_id": "f085d5e4-0b19-4a6c-a7ae-2a7dc1808050"}, "ba43e147-174c-445f-8134-d207255f449c": {"doc_hash": "9fed75016df41cbc2152dc4e3701c9ac4a24ea25b4d3abf1e4995902e6fec374", "ref_doc_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c"}, "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc": {"doc_hash": "838e2ee95a8527905b9bc1bf0cd02cc4c0a15b396d3f7a8e1d2790c1d19b91f6", "ref_doc_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c"}, "f29c625b-2500-48d8-abcb-f0860007b797": {"doc_hash": "08069a30d0f07a1ff67388e530d9cc891bb4d077c99fecab74211bccba2980d9", "ref_doc_id": "c85e4b76-88a2-4247-bcf5-52073a5fd15c"}, "b4272bda-de67-42a8-a372-c60868934a2e": {"doc_hash": "212bc3f4fc673bab5e0db1cde265a3a7cae1923b4050cc5c592c1bdd4e6489c5", "ref_doc_id": "45917dba-0753-4365-8c31-c6ae446b4a70"}, "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c": {"doc_hash": "5828c71f78b5fdd8c977626fbc34344f94a62bc0c71bc2946e9fccada7d61c4d", "ref_doc_id": "45917dba-0753-4365-8c31-c6ae446b4a70"}, "2f800325-9f87-4567-95df-39f099ce6576": {"doc_hash": "6011b71f63c7dcff1227f7f479e323b7c2ed6b94dd16476305a23c46584267ca", "ref_doc_id": "45917dba-0753-4365-8c31-c6ae446b4a70"}, "3795f35d-9d1c-495b-b41f-4fdb28e3f281": {"doc_hash": "e753caf26dae4c65c1bb7700d136afe6be3cdfaf3dc94abefc64c820c31378e0", "ref_doc_id": "45917dba-0753-4365-8c31-c6ae446b4a70"}, "5af3080b-576f-4cbf-8bcb-e34fe4f59259": {"doc_hash": "412a6d3af4135e3135534754065bf87e28170faeb9caf681cf525f1276edd7bf", "ref_doc_id": "73ffba1a-3744-44b9-b40b-23f80d706a77"}, "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65": {"doc_hash": "aa18c9bf293fb220c8ecb7fd595628c9ab35087adfbfb6021155d57b6e340c02", "ref_doc_id": "73ffba1a-3744-44b9-b40b-23f80d706a77"}, "7f59b949-78ca-4fe2-8c95-3437eb10e622": {"doc_hash": "00523f52200cf453356bf54267ee1dfe295c6292ae593a1ee2e520afad7c26c7", "ref_doc_id": "73ffba1a-3744-44b9-b40b-23f80d706a77"}, "67dd2691-0fda-47f8-b2a6-8c0b9b5beff1": {"doc_hash": "a5300e28becd5740838ad27c15a96aa7abfb6cca2ae0ad1946980dfb7db3788b", "ref_doc_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315"}, "08955ce6-2570-448d-be28-3e8edfe82241": {"doc_hash": "17d54d7b8b84b2dac40cbb1531bc506ccf71f34b4251ab9a8ff6c384476ca2f8", "ref_doc_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315"}, "5f651246-5fa9-4967-b88b-206da360133f": {"doc_hash": "619909734d442de4969b26e706bc20488ce520decec5b33eabd756b1d58b02ae", "ref_doc_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315"}, "f571c7ef-c8ea-4264-888c-2d44d3847f0a": {"doc_hash": "680dc8ad5947eb780ac85d636d6118d23bd18e2b6615ea8ad3f917b073400fb5", "ref_doc_id": "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315"}, "32497538-d1fb-4035-81f0-92d347009f16": {"doc_hash": "c8b44b9ebaa3cb2c0c53f8ebb10566a37d5daff2b4550e4a93a6146e27e02fb7", "ref_doc_id": "09b99a8f-2296-4196-8f73-21e233697462"}, "89c04de1-534e-4c35-b326-0ab0a360183e": {"doc_hash": "f89705c9bee1c72605d2ed158cfb41b36b2fc98710e6032ae50093d118e0a4f1", "ref_doc_id": "09b99a8f-2296-4196-8f73-21e233697462"}, "45333901-a829-425f-9567-c62c03e0ac68": {"doc_hash": "fd6096fcace3b81c9b64507b07f146b171dca339715c4824940a8c80041ca59f", "ref_doc_id": "6ad0a921-d639-4813-8c5c-4d47f9632345"}, "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff": {"doc_hash": "d11e126642cf208b27d2909f20ae4415ba850eac15a3b3149033a1a892cf0e0b", "ref_doc_id": "6ad0a921-d639-4813-8c5c-4d47f9632345"}, "d3a91f10-768a-4593-bc07-5dbf88014b0a": {"doc_hash": "3985ed81878f0f6c4d17fef479d3647040a176902c304fb67965e7acf12eab84", "ref_doc_id": "6ad0a921-d639-4813-8c5c-4d47f9632345"}, "250bb72d-46e5-4860-ade6-1205ec9df923": {"doc_hash": "f3d102b95bf968bd643d65df225a8014f3073b9be286aaf02ee2d6398bdd5e01", "ref_doc_id": "87634c56-a74f-43c1-aad8-9d65949efca2"}, "6ac34f5d-b8da-4a0e-9d18-91dead60e538": {"doc_hash": "369cb2cad275d98126dccb7d2d878ad78be3e6e0900266bd30dc3fa1d541b745", "ref_doc_id": "87634c56-a74f-43c1-aad8-9d65949efca2"}, "aba5f559-5219-4853-bd75-cc0ee93fb232": {"doc_hash": "f1c1b5c6a0691893cc71a1380bf07ebb658ff13290d25b598e303fa131a3e790", "ref_doc_id": "87634c56-a74f-43c1-aad8-9d65949efca2"}, "bb26f8b0-e476-4eb2-9537-caa3f3afaf91": {"doc_hash": "2165a5f0364d5a074ae7003bd2edc3caf46948a8019d9981818a3c4bd317ec85", "ref_doc_id": "13558517-2121-4d6d-92b0-bc91292b9028"}, "1c7e32be-40b9-427c-869d-a7ccfc03fbef": {"doc_hash": "a1c07fb380c5a271df8cdc89fad8125096d199f59ee0edfdf15e78b0398af732", "ref_doc_id": "13558517-2121-4d6d-92b0-bc91292b9028"}, "27ccdbee-50f3-47a9-a617-1f446d497103": {"doc_hash": "36832eec0fa10c07421d160ea89f3cc2cdb21469f1b3cf64199cd7367756f002", "ref_doc_id": "13558517-2121-4d6d-92b0-bc91292b9028"}, "96ebaa49-9d6b-46c9-80c6-92475d954c54": {"doc_hash": "d95b8055e6ef9501a6f8e749706ffa8260ee0eb471a940089c546cd5390f3554", "ref_doc_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9"}, "352c9c51-58d2-4850-a51f-63861c78d891": {"doc_hash": "4739702c144778befc7ede7f8e6de212c094f3486b462a56aac626915d25ce45", "ref_doc_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9"}, "196898ed-09ee-482b-923c-9cc1ac53a6f0": {"doc_hash": "042331bd015b544416d6c85670cc24a963c80cb7814cd35f54dec66456dc779b", "ref_doc_id": "9b3a602f-db55-4f86-a044-cb704bb3d0c9"}, "2f82d87d-bd81-4350-a233-6409ce7f9607": {"doc_hash": "c79e9525facd13803b01eaa5cadbed6bbcda4e34057ca4de9b239f7cde8eb2a7", "ref_doc_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d"}, "bdd846e1-cd86-4f33-a2c7-c0c278433cf8": {"doc_hash": "daf72b25e3760925d352dcdea465782fd8e9456621dde52c699cf4d9300223b4", "ref_doc_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d"}, "d20a4616-c53d-4257-9898-e11e238f14c4": {"doc_hash": "8d38ac36ceff04c1fcccd801b54daaf73ba66eec6abeb640b5abce8600099e0a", "ref_doc_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d"}, "096a511e-ef7c-400a-a9e8-1dbd147f5fe3": {"doc_hash": "cad51a121077599aa07fbbdd3c597b7594a13ca70b974ae28bfa5173f253f940", "ref_doc_id": "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d"}, "ee01a3e6-62e1-4644-bb17-7fa563be1b0d": {"doc_hash": "1c4582010f000d769089a242a58e766e047b05a633d086a8a1855893ad0d02b9", "ref_doc_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9"}, "2b91e14b-7672-4a8f-ba39-914b9390036d": {"doc_hash": "c324c11dc4443cbd442719d8b2620ac4968a8269809ed324a7dffedae9c32550", "ref_doc_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9"}, "55473136-e48c-47ae-bab4-5e4b96fea556": {"doc_hash": "025fcd754272adfb48dd888d415d47dc2c54dde4856edc232548cb9418157094", "ref_doc_id": "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9"}, "4cc23ce9-d29a-44b8-a7e7-2b12a815cdb9": {"doc_hash": "dbf94fe636e4e4caba4cd5fc5edc735b33eaa310504669c0d4c0334e8a261b6c", "ref_doc_id": "56af9903-7901-4a28-91b4-5f83b247405c"}, "ed060282-fc21-41f3-a532-6e6d3d518dd1": {"doc_hash": "dda6fe4608bc059b1f344995587983efb97090df4923b9d526b734456e35ae1a", "ref_doc_id": "56af9903-7901-4a28-91b4-5f83b247405c"}, "c0164bfc-b3c2-49ee-a7e8-e7a4f2bb4b5b": {"doc_hash": "bb4dfa380049617aa9553ec6fb681a754a9e7e96a66298f311e56c48bfbd664a", "ref_doc_id": "56af9903-7901-4a28-91b4-5f83b247405c"}, "6a1cbdc7-4f67-4558-a2c6-99fc7bbc40f5": {"doc_hash": "882a2b827ad4baa23630e1abd5f281dbdb0513ae4c4772d04e171023432372c0", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "5543203c-33c9-4995-83a3-18593cdef42c": {"doc_hash": "34ef8fed5b934c685ee1781b8e8a12cc066f06478115f26ba8e58254dacce8d8", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "9aac336d-7b3f-4489-a2c0-9081dc0ca110": {"doc_hash": "920d8a90c02e21e7a454ee961d06bb7cf1cb275de934cd618877837476d21032", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "b3002362-6364-43f5-93e7-50920b1f4fc0": {"doc_hash": "cecb34116dcdefee144dfffaf2d454423b91f4e0fefc903a1560e3478495b7ee", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "b961c072-d993-40c0-a369-45a6efc6eeed": {"doc_hash": "e45bb49ecf49dddab3997d15af943434e69d99a0991cd57d4cfb1bc378f8d240", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949": {"doc_hash": "dc12391f0c62a3d2dec4f5325d4cbf6d46d424d7be1209ae00a6bd6ff20e44a6", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "8acc20fe-d363-4276-af2a-3d44ecb8f466": {"doc_hash": "dfc5f2d99f1746b946e0865a6378f835bb08facd37b5de5cda9442611fe36008", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "6a2ec6a2-9e40-44fc-964d-5aaaf09a2282": {"doc_hash": "4ccc39219a6d89d099c0e3139620557be868e662bd5e11662b48956448f2b68a", "ref_doc_id": "9abf7f28-c822-46b6-88c9-199f460b10fe"}, "87a4b8a4-31cc-46d3-908d-f100b2442ed8": {"doc_hash": "aa46721d2ca3a9609b6e46d637d62d7ac5b55e8b504bab76eb9f5e838ebae450", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "0301fa88-a83b-4f56-aa8b-48c084c0fa77": {"doc_hash": "dd92d32062b1ce9a721b02bb9a48b749d5865518b7f2e3c71b95babc2df784ad", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "9aa86cb5-8043-4dbe-84e2-7686b7fef05d": {"doc_hash": "30bd912b3ffae99402ae856cc7a931563da02b980dff12a1a85b14ebcfa4cb97", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "0b46e3fd-4a3b-49a9-a814-b5db393236e4": {"doc_hash": "806b50d6eb9da6c9de1dc3f9dacc7041eca932c60a0f4bdeb37aaafcd7832ee8", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "3ac3ae97-0054-4981-bd29-78503ad95039": {"doc_hash": "abc83d2e3f4a56f9afc93944a97d5ce2622ff8dc6c4ee1afb5b97afe27427eb4", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "4f359d3b-227c-48cc-9d26-cc2b10750cca": {"doc_hash": "815f03ca385277158c8f0efe90f06cb1200a32d15c2243cffada0f6af63534d8", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "4f5cc793-1438-4f32-a687-217142ef6457": {"doc_hash": "489f8e79b3f9cc58901de7bafddcf5cfc8b2c7b8931b855faad2385d9b93c682", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "734cb5cc-7cc9-4cc9-b522-cf908e3db6f4": {"doc_hash": "9a0d952c115b7472f0de84e73173b592aaf8326ea601ea99976ebe39f5113663", "ref_doc_id": "4f8e412a-2edd-4aef-a87a-6ec7dca17f29"}, "6f7d7314-1ae3-427f-a146-460318c9335c": {"doc_hash": "ddbe4bc70633c8ec52512176cf01877474658939581e5b4f526944234f6ccefb", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "ace06032-54c2-4e81-91b0-404d8ad0c9b7": {"doc_hash": "b43798f0770b8b2af7ba36f9a50e921a35b6bc68d661c83526c51c6bded80119", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "027908e7-c87d-4cba-8b44-341925a17360": {"doc_hash": "1c8276e28c4ac9dc5cc6679f0bf74a86b01e061b9d4fc15adea29a11cae4c05c", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "c6bb529c-30f0-4df9-8547-6e9c9cbc482d": {"doc_hash": "8d2c6e794888a13839122994ee3cdbbdc9ebe3b0ad61be5a8840e7789db9f0b7", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "da7918bb-d065-4ee6-96e3-0a49a93cf873": {"doc_hash": "68e91f10ace0123ee2a5445d6f89cdce7fe419eb5aafe1fcf3c450eb8666f6d7", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "7ab1a388-1eff-4adb-9fc1-d11b99b4726c": {"doc_hash": "346e723346b7e15f9d9d63900ddceb58106e508194407912b74de77a424490bd", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "d7c275b6-176d-4638-b5dc-7aaad1410237": {"doc_hash": "7f13d16706ac5a3ffbc0a99817f2c677bb17fcd7865d3ba7c964c5961668fbad", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "4dbfd63d-c564-49da-ad73-3e20e13ddd76": {"doc_hash": "86eee2140828411138238bb50d1eff59c3cf02de4cc51b6631b5c834f70a8af1", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "28498651-e607-421d-b77b-a3ec19b45639": {"doc_hash": "b3645f0aba4ab629f684d06f5ce5ee846220e5b83bab2be8ea4ca17a8eb6d1de", "ref_doc_id": "adf8c2b8-cd0b-41d0-80f9-8d2bede24329"}, "49be2be8-205e-4523-a4e4-12e608a7cd96": {"doc_hash": "39cd4862af46a50734fe16a486e46e9d5e01ba59b74565f6097536d10851f040", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "ec8200b0-4737-40db-8337-3f8500eb9a7f": {"doc_hash": "84ecfd3dc4533e71c5be4998b44a4f30de74367e32b900c5094a5afe1d6208be", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "939627df-1bd1-455b-848b-43aa27a3aaf0": {"doc_hash": "ce9341be27c1f8151d0311955aa3f4938d1b990594a30de426ced77ae5bb81f7", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "95a8130f-647b-45d4-8c8f-1e5709ba95e0": {"doc_hash": "0f90d9c024f262ad4f92ea729685a088312fb14d50727173c926c2ae2e202fee", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "210071f2-2831-46db-ba63-4edfb9c25d5c": {"doc_hash": "9c0a18970f78cc12e7c9b6d9982de2ca3f62e5bd72e42de4221d64b357ce2e5e", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "c758fb51-55e3-4428-8050-9cc2a4174e60": {"doc_hash": "4615d83a46bdbd0154b55598a42b8263d37a96525113104df1b75cf7bc631a83", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "b60e597e-a3ca-4151-afe2-3da552c920c8": {"doc_hash": "463c8411e0764d0df1aa6f7cb7d26b9a01ef81d2941bef2343939b754741521d", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "1247a8fd-38b6-474a-b730-a7154a99668c": {"doc_hash": "4aea1a6d5b7c07e55fda4a3434b6fccb6fbdd31586a0ba1b64a3655c25e6d3eb", "ref_doc_id": "044ed4d6-9688-48a3-87ab-e5401a28eaa0"}, "66cfa6e3-b60f-4469-acb4-8a05abfcf73f": {"doc_hash": "f4803cbdcbb4d4b867db098af048997e17935c60097807c693c3c87697f141c0", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}, "d10c7e39-872e-4002-8f91-e817750e97bf": {"doc_hash": "0582ef2793d05fccff041467560b72fdfab4560a06154323ba31e519745e469d", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}, "44d6e25a-4eb3-4ec5-9e27-14da843a43b6": {"doc_hash": "48c934bc3933191cc25aaa37db76e476fc5fba5f0c58db9db91aea16394a4cfb", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}, "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf": {"doc_hash": "15268c6e1acbe18419b2a836c961740c5249d7ba5abf14fbf4f0b8a123d8cd7c", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}, "764e22a7-3ea2-4cf9-80b7-8fb61603fdee": {"doc_hash": "e55cbcdbb019e13b964ad28b2119925fae9ef20cfb5b01f9389e27e054532c24", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}, "7ddff084-0d81-4436-83d5-cb9521cfd0bb": {"doc_hash": "932eade731a5e3d65d958ed952ecdcd2818f00efee9c9ff91fbf4fcd8f2ef54f", "ref_doc_id": "7b1d8efa-2ae8-42a7-a416-5a0101c31c52"}}, "docstore/ref_doc_info": {"6cd0addb-54a2-401c-9293-89abce52365c": {"node_ids": ["75881486-77b2-4239-8b63-75994378a112", "f428f706-deda-42ae-902c-bb4f58b4bed8", "57cbc7a7-66aa-40cf-ae44-8431c6df11ec"], "metadata": {"page_label": "1", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "7bc5d992-276b-4dce-af34-5555472105c1": {"node_ids": ["51127c00-5ceb-467a-b0a3-caa85af34564", "42e86d8c-6918-49fe-8626-7b082fdaea39", "7d908595-7577-4425-b9a3-a9fb508ef678"], "metadata": {"page_label": "2", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "ad511b3a-3493-4365-b748-5f2416f1d3ef": {"node_ids": ["5bb2c668-41e4-478d-97ba-8ac4c86c1102", "e67eba12-fb45-4fa3-be1f-486d887e2bb5", "fb56eed8-d7d1-493e-acef-36c00ce3f746"], "metadata": {"page_label": "3", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "66598fac-9327-4310-81ba-8884891fb43e": {"node_ids": ["083c5355-3822-4dac-bc58-cb1441b6d345", "2e39ae4c-8895-4bc7-b47d-5dd231a7c694", "6b73c03a-7057-4816-b22b-44b2473f6408", "7817e635-6610-4f17-a01d-1817b4c707bb"], "metadata": {"page_label": "4", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "574f9694-51c7-47c9-bd44-b78161bc75c0": {"node_ids": ["77d06247-7c8e-472f-aee9-e7b66e777805", "f2bdf622-04df-4aa2-a512-39c9ef57f172", "13ab9919-3750-4d34-a1c5-20e16355554a"], "metadata": {"page_label": "5", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "210d1b6c-8484-43e3-b221-5e0462ad4cc4": {"node_ids": ["09d097f3-96ed-483d-a67a-7816d9204eb7", "4a036dc9-a064-410e-89b7-6a339245b223", "3fbeeb20-c298-4836-ad21-9af69c034820"], "metadata": {"page_label": "6", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "e642579e-94d1-4167-bd49-35a00b42755f": {"node_ids": ["9910a34a-1acf-41cb-81d1-6b52b1132055", "3e6e083a-4c82-4144-998f-04eb09eb2845"], "metadata": {"page_label": "7", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "8c6a0fd5-ba63-4f29-abc4-54384b714987": {"node_ids": ["473267cb-b912-4ce8-96fc-9275f8ca408c", "1365f001-2798-45be-9a09-b2ce3e137ad5", "d715779d-3df4-409e-adea-c4aa1b274b71"], "metadata": {"page_label": "8", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "73b1775f-5c5d-4d04-9781-24eeffc77174": {"node_ids": ["ac154c45-0153-4bd7-a193-7a585b69b8f8", "16f45661-8e39-47b5-b369-5dcde8079e86", "662f975b-3b80-44ef-a9e2-6b27ab361ad3"], "metadata": {"page_label": "9", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "68dff32f-927c-4c17-855c-9a312571a7a6": {"node_ids": ["ef098096-5368-453c-8f3c-a65e61b8d0da", "e23b7d11-8522-45fa-b836-b617cb14a48c", "22e35448-1073-4be6-ba5b-8a8fa5b71cbb"], "metadata": {"page_label": "10", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "b2b98e6d-9e95-470a-a61c-6cffd53965ed": {"node_ids": ["fd6be985-59f8-4c74-aa36-87ab035a8ec7", "658f33cd-d755-4d81-ac05-effd5fb8cee7", "7129a5f0-2cff-4e87-be92-466b1e2f738c"], "metadata": {"page_label": "11", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "08d53ae4-bf38-4160-96cd-5714cb401e7e": {"node_ids": ["1c23dcb4-26f5-47cb-9f56-ee9ac2bc66fa", "c261c705-1f41-4272-9cde-7d78eb378419"], "metadata": {"page_label": "12", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "3e605c8a-6fb8-4d4a-aaac-dd74db20b982": {"node_ids": ["2364dff8-cb51-4d62-bf6b-192430b80a39", "f09384d9-35d4-4fde-ba8f-ce23f412e0d8", "20fd018e-7887-4920-ba4d-751e6f972ec5"], "metadata": {"page_label": "13", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "f085d5e4-0b19-4a6c-a7ae-2a7dc1808050": {"node_ids": ["97fbe4a2-1747-4cb6-bc19-1afc1299fba9", "8a2d87bd-651a-4cdf-9765-22ee0f97fc4e"], "metadata": {"page_label": "14", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "c85e4b76-88a2-4247-bcf5-52073a5fd15c": {"node_ids": ["ba43e147-174c-445f-8134-d207255f449c", "bcf9c034-bfff-4fa3-8bc1-011e6b899bdc", "f29c625b-2500-48d8-abcb-f0860007b797"], "metadata": {"page_label": "15", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "45917dba-0753-4365-8c31-c6ae446b4a70": {"node_ids": ["b4272bda-de67-42a8-a372-c60868934a2e", "470ec4f0-dc13-4d16-8a31-b0bc9f6dc40c", "2f800325-9f87-4567-95df-39f099ce6576", "3795f35d-9d1c-495b-b41f-4fdb28e3f281"], "metadata": {"page_label": "16", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "73ffba1a-3744-44b9-b40b-23f80d706a77": {"node_ids": ["5af3080b-576f-4cbf-8bcb-e34fe4f59259", "f64b2f42-d3a9-460d-8f6c-31aa3d4abf65", "7f59b949-78ca-4fe2-8c95-3437eb10e622"], "metadata": {"page_label": "17", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "eb4d4182-3c4c-4b6e-b1f4-82ede37b8315": {"node_ids": ["67dd2691-0fda-47f8-b2a6-8c0b9b5beff1", "08955ce6-2570-448d-be28-3e8edfe82241", "5f651246-5fa9-4967-b88b-206da360133f", "f571c7ef-c8ea-4264-888c-2d44d3847f0a"], "metadata": {"page_label": "18", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "09b99a8f-2296-4196-8f73-21e233697462": {"node_ids": ["32497538-d1fb-4035-81f0-92d347009f16", "89c04de1-534e-4c35-b326-0ab0a360183e"], "metadata": {"page_label": "19", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "6ad0a921-d639-4813-8c5c-4d47f9632345": {"node_ids": ["45333901-a829-425f-9567-c62c03e0ac68", "b23fdf35-d6f9-4bf2-95cb-e31b187e23ff", "d3a91f10-768a-4593-bc07-5dbf88014b0a"], "metadata": {"page_label": "20", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "87634c56-a74f-43c1-aad8-9d65949efca2": {"node_ids": ["250bb72d-46e5-4860-ade6-1205ec9df923", "6ac34f5d-b8da-4a0e-9d18-91dead60e538", "aba5f559-5219-4853-bd75-cc0ee93fb232"], "metadata": {"page_label": "21", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "13558517-2121-4d6d-92b0-bc91292b9028": {"node_ids": ["bb26f8b0-e476-4eb2-9537-caa3f3afaf91", "1c7e32be-40b9-427c-869d-a7ccfc03fbef", "27ccdbee-50f3-47a9-a617-1f446d497103"], "metadata": {"page_label": "22", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "9b3a602f-db55-4f86-a044-cb704bb3d0c9": {"node_ids": ["96ebaa49-9d6b-46c9-80c6-92475d954c54", "352c9c51-58d2-4850-a51f-63861c78d891", "196898ed-09ee-482b-923c-9cc1ac53a6f0"], "metadata": {"page_label": "23", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "c80ad9d4-e1fe-4165-89b8-564e19dd9c5d": {"node_ids": ["2f82d87d-bd81-4350-a233-6409ce7f9607", "bdd846e1-cd86-4f33-a2c7-c0c278433cf8", "d20a4616-c53d-4257-9898-e11e238f14c4", "096a511e-ef7c-400a-a9e8-1dbd147f5fe3"], "metadata": {"page_label": "24", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "dffbad19-fc3a-4ef2-b154-6aa53e48bdf9": {"node_ids": ["ee01a3e6-62e1-4644-bb17-7fa563be1b0d", "2b91e14b-7672-4a8f-ba39-914b9390036d", "55473136-e48c-47ae-bab4-5e4b96fea556"], "metadata": {"page_label": "25", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "56af9903-7901-4a28-91b4-5f83b247405c": {"node_ids": ["4cc23ce9-d29a-44b8-a7e7-2b12a815cdb9", "ed060282-fc21-41f3-a532-6e6d3d518dd1", "c0164bfc-b3c2-49ee-a7e8-e7a4f2bb4b5b"], "metadata": {"page_label": "26", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "9abf7f28-c822-46b6-88c9-199f460b10fe": {"node_ids": ["6a1cbdc7-4f67-4558-a2c6-99fc7bbc40f5", "5543203c-33c9-4995-83a3-18593cdef42c", "9aac336d-7b3f-4489-a2c0-9081dc0ca110", "b3002362-6364-43f5-93e7-50920b1f4fc0", "b961c072-d993-40c0-a369-45a6efc6eeed", "150c95a6-f2cf-48b3-a3a4-c3e9dcbfa949", "8acc20fe-d363-4276-af2a-3d44ecb8f466", "6a2ec6a2-9e40-44fc-964d-5aaaf09a2282"], "metadata": {"page_label": "27", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "4f8e412a-2edd-4aef-a87a-6ec7dca17f29": {"node_ids": ["87a4b8a4-31cc-46d3-908d-f100b2442ed8", "0301fa88-a83b-4f56-aa8b-48c084c0fa77", "9aa86cb5-8043-4dbe-84e2-7686b7fef05d", "0b46e3fd-4a3b-49a9-a814-b5db393236e4", "3ac3ae97-0054-4981-bd29-78503ad95039", "4f359d3b-227c-48cc-9d26-cc2b10750cca", "4f5cc793-1438-4f32-a687-217142ef6457", "734cb5cc-7cc9-4cc9-b522-cf908e3db6f4"], "metadata": {"page_label": "28", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "adf8c2b8-cd0b-41d0-80f9-8d2bede24329": {"node_ids": ["6f7d7314-1ae3-427f-a146-460318c9335c", "ace06032-54c2-4e81-91b0-404d8ad0c9b7", "027908e7-c87d-4cba-8b44-341925a17360", "c6bb529c-30f0-4df9-8547-6e9c9cbc482d", "da7918bb-d065-4ee6-96e3-0a49a93cf873", "7ab1a388-1eff-4adb-9fc1-d11b99b4726c", "d7c275b6-176d-4638-b5dc-7aaad1410237", "4dbfd63d-c564-49da-ad73-3e20e13ddd76", "28498651-e607-421d-b77b-a3ec19b45639"], "metadata": {"page_label": "29", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "044ed4d6-9688-48a3-87ab-e5401a28eaa0": {"node_ids": ["49be2be8-205e-4523-a4e4-12e608a7cd96", "ec8200b0-4737-40db-8337-3f8500eb9a7f", "939627df-1bd1-455b-848b-43aa27a3aaf0", "95a8130f-647b-45d4-8c8f-1e5709ba95e0", "210071f2-2831-46db-ba63-4edfb9c25d5c", "c758fb51-55e3-4428-8050-9cc2a4174e60", "b60e597e-a3ca-4151-afe2-3da552c920c8", "1247a8fd-38b6-474a-b730-a7154a99668c"], "metadata": {"page_label": "30", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}, "7b1d8efa-2ae8-42a7-a416-5a0101c31c52": {"node_ids": ["66cfa6e3-b60f-4469-acb4-8a05abfcf73f", "d10c7e39-872e-4002-8f91-e817750e97bf", "44d6e25a-4eb3-4ec5-9e27-14da843a43b6", "aa0d1fa4-3555-4bda-b58f-2e6c91d8e2cf", "764e22a7-3ea2-4cf9-80b7-8fb61603fdee", "7ddff084-0d81-4436-83d5-cb9521cfd0bb"], "metadata": {"page_label": "31", "file_name": "2404_14809v1.pdf", "Title of this paper": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications", "Authors": "Wenbo Shang, Xin Huang", "Date published": "04/23/2024", "URL": "http://arxiv.org/abs/2404.14809v1", "summary": "A graph is a fundamental data model to represent various entities and their\ncomplex relationships in society and nature, such as social networks,\ntransportation networks, financial networks, and biomedical systems. Recently,\nlarge language models (LLMs) have showcased a strong generalization ability to\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\nand specific-domain content generation. Compared with graph learning models,\nLLMs enjoy superior advantages in addressing the challenges of generalizing\ngraph tasks by eliminating the need for training graph learning models and\nreducing the cost of manual annotation. In this survey, we conduct a\ncomprehensive investigation of existing LLM studies on graph data, which\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\npoints out the existing remaining challenges and future directions.\nSpecifically, we study the key problems of LLM-based generative graph analytics\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\napplications. LLM-GQP focuses on an integration of graph analytics techniques\nand LLM prompts, including graph understanding and knowledge graph (KG) based\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\ngraphs, including graph learning, graph-formed reasoning and graph\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\nmodels. We also explore open problems and future directions in this exciting\ninterdisciplinary research area of LLMs and graph analytics."}}}}