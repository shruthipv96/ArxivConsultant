{"docstore/data": {"e8aa655b-29e6-4704-840b-85c2837539bd": {"__data__": {"id_": "e8aa655b-29e6-4704-840b-85c2837539bd", "embedding": null, "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "bfce3e3b595fbfb0aa6953765ddfdebc94050a593983fce75855f2f7b9004318", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d64b766-68be-49b4-b9d1-eb4881b0f0d8", "node_type": "1", "metadata": {}, "hash": "2171e02339b288f0d3ef95e2f97950eb7e5d0a9732900ceae1c1c1be3f725b79", "class_name": "RelatedNodeInfo"}}, "text": "How and Why LLMs Use Deprecated APIs in Code\nCompletion? An Empirical Study\nChong Wang\u2217, Kaifeng Huang\u2020, Jian Zhang\u2217, Yebo Feng\u2217, Lyuye Zhang\u2217, Yang Liu\u2217, and Xin Peng\u2021\n\u2217School of Computer Science and Engineering, Nanyang Technological University, Singapore\n{chong.wang, jian_zhang, yebo.feng}@ntu.edu.sg, zh0004ye@e.ntu.edu.sg, yangliu@ntu.edu.sg\n\u2020School of Software Engineering, Tongji University, China\nkaifengh@tongji.edu.cn\n\u2021School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China\npengxin@fudan.edu.cn\nAbstract \u2014Large language models (LLMs), pre-trained or\nfine-tuned on large code corpora, have shown effectiveness\nin generating code completions. However, in LLM-based code\ncompletion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid\nand continuous evolution of libraries. While existing studies have\nhighlighted issues with predicting incorrect APIs, the specific\nproblem of deprecated API usage in LLM-based code completion\nhas not been thoroughly investigated.\nTo address this gap, we conducted the first evaluation study\non deprecated API usage in LLM-based code completion. This\nstudy involved seven advanced LLMs, 145 API mappings from\neight popular Python libraries, and 28,125 completion prompts.\nThe study results reveal the status quo and root causes of\ndeprecated API usage in LLM-based code completion from the\nperspectives of model ,prompt , and library . Based on these findings,\nwe propose two lightweight fixing approaches, REPLACE API and\nINSERT PROMPT , which can serve as baseline approaches for\nfuture research on mitigating deprecated API usage in LLM-\nbased completion. Additionally, we provide implications for\nfuture research on integrating library evolution with LLM-driven\nsoftware development.\nI. I NTRODUCTION\nLarge language models (LLMs) [ 1,2,3,4,5,6] have\nsignificantly advanced various aspects of software engineering,\nincluding code completion [ 7,8], code understanding [ 9], and\nprogram repair [ 10,11]. These models, pre-trained or fine-tuned\nwith extensive knowledge of code on large corpora, are effective\nfor tailoring to different downstream tasks. In the realm of\ncode completion, the state-of-the-art has evolved from statistics-\nbased methods [ 12,13] to LLM-based techniques [ 14,15,16].\nCode completion is a sophisticated task that suggests variables,\nfunctions, classes, methods, and even entire code blocks, which\ndepends both on tools\u2019 capability and developers\u2019 practical\nneeds.\nMotivation. To accelerate development, developers heavily\nrely on third-party libraries, interacting with them through\nApplication Programming Interfaces (APIs). However, this\nreliance presents a challenge for code completion tools.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2765, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d64b766-68be-49b4-b9d1-eb4881b0f0d8": {"__data__": {"id_": "0d64b766-68be-49b4-b9d1-eb4881b0f0d8", "embedding": null, "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "bfce3e3b595fbfb0aa6953765ddfdebc94050a593983fce75855f2f7b9004318", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e8aa655b-29e6-4704-840b-85c2837539bd", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "f5417f99347ab77e8aca5a0389e48b56f9d044939c464ddaa3fc877e6bc3ff92", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ed7f7466-a6bf-4152-9e52-2b80bced6b35", "node_type": "1", "metadata": {}, "hash": "2e07339ea4a1fa38490e3cb1c43ce8211e4d511b38bdec9a34971ff5dca51dce", "class_name": "RelatedNodeInfo"}}, "text": "These models, pre-trained or fine-tuned\nwith extensive knowledge of code on large corpora, are effective\nfor tailoring to different downstream tasks. In the realm of\ncode completion, the state-of-the-art has evolved from statistics-\nbased methods [ 12,13] to LLM-based techniques [ 14,15,16].\nCode completion is a sophisticated task that suggests variables,\nfunctions, classes, methods, and even entire code blocks, which\ndepends both on tools\u2019 capability and developers\u2019 practical\nneeds.\nMotivation. To accelerate development, developers heavily\nrely on third-party libraries, interacting with them through\nApplication Programming Interfaces (APIs). However, this\nreliance presents a challenge for code completion tools. Third-\nparty libraries constantly evolve to undergo refactorings [ 17],\nfix bugs [ 18], apply security patches [ 19], or introduce new\nfeatures. This rapid evolution leads to frequent API changes,\nwith older APIs being deprecated and replaced by newer ones.Deprecated APIs are discouraged to use because they might not\nwork well with newer features or data. These outdated APIs\nwill eventually disappear in future library updates [ 20]. Taking\nPyTorch [ 21], a popular deep learning library for instance, the\nAPI torch.gels() was deprecated in version 1.2 (August 2019)\nin favor of torch.lstsq() . Then, torch.lstsq() was deprecated\nin version 1.9 (June 2021) in favor of torch.linalg.lstsq() .\nConsequently, newly developed code should avoid using the\ndeprecated torch.gels() andtorch.lstsq() . Therefore, it\u2019s crucial\nfor code completion tools to suggest the correct, up-to-dated\nAPIs to developers.\nLiterature. However, to the best of our knowledge, the\ncapabilities of LLM-based code completion regarding API\ndeprecation is understudied [22, 23]. Although there emerges\na substantial number of evaluation on code completion, a body\nof research focused on assessing the overall accuracy across\nvarious benchmarks [ 9,24,25,26,27]. Interestingly, Ding et\nal.[28] identified undefined names and unused variables as the\nmost common syntactic errors produced by LLMs in Python\ncode completions. Izadi et al. [29] found that incorrect function\nname predictions were prevalent, accounting for 23% of all\ntoken-level errors. Furthermore, Liu et al. [30] highlighted\nthe issue of hallucinations in LLM-generated code. Their\nfindings indicate the prevalence and potential risks of using\nunexpected APIs. Nevertheless, while researchers have noted\nthe prevalence of incorrect function name predictions, they\nhave not investigated this issue in depth. Library APIs, which\nconstitute an important part in predicting external function\nnames, are worth attached importance to.\nStudy. To address this gap, we conducted a study to\nexamine the issue of deprecated API usage in LLM-based code\ncompletion.", "mimetype": "text/plain", "start_char_idx": 2044, "end_char_idx": 4855, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ed7f7466-a6bf-4152-9e52-2b80bced6b35": {"__data__": {"id_": "ed7f7466-a6bf-4152-9e52-2b80bced6b35", "embedding": null, "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "bfce3e3b595fbfb0aa6953765ddfdebc94050a593983fce75855f2f7b9004318", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d64b766-68be-49b4-b9d1-eb4881b0f0d8", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "07e53b52fbcef0dbe7417c6a2f7f861d654677c4378fe765b2fe43505fdb83ff", "class_name": "RelatedNodeInfo"}}, "text": "Interestingly, Ding et\nal.[28] identified undefined names and unused variables as the\nmost common syntactic errors produced by LLMs in Python\ncode completions. Izadi et al. [29] found that incorrect function\nname predictions were prevalent, accounting for 23% of all\ntoken-level errors. Furthermore, Liu et al. [30] highlighted\nthe issue of hallucinations in LLM-generated code. Their\nfindings indicate the prevalence and potential risks of using\nunexpected APIs. Nevertheless, while researchers have noted\nthe prevalence of incorrect function name predictions, they\nhave not investigated this issue in depth. Library APIs, which\nconstitute an important part in predicting external function\nnames, are worth attached importance to.\nStudy. To address this gap, we conducted a study to\nexamine the issue of deprecated API usage in LLM-based code\ncompletion. The study aims to answer the primary research\nquestion:\nWhat are the status quo and root causes of deprecated\nand replacing API usage in LLM-based code completion?\nThis question is explored through three detailed aspects:\nModel Perspective (RQ1) investigates the status quo and root\ncauses based on the performance of various LLMs;arXiv:2406.09834v1  [cs.SE]  14 Jun 2024", "mimetype": "text/plain", "start_char_idx": 4000, "end_char_idx": 5227, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "985bf3e8-9ac6-4377-9830-bd40e63cc4df": {"__data__": {"id_": "985bf3e8-9ac6-4377-9830-bd40e63cc4df", "embedding": null, "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "6b69903b460414782330f0f17283d1c8a5a90b7765bd7d2e673a7d34c671d97e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "30c4eaaf-3038-4969-ae1c-67dfff2da784", "node_type": "1", "metadata": {}, "hash": "db52ebaa73d309a753ffbcb489eb9e79d7a3d9e6e07bd4987af47d3969347ef7", "class_name": "RelatedNodeInfo"}}, "text": "Prompt Perspective (RQ2) examines the impact of different\nprompts on the status quo and root causes;\nLibrary Perspective (RQ3) analyzes the status quo and root\ncauses across different libraries.\nTo address these research questions, we conducted a series\nof experiments involving various libraries and LLMs. We\ncollected 145 API mappings between deprecated APIs and\ntheir replacements from eight popular Python libraries. Based\non these mappings, we retrieved 9,022 outdated functions\nand 19,103 up-to-dated functions using the deprecated APIs\nand replacing APIs, respectively. Each outdated or up-to-dated\nfunction was transformed into a line-level completion prompt\nby identifying the deprecated or replacing API and removing\nthe containing and subsequent lines. The located API is referred\nto as the reference API. These prompts were then inputted\ninto seven advanced code LLMs, including CodeLlama [ 5] and\nGPT-3.5, to generate completions and analyze the predicted\nAPI usages. If the predicted API usage corresponds to either\nthe deprecated or replacement version of the reference API, it is\nannotated as plausible ; otherwise, it is annotated as irrelevant .\nThe study results reveal the following findings: Answer\nto RQ1: All seven evaluated LLMs encounter challenges in\npredicting plausible API usages and face issues with deprecated\nAPI usages, due to the presence of deprecated API usages\nduring model training and the absence of API deprecation\nknowledge during model inference. Answer to RQ2: For\nthe two categories of prompts derived from outdated and\nup-to-dated functions, the LLMs\u2019 performance in predicting\nplausible and deprecated API usages differs significantly,\ninfluenced by the distinct code context characteristics of these\nprompts. Answer to RQ3: Across the eight libraries, the LLMs\nexhibit significant differences in their use of deprecated APIs,\ninfluenced by the characteristics of API deprecations during\nthe evolution of these libraries.\nApproach. Based on the study results and findings, we devel-\noped two lightweight fixing approaches to mitigate deprecated\nAPI usage in LLM-based code completion. Given a completion\ncontaining a deprecated API usage, the first approach, named\nREPLACE API, directly replaces the deprecated API usage\nwith the replacement and regenerates the remaining parts\n(e.g., argument list) during the decoding process. The second\napproach, named INSERT PROMPT , inserts an additional\nreplacing prompt after the original prompt to guide the LLMs\nto use the replacement API and then regenerate the completions.\nWe then evaluate the effectiveness of the proposed approaches\nin terms of fixing deprecated API usages and the accuracy in\npredicting line-level completions ( RQ4 ). The evaluation results\ndemonstrate that REPLACE API effectively addresses deprecated\nAPI usages for all evaluated open-source LLMs, achieving fix\nrates exceeding 85% with acceptable accuracy measured by\nEdit Similarity and Exact Match compared to ground-truth\ncompletions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3003, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "30c4eaaf-3038-4969-ae1c-67dfff2da784": {"__data__": {"id_": "30c4eaaf-3038-4969-ae1c-67dfff2da784", "embedding": null, "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "6b69903b460414782330f0f17283d1c8a5a90b7765bd7d2e673a7d34c671d97e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "985bf3e8-9ac6-4377-9830-bd40e63cc4df", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "926e1557e002152025526ae0e37b8a62aae361018e19dea60287ed4c17199973", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c705b20e-0dc7-4f37-9b58-b2ab0ebae75e", "node_type": "1", "metadata": {}, "hash": "a858b225ea48c1ea9ed273a6e851c28a0033ec4a69beff26c1565f706e2b0073", "class_name": "RelatedNodeInfo"}}, "text": "Given a completion\ncontaining a deprecated API usage, the first approach, named\nREPLACE API, directly replaces the deprecated API usage\nwith the replacement and regenerates the remaining parts\n(e.g., argument list) during the decoding process. The second\napproach, named INSERT PROMPT , inserts an additional\nreplacing prompt after the original prompt to guide the LLMs\nto use the replacement API and then regenerate the completions.\nWe then evaluate the effectiveness of the proposed approaches\nin terms of fixing deprecated API usages and the accuracy in\npredicting line-level completions ( RQ4 ). The evaluation results\ndemonstrate that REPLACE API effectively addresses deprecated\nAPI usages for all evaluated open-source LLMs, achieving fix\nrates exceeding 85% with acceptable accuracy measured by\nEdit Similarity and Exact Match compared to ground-truth\ncompletions. While INSERT PROMPT does not currently achieve\nsufficient effectiveness and accuracy in fixing completions\ncontaining deprecated API usages, it shows potential for future\nexploration.\nTo summarize, this paper makes the following contributions:\u2022The first study that reveals the status quo and root causes\nof deprecated API usages from model perspective, prompt\nperspective, and library perspective. The study involves\nseven advanced LLMs, 145 API mappings from eight\npopular Python libraries, and 28,125 prompts derived from\n9,022 outdated functions and 19,103 up-to-dated functions.\n\u2022Two lightweight fixing approaches, named REPLACE API\nand INSERT PROMPT , which can serve as baseline ap-\nproaches for future research on mitigating deprecated API\nusage in LLM-based completion.\n\u2022The implications that provide potential research directions\non the synergy of library evolution and LLM-driven\nsoftware development.\nII. R ELATED WORK\nWe review the related work with respect to library evolution\nand LLM-based code completion.\nA. Library Evolution\nLibrary evolution involves refactorings [ 17], bug fixes [ 18],\nand new feature introductions. Typically, refactorings can depre-\ncate old APIs and introduce new replacements. Several studies\nhave examined the reasons that developers deprecate APIs and\nhow the clients react to such deprecations [ 31,32,33,34]. The\nreasons include improving readability, reducing redundancy,\navoiding bad code practices and fixing functional bugs. Depre-\ncated APIs can affect hundreds of clients [ 35], particularly when\nclients struggle to keep pace with rapidly evolving software\n[36]. McDonnell et al. [ 37] found that only 22% of outdated\nAPI usages are eventually upgraded to use replacement APIs.\nSimilarly, Hora et al. [ 38] found that client developers consumes\nconsiderate time to discover and apply replacing APIs, with\nthe majority of systems not reacting at all. When clients do\nnot upgrade their APIs, they silently accumulate technical\ndebt in the form of future API changes when they finally\nupgrade [ 39].", "mimetype": "text/plain", "start_char_idx": 2131, "end_char_idx": 5053, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c705b20e-0dc7-4f37-9b58-b2ab0ebae75e": {"__data__": {"id_": "c705b20e-0dc7-4f37-9b58-b2ab0ebae75e", "embedding": null, "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "6b69903b460414782330f0f17283d1c8a5a90b7765bd7d2e673a7d34c671d97e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "30c4eaaf-3038-4969-ae1c-67dfff2da784", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "5f7289c6677109ebcea62411ee2f5389ab97dccc3c31c185c1f61902cdbbf00d", "class_name": "RelatedNodeInfo"}}, "text": "Several studies\nhave examined the reasons that developers deprecate APIs and\nhow the clients react to such deprecations [ 31,32,33,34]. The\nreasons include improving readability, reducing redundancy,\navoiding bad code practices and fixing functional bugs. Depre-\ncated APIs can affect hundreds of clients [ 35], particularly when\nclients struggle to keep pace with rapidly evolving software\n[36]. McDonnell et al. [ 37] found that only 22% of outdated\nAPI usages are eventually upgraded to use replacement APIs.\nSimilarly, Hora et al. [ 38] found that client developers consumes\nconsiderate time to discover and apply replacing APIs, with\nthe majority of systems not reacting at all. When clients do\nnot upgrade their APIs, they silently accumulate technical\ndebt in the form of future API changes when they finally\nupgrade [ 39]. To locate the replacing API, existing works\nleverage change rules written by developers [ 40], developer\nrecordings [ 41], similarity matching [ 42], mining API usage in\nlibraries [ 43], and in client projects [ 44]. Henkel and Diwan\n[41] developed an IDE plugin that allows library developers to\nrecord API refactoring actions and client developers to replay\nthem. Godfrey and Zou [ 45] proposed a semi-automated origin\nanalysis using similarities in name, declaration, complexity\nmetrics, and call dependencies. Wu et al. [ 46] introduced a\nhybrid approach combining call dependency and text similarity\nanalysis to identify API change rules. Recently, (author?) [47]\nproposed RepFinder to find replacement APIs for deprecated\nAPIs in library updates from multiple sources.\nIn this work, we aim to comprehend the statuses and causes\nof deprecated API usages in LLM-based code completion and\nprovide implications for mitigating the deprecated API usages.\nB. LLM-based Code Completion\nCode completion is an important functionality in modern\nIDEs and editors. Historically, researchers have explored\nstatistical models [ 12,13]. With the advent in natural language", "mimetype": "text/plain", "start_char_idx": 4223, "end_char_idx": 6216, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fb2ebb7c-593a-4b86-ac70-23bd48011946": {"__data__": {"id_": "fb2ebb7c-593a-4b86-ac70-23bd48011946", "embedding": null, "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44e499e2-84d9-471a-bb89-e79885547d8c", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7624e0037116e379e221cc7304fea4541299d1137825b3d228ce7a48597ed550", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6bffa0af-c2fd-4965-8d55-8c53d0135ecf", "node_type": "1", "metadata": {}, "hash": "bfd150d8d6109024e3c66047001732b8daa0ae6eb16e2dcf1a5b67005233bebe", "class_name": "RelatedNodeInfo"}}, "text": "Study Setup(Sec. 3)Study Results(Sec. 4)\nAPIMapping CollectionCompletion Prompt Construction\nRQ1:Model PerspectiveRQ2:Prompt PerspectiveLLM-based Code Completion\nCode CompletionsLibrary Docs\nRQ3:Library PerspectiveStatusQuooAPI Usage PlausibilityoDeprecatedUsageRate\nMitigation Approaches(Sec. 5)Approach 1:ReplaceAPIApproach 2: InsertPromptRQ4:EffectivenessoFixed RateoEdit SimilarityoExactMatch\nCode Repos\nLLMs\nCompletionResultAnnotation\noRoot Cause AnalysisRoot Causes\nFig. 1: Overview of Our Study\nprocessing, researchers have embraced deep learning for code\ncompletion [ 7,8] because they are similar in token-based\nprediction. To explore the capability of code completion tools\ndriven by large language models (LLMs) [ 14,15,16], numerous\nevaluations of LLMs have been proposed. Ciniselli et al.\n[26,27] conducted a large-scale study exploring the accuracies\nof state-of-the-art Transformer-based models in supporting code\ncompletion at various granularity levels, from single tokens to\nentire code segments. Zeng et al. [ 9] found that pre-trained\nmodels significantly outperform non-pre-trained state-of-the-art\ntechniques in program understanding tasks. They also reveal\nthat no single pre-trained model dominates across all tasks.\nXu et al. [ 24] evaluated the performance of LLMs on the\nHumanEval dataset. Ding et al. [ 28] identified undefined names\nand unused variables as the most common errors produced\nby language models in Python code completions. Izadi et al.\n[29] evaluated the LLMs using real auto-completion usage\ndata across 12 languages. They found that incorrect function\nname predictions, were prevalent, accounting for 23% of all\ntoken-level errors errors. Besides, Liu et al. [ 25] proposed\nEvaluPlus, which benchmarks the functional correctness of\nLLM-synthesized code using test cases. In addition to accuracy\nconcerns, LLM-based approaches face issues such as security\nvulnerabilities and hallucinations. Sallou et al. [ 48] explored\nthreats posed by LLMs, including unpredictability in model\nevolution, data leakage, and reproducibility. Liu et al. [ 30]\ncategorized the hallucinations brought by LLM-generated code.\nThe findings on incorrect function predictions partially\nmotivate our study.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2224, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6bffa0af-c2fd-4965-8d55-8c53d0135ecf": {"__data__": {"id_": "6bffa0af-c2fd-4965-8d55-8c53d0135ecf", "embedding": null, "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44e499e2-84d9-471a-bb89-e79885547d8c", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7624e0037116e379e221cc7304fea4541299d1137825b3d228ce7a48597ed550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb2ebb7c-593a-4b86-ac70-23bd48011946", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "d07c3b2a338b80b70ca30a6c1bcb43bc9279731425d15b447292cb993cc19b10", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6962cab4-99cf-4faa-9046-7e4ec07da786", "node_type": "1", "metadata": {}, "hash": "b35d819b008f74cc6e179a3f3cf6d8e31232c744ba4f2ef2086f4373af26809b", "class_name": "RelatedNodeInfo"}}, "text": "Izadi et al.\n[29] evaluated the LLMs using real auto-completion usage\ndata across 12 languages. They found that incorrect function\nname predictions, were prevalent, accounting for 23% of all\ntoken-level errors errors. Besides, Liu et al. [ 25] proposed\nEvaluPlus, which benchmarks the functional correctness of\nLLM-synthesized code using test cases. In addition to accuracy\nconcerns, LLM-based approaches face issues such as security\nvulnerabilities and hallucinations. Sallou et al. [ 48] explored\nthreats posed by LLMs, including unpredictability in model\nevolution, data leakage, and reproducibility. Liu et al. [ 30]\ncategorized the hallucinations brought by LLM-generated code.\nThe findings on incorrect function predictions partially\nmotivate our study. However, our study focuses on the severity\nof predicting deprecated API usages in LLM-based code\ncompletion.TABLE I: Statistics of our Collected API Mappings in Eight\nPython Libraries\nLibrary Version # Mappings# Functions\nOutdated Up-to-dated\nNumpy 1.26.4 3 567 2,988\nPandas 2.2.2 10 69 69\nscikit-learn 1.5.0 18 985 1,197\nSciPy 1.13.0 4 245 1,458\nseaborn 0.13.2 3 904 1,329\nTensorFlow 2.16.1 57 1,491 4,830\nPyTorch 2.3.0 21 4,726 6,406\nTransformers 4.40.2 29 100 63\nTotal \u2013 145 9,022 19,103\nIII. S TUDY SETUP\nWe chose Python, a popular programming language which\nranks first among the most popular ones based in the recent\nyear [ 49]. We targeted eight popular Python libraries. Five of\nthese libraries were used in a previous study on Python API\ndeprecation [ 19], including Numpy, Pandas, scikit-learn, SciPy,\nand seaborn. Additionally, we added three popular deep learning\nlibraries, i.e.,TensorFlow1, PyTorch2, and Transformers3. The\nsetup of our study is presented in Figure 1. It includes four steps.\nThe API Mapping Collection step gathers mappings between\ndeprecated APIs and their replacements from various libraries.\nThe Completion Prompt Construction step involves creating\ncompletion prompts by identifying instances of deprecated and\nreplacement API usage in open-source Python repositories.\nThe LLM-Based Code Completion step uses various LLMs\nto generate code completions for these prompts. Finally, the\nCompletion Result Annotation step automatically annotates the\ngenerated completions and calculates relevant metrics.", "mimetype": "text/plain", "start_char_idx": 1465, "end_char_idx": 3760, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6962cab4-99cf-4faa-9046-7e4ec07da786": {"__data__": {"id_": "6962cab4-99cf-4faa-9046-7e4ec07da786", "embedding": null, "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44e499e2-84d9-471a-bb89-e79885547d8c", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7624e0037116e379e221cc7304fea4541299d1137825b3d228ce7a48597ed550", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6bffa0af-c2fd-4965-8d55-8c53d0135ecf", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "55c598e9aa5f85818729cadfc654d65ff00d594bf4774208ca9266790f9000d6", "class_name": "RelatedNodeInfo"}}, "text": "We targeted eight popular Python libraries. Five of\nthese libraries were used in a previous study on Python API\ndeprecation [ 19], including Numpy, Pandas, scikit-learn, SciPy,\nand seaborn. Additionally, we added three popular deep learning\nlibraries, i.e.,TensorFlow1, PyTorch2, and Transformers3. The\nsetup of our study is presented in Figure 1. It includes four steps.\nThe API Mapping Collection step gathers mappings between\ndeprecated APIs and their replacements from various libraries.\nThe Completion Prompt Construction step involves creating\ncompletion prompts by identifying instances of deprecated and\nreplacement API usage in open-source Python repositories.\nThe LLM-Based Code Completion step uses various LLMs\nto generate code completions for these prompts. Finally, the\nCompletion Result Annotation step automatically annotates the\ngenerated completions and calculates relevant metrics.\nA. API Mapping Collection\nWe identified API mappings ( i.e.,deprecated APIs and the\nmapping replacements) from the documentation and change\nlogs from each library following the previous study [ 19].\nSpecifically, we reviewed the documentation and change logs of\neach library and manually look for deprecated API occurrences\nwhich indicate the corresponding the mapping replacements.\nFor instance, in the API documentation of PyTorch, version\n1.9.0 [ 50], a deprecation message indicates that \u201ctorch.lstsq() is\ndeprecated in favor of torch.linalg.lstsq() and will be removed in\na future PyTorch release. \u201d , where the mapping of the deprecated\nAPI to the replacing API is torch.lstsq \u2192torch.linalg.lstsq . For\none-to-many mappings ( i.e.,one deprecated API mapped to\nmultiple replacing APIs), we split them into many one-to-one\nmappings. In total, the authors obtained 145 API mappings.\nThe statistics of the API mappings are presented Table I.\n1https://www.tensorflow.org/\n2https://pytorch.org/\n3https://huggingface.co/docs/transformers/index", "mimetype": "text/plain", "start_char_idx": 2860, "end_char_idx": 4803, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d69a6ae0-a550-4168-a970-644ba5fe7867": {"__data__": {"id_": "d69a6ae0-a550-4168-a970-644ba5fe7867", "embedding": null, "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "0072f08a7c36a7c8a3dc8f513e2e3bf7729f060246f1cf98237e6b0ebea0103c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6", "node_type": "1", "metadata": {}, "hash": "90aed304996771df4611a356408f5a6d7b0e45e21b660b26b98ae29e60d6a233", "class_name": "RelatedNodeInfo"}}, "text": "B. Completion Prompt Construction\nWe constructed code completion prompts by searching the\ndeprecated API and replacing API usages from open-source\nPython repositories.\n1) Outdated and Up-to-dated Function Location.: We uti-\nlized Sourcegraph [ 51], a widely used code search service. It\nsupports integration with GitHub where we can retrieve Python\nsource files from millions of open-source code repositories. For\neach deprecated or replacing API, we constructed search queries\nusing both its full qualified name (FQN) ( e.g., torch.lstsq ) and\na logical disjunction of its constituent parts ( e.g., \u201ctorch AND\nlinalg AND lstsq\u201d) to ensure comprehensive retrieval. For each\nretrieved Python source file, we parsed it into an Abstract\nSyntax Tree (AST) and extracted the containing functions that\ninvoked the deprecated or replacing APIs. Specifically, we\nlocated function definition nodes in the AST and traversed its\ndescendants. For each descendant, we checked if it is a function\ncall node and matched the function call to the deprecated or\nreplacing APIs. To correctly match the function call via API\nFQNs, we performed lightweight object type resolution and\nAPI alias resolution, similar to [19].\n\u2022Object Type Resolution : In the object-oriented program-\nming (OOP) languages, the APIs can be encapsulated into\na class as a method. Therefore, determining the FQN of the\nAPI invocation need to resolve the corresponding type of\nthe invoking object. For example, the pandas library defines\na core class DataFrame with a member method loc() and\nthe client creates an object of class DataFrame , assigns to a\nvariable dt, and invokes the method using dt.loc() . Typically,\nit requires resolving the type of dt. To that end, we analyzed\ntheassign statements to track object definitions, enabling\nus to determine the class names for objects in function\ncalls and infer the called APIs. For instance, if the object\n\u201cdt\u201d in the call dt.loc() was created in a preceding assign\nstatement ( dt = pandas.DataFrame(...) ), we could infer that\nthe corresponding API was pandas.DataFrame.loc() .\n\u2022API Alias Resolution : Developers can alias packages,\nclasses, and functions in Python using the import-as\nfeature [ 52]. This mechanism requires resolving API aliases\nby analyzing import statements. For example, the pandas\npackage is often imported with the alias \u201cpd\u201d via the state-\nment import pandas as pd . In this case, pd.DataFrame.loc()\nwas resolved to pandas.DataFrame.loc() . Additionally,\nPython provides a from-import mechanism allowing\ndevelopers to use APIs with short names instead of their\nFQNs. For example, through from torch.linalg import lstsq ,\nthe API in torch.linalg can be directly called via lstsq() .\nThese short names were also resolved by analyzing the\nimport statements.\nAfter the lightweight object type resolution and API alias\nresolution, we obtained the corresponding FQN for each\nfunction call.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2915, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6": {"__data__": {"id_": "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6", "embedding": null, "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "0072f08a7c36a7c8a3dc8f513e2e3bf7729f060246f1cf98237e6b0ebea0103c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d69a6ae0-a550-4168-a970-644ba5fe7867", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "82aaf5654ce62dfc1115e7683da00a96e4f05ed749122081d281290fc4297f2e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8a751a7e-8269-4a3b-ab57-23056b03605d", "node_type": "1", "metadata": {}, "hash": "afc94f301ef7e4a8bd7aa26e645899b77ab1ee89bdd917889d01ce75fdd56ac1", "class_name": "RelatedNodeInfo"}}, "text": "\u2022API Alias Resolution : Developers can alias packages,\nclasses, and functions in Python using the import-as\nfeature [ 52]. This mechanism requires resolving API aliases\nby analyzing import statements. For example, the pandas\npackage is often imported with the alias \u201cpd\u201d via the state-\nment import pandas as pd . In this case, pd.DataFrame.loc()\nwas resolved to pandas.DataFrame.loc() . Additionally,\nPython provides a from-import mechanism allowing\ndevelopers to use APIs with short names instead of their\nFQNs. For example, through from torch.linalg import lstsq ,\nthe API in torch.linalg can be directly called via lstsq() .\nThese short names were also resolved by analyzing the\nimport statements.\nAfter the lightweight object type resolution and API alias\nresolution, we obtained the corresponding FQN for each\nfunction call. We checked whether the corresponding FQNs\nmatched the APIs in the collected API mappings, identifying\nthe first matched API as the reference API.\nAPI Mapping:   torch.lstsq  ->  torch.linalg.lstsqCompletion PromptReference APIFig. 2: Illustration of Completion Prompt Construction for An\nUp-to-dated Function.\nWe denote the containing function as an outdated function\nif a deprecated API was matched. Meanwhile, we denote it as\nanup-to-dated function if a replacing API was matched. In\ntotal, we collected Python 113,660 source files by querying\nSourceGraph. Among them, we extracted 9,022 outdated and\n19,103 up-to-dated functions. The statistics of the outdated and\nup-to-dated functions are presented in Table I.\n2) Incomplete Code Extraction.: In the task of code com-\npletion, developers usually have started with a few lines of\ncode and pause in the middle, waiting for LLMs to return\nthe suggested content based on the upward context. Therefore,\nto evaluate the performance of LLMs in the scenario, we\nconstructed the line-level code completion prompts . For each\noutdated or up-to-dated function, we located the invocation line\nof the deprecated or replacing APIs, respectively. We collected\nthe preceding lines before the invocation line into our line-\nlevel code completion prompts for an outdated or up-to-dated\nfunction, which is usually incomplete.\nFigure 2 represents one of our collected up-to-dated functions.\nThe function invokes a API of PyTorch, i.e., torch.linalg.lstsq\nin the fourth line. The line-level code completion prompt for\nthis function is highlighted in the wine-red dotted rectangle.\nAfter processing all outdated and up-to-dated functions, we\nobtained two corresponding datasets, denoted as OandU,\nrespectively. Each sample in OandUwas formatted as ( pmpt ,\ndep\u2192rep), where pmpt is a code completion prompt pmpt\nanddep\u2192repdenotes an API mapping from the deprecated\nAPI to the corresponding replacing API.\nC. LLM-based Code Completion\nWe leverage multiple LLMs in the code completion task to\nobserve their performance.", "mimetype": "text/plain", "start_char_idx": 2086, "end_char_idx": 4965, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a751a7e-8269-4a3b-ab57-23056b03605d": {"__data__": {"id_": "8a751a7e-8269-4a3b-ab57-23056b03605d", "embedding": null, "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "0072f08a7c36a7c8a3dc8f513e2e3bf7729f060246f1cf98237e6b0ebea0103c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "fd1ee196804d48d9d9d8a46af01d967729a64651ea889848d980aec54bbe0668", "class_name": "RelatedNodeInfo"}}, "text": "We collected\nthe preceding lines before the invocation line into our line-\nlevel code completion prompts for an outdated or up-to-dated\nfunction, which is usually incomplete.\nFigure 2 represents one of our collected up-to-dated functions.\nThe function invokes a API of PyTorch, i.e., torch.linalg.lstsq\nin the fourth line. The line-level code completion prompt for\nthis function is highlighted in the wine-red dotted rectangle.\nAfter processing all outdated and up-to-dated functions, we\nobtained two corresponding datasets, denoted as OandU,\nrespectively. Each sample in OandUwas formatted as ( pmpt ,\ndep\u2192rep), where pmpt is a code completion prompt pmpt\nanddep\u2192repdenotes an API mapping from the deprecated\nAPI to the corresponding replacing API.\nC. LLM-based Code Completion\nWe leverage multiple LLMs in the code completion task to\nobserve their performance. The LLMs include both open-source\nand closed-source models, whose parameter sizes ranges from\n350 million to 175 billion. The complete list of the LLMs are\npresented in Table II.\n\u2022CodeGen-350m, 2b, 6b : CodeGen [ 3] is a family of\nlarge language models developed by Salesforce specifically\nfor code generation. These models are trained on diverse\nprogramming languages and are designed to assist in\nwriting code by providing intelligent code suggestions and\ncompletions.\n\u2022DeepSeek-1.3b : DeepSeek-Coder [ 6] is designed on top\nof advanced transformer-based models tailored for code-\nrelated applications. This model is trained on a diverse\nset of coding repositories, which include a variety of", "mimetype": "text/plain", "start_char_idx": 4103, "end_char_idx": 5660, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc767552-1244-45fc-93a1-f8e8727c5606": {"__data__": {"id_": "dc767552-1244-45fc-93a1-f8e8727c5606", "embedding": null, "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "d1d4766067c38aa00e27c35817d26c3508d060d42e2401c10ea4e77d974e6a76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a6d6f873-ddda-43c4-816a-74094468b294", "node_type": "1", "metadata": {}, "hash": "5032e3c4c008f21b1330a67bb9cea22ca28313be46a19d8270b2f75104184940", "class_name": "RelatedNodeInfo"}}, "text": "programming languages and coding styles. It combines\nstate-of-the-art machine learning techniques to provide\nrobust code suggestions and completions.\n\u2022StarCoder2-3b : StarCoder2 [ 4] is an advanced language\nmodel optimized for coding tasks. It leverages large-scale\npre-training on code datasets to understand programming\nlanguages deeply. StarCoder2 excels in code completion,\nbug detection, and code translation, making it a valuable\ntool for developers seeking to enhance their coding effi-\nciency and accuracy.\n\u2022CodeLlama-7b : CodeLlama [ 5] is a specialized variant of\nMeta\u2019s LLaMA architecture [ 53], adapted for programming\ntasks. It is designed to support developers by providing\ncode suggestions, completing code snippets, and assisting\nin debugging. CodeLlama is trained on a vast corpus of\nprogramming languages and can perform a variety of code-\nrelated tasks with high proficiency.\n\u2022GPT-3.5 : GPT-3.5 [ 54] is a general-purpose language\nmodel developed by OpenAI. While it is not exclusively\ndesigned for coding, it possesses powerful code generation\ncapabilities due to its extensive training on diverse text,\nincluding programming languages. GPT-3.5 can understand\nand generate code across various languages, making it\na versatile tool for code completion, documentation, and\ncoding assistance. When used for code-related tasks, an\ninstruction (prompt) is often provided to guide the model\nto generate the desired code output.\nIn our implementation, the first six code LLMs were\ndownloaded from Hugging Face [ 55]. For LLMs with\nPython-specific versions available, we utilized those versions\nto improve completion results for Python functions.\nConsequently, the versions used for CodeGen and\nCodeLlama were CodeGen-{350M,2B,6B}-mono\nand CodeLlama-7b-Python-hf , which were\nfine-tuned on additional Python corpora. For\nDeepSeek and StarCoder2, the versions employed\nwere deepseek-coder-1.3b-instruct and\nstarcoder2-3b , respectively. For the general purpose\nLLM, i.e.,GPT-3.5, we queried the model via its official online\nAPIs [ 56], using the gpt-3.5-turbo version released in\nJanuary 2024.\nFor the six LLMs specifically tailored for code-related tasks,\ni.e.,three versions of CodeGen, DeepSeek, StarCoder2, and\nCodeLlama, the constructed prompts can be directly fed into\nthe models to generate completions. Meanwhile, for the general-\npurpose GPT-3.5, we provided an instruction to ensure accurate\ncode completion for the constructed prompts. The instruction\nwas: \u201cComplete and output the next line for the following\nPython function: pmpt \u201d.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2557, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a6d6f873-ddda-43c4-816a-74094468b294": {"__data__": {"id_": "a6d6f873-ddda-43c4-816a-74094468b294", "embedding": null, "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "d1d4766067c38aa00e27c35817d26c3508d060d42e2401c10ea4e77d974e6a76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc767552-1244-45fc-93a1-f8e8727c5606", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "5589b3ddf255dc5ab3b28275e17efaad286ea8cd7d925e33300cba5a8706c1f1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ac7e86f-5390-4fba-827e-5b7841194cd1", "node_type": "1", "metadata": {}, "hash": "c349101e7c2436a925df6ba4c25abce211d024400ace7877ef6d1f68151cb4d8", "class_name": "RelatedNodeInfo"}}, "text": "For\nDeepSeek and StarCoder2, the versions employed\nwere deepseek-coder-1.3b-instruct and\nstarcoder2-3b , respectively. For the general purpose\nLLM, i.e.,GPT-3.5, we queried the model via its official online\nAPIs [ 56], using the gpt-3.5-turbo version released in\nJanuary 2024.\nFor the six LLMs specifically tailored for code-related tasks,\ni.e.,three versions of CodeGen, DeepSeek, StarCoder2, and\nCodeLlama, the constructed prompts can be directly fed into\nthe models to generate completions. Meanwhile, for the general-\npurpose GPT-3.5, we provided an instruction to ensure accurate\ncode completion for the constructed prompts. The instruction\nwas: \u201cComplete and output the next line for the following\nPython function: pmpt \u201d. For all these LLMs, we utilized greedy\ndecoding ( i.e.,choosing the token with highest possibility at\neach decoding step) to generate one completion for each prompt\ninOorU. The maximal output token limit was set to 50. The\ngreedy decoding for GPT-3.5 was implemented through setting\nthe temperature parameter to 0.\nFormally, the procedure of LLM-based completion is definedTABLE II: Evaluated Large Language Models (LLMs).\nModel # Parameters Open-Source\nCodeGen-350m 350 million \u2713\nCodeGen-2b 2 billion \u2713\nCodeGen-6b 6 billion \u2713\nDeepSeek-1.3b 1.3 billion \u2713\nStarCoder2-3b 3 billion \u2713\nCodeLlama-7b 7 billion \u2713\nGPT-3.5 175 billion \u2717\nas:\ncomp\u2190LLM (pmpt )\nD. Completion Result Annotation\nFor each sample ( pmpt ,dep\u2192rep), we examined the\ncompletions generated by LLMs and determine whether the\nstudied API was predicted and whether the deprecated API or\nreplacing API was predicted. Specifically, we extract the FQN\nof the API invocation in the predicted line using the same\nobject type resolution and API alias resolution in Sec. III-B 1.\nThe annotation procedure is formally described as follows,\ncomp is the completion result:\n{good,bad,irrelevant } \u2190 annotate (comp )\nSpecifically, bad denotes that the LLM gives a completion\nsuggestion using a deprecated API, i.e., the FQN of an\ninvocating API was matched to dep;good denotes the LLM\ngives a completion suggestion using a replacing API, i.e.,the\nFQN of an invocating API was matched to rep;irrelevant\ndenotes that the LLM suggests neither of the mapping APIs.\nMoreover, if a completion was annotated as either badorgood ,\nwe treat it as plausible . This indicates that the LLM successfully\nunderstood the code context and selected a plausible API\nfunctionality.", "mimetype": "text/plain", "start_char_idx": 1829, "end_char_idx": 4268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ac7e86f-5390-4fba-827e-5b7841194cd1": {"__data__": {"id_": "5ac7e86f-5390-4fba-827e-5b7841194cd1", "embedding": null, "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "d1d4766067c38aa00e27c35817d26c3508d060d42e2401c10ea4e77d974e6a76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a6d6f873-ddda-43c4-816a-74094468b294", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "49e274767cd20a3ed32dc2e909b879cbde32b68cbc0e26c191e1630a45553891", "class_name": "RelatedNodeInfo"}}, "text": "Specifically, we extract the FQN\nof the API invocation in the predicted line using the same\nobject type resolution and API alias resolution in Sec. III-B 1.\nThe annotation procedure is formally described as follows,\ncomp is the completion result:\n{good,bad,irrelevant } \u2190 annotate (comp )\nSpecifically, bad denotes that the LLM gives a completion\nsuggestion using a deprecated API, i.e., the FQN of an\ninvocating API was matched to dep;good denotes the LLM\ngives a completion suggestion using a replacing API, i.e.,the\nFQN of an invocating API was matched to rep;irrelevant\ndenotes that the LLM suggests neither of the mapping APIs.\nMoreover, if a completion was annotated as either badorgood ,\nwe treat it as plausible . This indicates that the LLM successfully\nunderstood the code context and selected a plausible API\nfunctionality.\nWe investigate the performance of the LLMs using the\nfollowing metrics:\n\u2022API Usage Plausibility (AUP): This metric measures the\nportion of plausible completions, which were annotated as\ngood orbad. AUP is defined as:\nAUP =1\n|P|X\npmpt\u2208PI(annotate (LLM (pmpt ))\u2208 {good,bad})\n\u2022Deprecated Usage Rate (DUR): This metric calculates\nthe rate of plausible completions that were annotated as\nbad. DUR is defined as:\nDUR =P\npmpt\u2208PI(annotate (LLM (pmpt )) = bad)P\npmpt\u2208PI(annotate (LLM (pmpt ))\u2208 {good,bad})\nIn these equations, Pis the prompt set corresponding to O\norU, andI(\u00b7)is a binary function that returns 1 if the passed\nargument is true and 0 otherwise.", "mimetype": "text/plain", "start_char_idx": 3434, "end_char_idx": 4919, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03742b21-750a-4466-a34a-1cda4a78c6ca": {"__data__": {"id_": "03742b21-750a-4466-a34a-1cda4a78c6ca", "embedding": null, "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "dba47ad447cc2cfe16800095fe8e4f2c3f9e97d20205a69d500a67527a253485", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a5e0295-b273-4f53-a41b-d6d107627d14", "node_type": "1", "metadata": {}, "hash": "ba7f9f594904de142269a1826a4355619862393229faa0bd28c6c7e6db8aec17", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 3: Distribution of good ,bad, and irrelevant Completions\nby LLMs for Prompts from OandU\nTABLE III: AUP and DUR Metrics for O,U, and Overall\nDataset ( i.e.,All =O \u222a U )\nModelAUP (%) DUR (%)\nO U All O U All\nCodeGen-350m 8.6 14.2 12.3 77.7 9.0 24.9\nCodeGen-2b 19.0 25.2 23.1 89.6 11.3 32.6\nCodeGen-6b 26.1 30.9 29.3 90.0 11.1 34.2\nDeepSeek-1.3b 10.2 13.4 12.3 69.7 11.6 27.2\nStarCoder-3b 8.8 10.9 10.2 79.4 17.0 34.4\nCodeLlama-7b 27.6 32.1 30.6 86.9 12.1 34.2\nGPT-3.5 13.5 16.0 15.2 85.7 17.8 37.4\nIV. S TUDY RESULTS\nWe present the experimental results and key findings on the\nstatus quo and root causes of deprecated and replacement API\nusage in LLM-based code completion. As illustrated in Figure 1,\nthe results are categorized into three detailed aspects: Model\nPerspective (RQ1), Prompt Perspective (RQ2), and Library\nPerspective (RQ3). For each RQ, the results and findings are\npresented by first showing the status quo through API Usage\nPlausibility andDeprecated Usage Rate , followed by providing\nan in-depth Root Cause Analysis .\nA. RQ1: Model Perspective for Status Quo and Cause Analysis\n1) Status Quo Analysis: Figure 3 shows the distribution of\ngood andbadcompletions by the different LLMs, and Table III\npresents the AUP and DUR metrics.\nAPI Usage Plausibility. The completion distribution and\nthe low AUP highlight that all the LLMs faced challenges in\npredicting plausible API usages for the given prompts. The\nAUP of the LLMs for overall dataset ( i.e.,All=O\u222aU ) ranges\nfrom 10% to 30%, indicating that a majority of predictions\nwere irrelevant . Among the LLMs, CodeLlama-7b achieved\nthe highest AUP (30.6%), while StarCoder2-3b had the lowest\noverall AUP (10.2%).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1684, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a5e0295-b273-4f53-a41b-d6d107627d14": {"__data__": {"id_": "3a5e0295-b273-4f53-a41b-d6d107627d14", "embedding": null, "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "dba47ad447cc2cfe16800095fe8e4f2c3f9e97d20205a69d500a67527a253485", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "03742b21-750a-4466-a34a-1cda4a78c6ca", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "098a56ce5e28a117f576e2b8e5e0b61eb84571e9bee00e98aca818fa22151366", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "287659e0-6a62-46b2-b623-10c48f3be32b", "node_type": "1", "metadata": {}, "hash": "60a916553fd25293c630f2854c9427af06ccc39a5a6d18b6fa87d57029a9329e", "class_name": "RelatedNodeInfo"}}, "text": "A. RQ1: Model Perspective for Status Quo and Cause Analysis\n1) Status Quo Analysis: Figure 3 shows the distribution of\ngood andbadcompletions by the different LLMs, and Table III\npresents the AUP and DUR metrics.\nAPI Usage Plausibility. The completion distribution and\nthe low AUP highlight that all the LLMs faced challenges in\npredicting plausible API usages for the given prompts. The\nAUP of the LLMs for overall dataset ( i.e.,All=O\u222aU ) ranges\nfrom 10% to 30%, indicating that a majority of predictions\nwere irrelevant . Among the LLMs, CodeLlama-7b achieved\nthe highest AUP (30.6%), while StarCoder2-3b had the lowest\noverall AUP (10.2%). This may be attributed to the fact that\nStarCoder2 was not specifically fine-tuned on additional Python\ncorpora, unlike other LLMs such as CodeLlama and CodeGen.Comparing the three versions of CodeGen suggests that the\ncapacity of LLMs to predict plausible API usages increased\nwith model size ( i.e.,12.3%, 23.1%, and 29.3% for CodeGen-\n350m, -2b, and -6b, respectively), given the model architecture\nand training data remain consistent. However, it\u2019s noteworthy\nthat the largest LLM, GPT-3.5, did not achieve a high AUP\n(15.2%), possibly due to the instruction used not being finely\ntuned with advanced prompt engineering techniques such as\nchain-of-thought (COT) [ 57] and in-context learning (ICL) [ 58].\nFinding 1: All the evaluated LLMs faced challenges in\npredicting plausible API usages, with AUP ranging from\n10% to 30%. Effectiveness of the LLMs in code completion\ngenerally improved with model size and language-specific\nfine-tuning.\nDeprecated Usage Rate. The distribution shown in Figure 3,\nalong with the DUR metric presented in Table III, indicates\nthat all LLMs faced issues with using deprecated API usages.\nThe DUR of the LLMs for the overall dataset ( i.e., All\n=O \u222a U ) ranges from 25% to 38%, with larger models\n(e.g., CodeGen-6b, CodeLlama-7b, and GPT-3.5) generally\npredicting more usages of deprecated APIs. Considering the\ndifferences among the LLMs, CodeLlama-7b and CodeGen-\n6b demonstrated the best balance between AUP and DUR.\nThey achieved significant improvements in AUP compared to\nother LLMs, with a comparable DUR of 34.2%. Conversely,\nStarCoder2-3b and GPT-3.5 exhibited higher DUR ( i.e.,34.4%\nand 37.4%) despite having much lower AUP.", "mimetype": "text/plain", "start_char_idx": 1041, "end_char_idx": 3356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "287659e0-6a62-46b2-b623-10c48f3be32b": {"__data__": {"id_": "287659e0-6a62-46b2-b623-10c48f3be32b", "embedding": null, "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "dba47ad447cc2cfe16800095fe8e4f2c3f9e97d20205a69d500a67527a253485", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a5e0295-b273-4f53-a41b-d6d107627d14", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "d84015b91217a50d7e26602059cd17fc536945c9c778c0de4e2a909408eb3202", "class_name": "RelatedNodeInfo"}}, "text": "The DUR of the LLMs for the overall dataset ( i.e., All\n=O \u222a U ) ranges from 25% to 38%, with larger models\n(e.g., CodeGen-6b, CodeLlama-7b, and GPT-3.5) generally\npredicting more usages of deprecated APIs. Considering the\ndifferences among the LLMs, CodeLlama-7b and CodeGen-\n6b demonstrated the best balance between AUP and DUR.\nThey achieved significant improvements in AUP compared to\nother LLMs, with a comparable DUR of 34.2%. Conversely,\nStarCoder2-3b and GPT-3.5 exhibited higher DUR ( i.e.,34.4%\nand 37.4%) despite having much lower AUP. These results\nindicate that the preference of LLMs for using deprecated\nor replacing APIs is not closely related to their capacity for\npredicting plausible completions.\nFinding 2: All the evaluated LLMs faced issues with\ndeprecated API usages, with DUR ranging from 25% to\n38%, and larger models exhibiting higher DUR. Among\nthe LLMs, CodeLlama-7b and CodeGen-6b demonstrated\nthe best balance between AUP and DUR.\n2) Root Cause Analysis: From the model perspective, the\ncauses of deprecated API usages can be divided into two main\npoints:\nModel Training: The LLMs were trained on large-scale code\ncorpora, primarily collected from code repositories. As libraries\nevolved, both deprecated APIs and their replacements were\nused in software development, leading to training corpora\ncontaining instances of deprecated API usages. For instance,\nin this study, we collected 9,022 functions from open-source\ncode corpora that used deprecated APIs. When trained on such\ndata, LLMs might \u201cmemorize\u201d these deprecated APIs and their\nusage contexts as part of the learned knowledge [ 59,60]. The\ndifferent training corpora also led to the different AUP and\nDUR of the LLMs.\nModel Inference: During the inference stage, LLMs generated\ncompletions by predicting token probabilities based on their\nlearned prior knowledge ( e.g., the memorized API usage", "mimetype": "text/plain", "start_char_idx": 2810, "end_char_idx": 4695, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "36e3e2f2-34b3-485d-8c4c-e6f3c11cc2d4": {"__data__": {"id_": "36e3e2f2-34b3-485d-8c4c-e6f3c11cc2d4", "embedding": null, "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7580c9f4562aaf12a40470f21b7e69c1dbee6fb16c90cc9fd74ae3d4f1cc1b4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "94565e18-a11a-43e1-a068-323f08a8f7cc", "node_type": "1", "metadata": {}, "hash": "f25c6b3ea325a27c19584c6e9f84fb821ca76d33f80d66bb6c56c5909cceac13", "class_name": "RelatedNodeInfo"}}, "text": "contexts) and applying token selection strategies ( e.g., greedy\nsearch or beam search). Given certain contexts, LLMs were\nlikely to predict deprecated API usages due to the high token\nprobabilities, without considering any posterior knowledge\nabout API deprecations.\nFinding 3: There are two primary reasons why LLMs\npredict deprecated APIs: the presence of deprecated API\nusages in corpora during model training, and the absence of\nposterior knowledge about API deprecations during model\ninference.\nB. RQ2: Prompt Perspective for Status Quo and Cause Analysis\n1) Status Quo Analysis: Table III presents the AUP and\nDUR metrics for prompts from the two datasets, i.e.,Oand\nU.\nAPI Usage Plausibility. Between the prompts from the\ntwo different datasets, OandU, there are some differ-\nences in AUP for all LLMs, with relative differences ( i.e.,\n(AUPU\u2212AUPO)/AUPO) ranging from 16% to 65%. This\ndisparity may be attributed to the imbalance in the number\nof outdated and up-to-dated functions in the LLMs\u2019 training\ncorpora [ 61,62]. Indirect evidence for this is that, in this\nstudy, the up-to-dated functions collected from open-source\ncode repositories were about twice as many as the outdated\nfunctions ( i.e.,19,103 vs.9,022), even though there was no\ncollection preference. Given that LLMs were often trained on\nopen-source code repositories, they likely learned more up-to-\ndated functions than outdated functions, leading to better AUP\nfor the Udataset. Additionally, larger LLMs showcased smaller\nAUP differences ( e.g., 16% for CodeLlama-7b), possibly due\nto the better generalizability.\nFinding 4: The LLMs showcased difference in AUP\nbetween the two datasets OandU. This difference is\npossibly attributed to the different distribution of outdated\nand up-to-dated functions in the training corpora of LLMs.\nDeprecated Usage Rate. When considering OandU\nseparately, all LLMs consistently demonstrated extremely high\ndeprecated usage rates for O(70%-90% DUR) and relatively\nlow rates for U(9%-18% DUR). This significant difference is\nalso evident in the distribution of good andbad completions\nshown in Figure 3. In fact, for plausible completions, the rate\nofreference API usages ( i.e.,the usages used in the original\nfunctions) equals AUP for O, while it is (1\u2212AUP )forU.\nConsidering this rate, there is no noticeable difference between\nOandU(i.e., around 70%-90% for both). This suggests\nthat LLMs predicted the reference APIs for most prompts\nfrom both datasets, influenced by their differing characteristics.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2519, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "94565e18-a11a-43e1-a068-323f08a8f7cc": {"__data__": {"id_": "94565e18-a11a-43e1-a068-323f08a8f7cc", "embedding": null, "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7580c9f4562aaf12a40470f21b7e69c1dbee6fb16c90cc9fd74ae3d4f1cc1b4e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36e3e2f2-34b3-485d-8c4c-e6f3c11cc2d4", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "da9e68fb2d89ffcf4849e160d3121ba6fac5e07607e6df6b0231f7c4fab63f52", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7ec9e23-6b59-48f1-88ea-f51ced473ada", "node_type": "1", "metadata": {}, "hash": "a6336355933cfceb0c296f944da7542265414ee1bacca446a3d3cd091a9072e5", "class_name": "RelatedNodeInfo"}}, "text": "Deprecated Usage Rate. When considering OandU\nseparately, all LLMs consistently demonstrated extremely high\ndeprecated usage rates for O(70%-90% DUR) and relatively\nlow rates for U(9%-18% DUR). This significant difference is\nalso evident in the distribution of good andbad completions\nshown in Figure 3. In fact, for plausible completions, the rate\nofreference API usages ( i.e.,the usages used in the original\nfunctions) equals AUP for O, while it is (1\u2212AUP )forU.\nConsidering this rate, there is no noticeable difference between\nOandU(i.e., around 70%-90% for both). This suggests\nthat LLMs predicted the reference APIs for most prompts\nfrom both datasets, influenced by their differing characteristics.\nNonetheless, the 9%-18% DUR for Uindicates that LLMs still\npredicted the usage of deprecated APIs, even for the prompts\nfrom up-to-dated functions.Finding 5: The LLMs consistently exhibited a significant\ndifference in DUR between the two datasets, OandU,\nwith extremely high deprecated API usage rates for O\n(70%-90% DUR) and relatively low rates for U(9%-18%\nDUR).\n2) Root Cause Analysis: The contextual characteristics\nof the input completion prompts can significantly influence\nLLMs\u2019 use of deprecated APIs. Since the completions were\ngenerated based on the input prompts, specific contexts can\nlead LLMs to use deprecated APIs. As presented above, the\nLLMs showed significantly different DUR for prompts from\nOandU. Upon comparing the prompts from the two datasets,\nwe found that contextual characteristics of the prompts, such\nas specific objects, control flows, and data flows, often lead\nthe LLMs\u2019 predictions, i.e.,whether to use deprecated APIs or\ntheir replacements.\nFinding 6: The contextual characteristics of the input\nprompts, such as the defined objects, control flows, and data\nflows, is a significant influence on the use of deprecated\nAPIs.\nC. RQ3: Library Perspective for Status Quo and Cause\nAnalysis\nWe also conducted a detailed analysis to examine the LLMs\u2019\ncompletions across different libraries.\n1) Status Quo Analysis: The status quo from library per-\nspective focuses on how the AUP and DUR metrics vary with\ndifferent libraries.\nAPI Usage Plausibility. The results of API usage plausibility\nare illustrated in the scatter plots depicted in Figure 4, where\neach data point signifies the AUP of an LLM for a specific\nlibrary. Across the 8 libraries, most LLMs exhibited relatively\nlow API usage plausibility for both OandU, with AUP below\n30%.", "mimetype": "text/plain", "start_char_idx": 1814, "end_char_idx": 4288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f7ec9e23-6b59-48f1-88ea-f51ced473ada": {"__data__": {"id_": "f7ec9e23-6b59-48f1-88ea-f51ced473ada", "embedding": null, "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7580c9f4562aaf12a40470f21b7e69c1dbee6fb16c90cc9fd74ae3d4f1cc1b4e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "94565e18-a11a-43e1-a068-323f08a8f7cc", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b386a45ce1d82b49ec1021e4c40f43eb69b3f98960ce03db3bf8449deb0bf716", "class_name": "RelatedNodeInfo"}}, "text": "Finding 6: The contextual characteristics of the input\nprompts, such as the defined objects, control flows, and data\nflows, is a significant influence on the use of deprecated\nAPIs.\nC. RQ3: Library Perspective for Status Quo and Cause\nAnalysis\nWe also conducted a detailed analysis to examine the LLMs\u2019\ncompletions across different libraries.\n1) Status Quo Analysis: The status quo from library per-\nspective focuses on how the AUP and DUR metrics vary with\ndifferent libraries.\nAPI Usage Plausibility. The results of API usage plausibility\nare illustrated in the scatter plots depicted in Figure 4, where\neach data point signifies the AUP of an LLM for a specific\nlibrary. Across the 8 libraries, most LLMs exhibited relatively\nlow API usage plausibility for both OandU, with AUP below\n30%. Notable exceptions were Pandas and TensorFlow, where\nCodeLlama-7b, CodeGen-6b, and CodeGen-2b (represented\nby symbols \u201c \u2605\u201d, \u201c \u201d, and \u201c \u201d, respectively) achieved\nbetter AUP (around or greater than 40%). This aligns with the\nresults presented in Model Perspective, where CodeLlama-7b,\nCodeGen-6b, and CodeGen-2b achieved the best results for\nthe overall dataset. On the other hand, among the libraries,\ncompletion prompts from SciPy and seaborn posed the most\ndifficulty for LLMs in predicting plausible API usages, with\nAUP consistently below 15%.\nFinding 7: Most LLMs exhibited relatively low API usage\nplausibility across the 8 libraries, with AUP below 30%.\nCodeLlama-7b, CodeGen-6b, and CodeGen-2b achieved\nbetter AUP for Pandas (about 45%-65%) and TensorFlow\n(around 40%).\nDeprecated Usage Rate. The results are presented in the\nscatter plots shown in Figure 5, where each data point represents\nthe DUR of a particular LLM for a specific library. The results\nreveal significant differences in the usage of deprecated APIs", "mimetype": "text/plain", "start_char_idx": 3497, "end_char_idx": 5314, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f8ff5c42-8485-434c-9d51-4050e60bc1f9": {"__data__": {"id_": "f8ff5c42-8485-434c-9d51-4050e60bc1f9", "embedding": null, "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "568c0afc-7a11-41a6-b60d-1a63d39797b9", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "a8dde3f753bff3e147f63ef682025ba971fac515bf9aa28b87d4aef45d5ab2b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ebfd879e-a450-47b2-b02a-1f3d3fbc805a", "node_type": "1", "metadata": {}, "hash": "d22b8256d3329f5ed547e35ed349533bc1bfc17a12245f1e7b5cceff89defe0a", "class_name": "RelatedNodeInfo"}}, "text": "Fig. 4: AUP by Different LLMs across Eight Libraries\nFig. 5: DUR by Different LLMs across Eight Libraries\nacross the libraries, with DUR ranging from approximately\n0% to 100%. Specifically, LLMs generally showed low DUR\n(around or below 20%) for Numpy, scikit-learn, and TensorFlow.\nIn contrast, LLMs exhibited consistently high DUR for SciPy\n(approximately 30%-50%) and PyTorch (approximately 50%-\n70%), and unstable DUR for Pandas (approximately 30%-80%)\nand Transformers (approximately 40%-100%).\nFinding 8: LLMs showed significant differences in the\nusage of deprecated APIs across various libraries, with\nDUR ranging from approximately 0% to 100%. LLMs\nexhibited consistently high DUR for SciPy and PyTorch,\nand unstable DUR for Pandas and Transformers.\n2) Root Cause Analysis: After analyzing the completion\nprompts and LLMs\u2019 predictions, we found that the AUP\ndifferences between these libraries were primarily due to\nthe characteristics of the API usage context. More specifi-cally, the usage contexts of certain APIs followed common\npatterns and were surrounded by related APIs, allowing\nadvanced LLMs like CodeLlama-7b to infer the desired API\nfunctionality based on the completion prompt. For example,\nmany utility APIs in TensorFlow, such as the deprecated\ntensorflow.compat.v1.initialize_all_variables and its replace-\nment tensorflow.compat.v1.global_variables_initializer , were\noften used in recognizable patterns that were easier for LLMs\nto predict. Conversely, some APIs were used more flexibly\nin diverse contexts and lacked obvious combinations with\nother APIs, leading to low AUP for LLMs in predicting such\nAPIs. For instance, many APIs in SciPy, like the deprecated\nscipy.misc.comb and its replacement scipy.special.comb , can\nbe used in diverse contexts to produce combinations for a data\nsequence. Since the data sequence can originate from numerous\nsources and be structured in various ways ( e.g., Numpy array\nand Pandas Series), it is challenging for LLMs to predict these\nAPIs based on the completion prompt without additional hints.\nThe characteristics of API deprecations during library\nevolution also significantly impacted the use of deprecated APIs\nin LLM-based code completions. Some APIs were deprecated\ndue to simple package refactoring, leading to similar usage\npatterns for the deprecated APIs and their replacements. For\nexample, in the version 1.9.0 release of PyTorch, many APIs\nfor tensor linear algebra were moved from the torch package to\nthetorch.linalg package without changes to the API parameters\nor usage patterns ( e.g., torch.lstsq \u2192torch.linalg.lstsq ). In such\ncases, LLMs found it more difficult to distinguish between\ndeprecated APIs and their replacements, resulting in more\nfrequent use of deprecated APIs in the predicted completions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2794, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ebfd879e-a450-47b2-b02a-1f3d3fbc805a": {"__data__": {"id_": "ebfd879e-a450-47b2-b02a-1f3d3fbc805a", "embedding": null, "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "568c0afc-7a11-41a6-b60d-1a63d39797b9", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "a8dde3f753bff3e147f63ef682025ba971fac515bf9aa28b87d4aef45d5ab2b8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f8ff5c42-8485-434c-9d51-4050e60bc1f9", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "c021250f61185b0ae0b1ff971b70880fd55754c880fbe3c102db51f0479fdefa", "class_name": "RelatedNodeInfo"}}, "text": "The characteristics of API deprecations during library\nevolution also significantly impacted the use of deprecated APIs\nin LLM-based code completions. Some APIs were deprecated\ndue to simple package refactoring, leading to similar usage\npatterns for the deprecated APIs and their replacements. For\nexample, in the version 1.9.0 release of PyTorch, many APIs\nfor tensor linear algebra were moved from the torch package to\nthetorch.linalg package without changes to the API parameters\nor usage patterns ( e.g., torch.lstsq \u2192torch.linalg.lstsq ). In such\ncases, LLMs found it more difficult to distinguish between\ndeprecated APIs and their replacements, resulting in more\nfrequent use of deprecated APIs in the predicted completions.\nFinding 9: The characteristics of API deprecations\nduring library evolution significantly impacted the use of\ndeprecated APIs in LLM-based code completions. Minor\nchanges between deprecated APIs and their replacements,\nsuch as simple package refactoring, often led to more\npronounced issues with deprecated API usages.\nV. M ITIGATION APPROACHES\nBased on the findings regarding the causes of deprecated\nAPI usage, we proposed two lightweight mitigation approaches,\nwhich can serve as baselines for future investigation.\nA. Motivation\nAs analyzed in the RQs, the causes of deprecated API usage\nin LLM-based completions can be attributed to Model Training,\nModel Inference, Prompt, and Library aspects. In this section,\nwe further explore the feasibility of mitigating deprecated API\nusage issues from these four perspectives.\nFor model training, a direct mitigation method is to clean up\nthe code containing deprecated APIs from the training corpora.\nHowever, this is impractical due to the constant evolution of\nlibraries. New API deprecations would necessitate repeatedly\nrebuilding the training corpora and retraining the model. From\nthe library perspective, we cannot control the evolution of\nthe library and API deprecation. Therefore, mitigation efforts", "mimetype": "text/plain", "start_char_idx": 2064, "end_char_idx": 4052, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "293dcdba-9c12-491c-b1ff-cd2bf7a49090": {"__data__": {"id_": "293dcdba-9c12-491c-b1ff-cd2bf7a49090", "embedding": null, "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "ef3b30443b51b48b64b5dce381265aa1d3ab9bebb648daa062d7a98f9e5ce010", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6", "node_type": "1", "metadata": {}, "hash": "3c3a4a6a036f340062979de0381e1b6b2fe6c751da33f2b06aac2aa43f8818ef", "class_name": "RelatedNodeInfo"}}, "text": "Algorithm 1: Deprecation-Aware Code Completion\nInput: Prompt pmpt , API Mappings M\nOutput: Completion comp\n1comp\u2190LLM (pmpt )\n2for(dep\u2192rep)\u2208 M do\n3 if C ONTAINS (comp, dep )then\n4 comp\u2190FIX(pmpt, comp, dep, rep )\n5 break\nshould focus on decoding strategies in model inference and\nprompt engineering.\nB. Two Lightweight Approaches\nOur basic idea is illustrated in Algorithm 1. Given an LLM,\nits generation process can generally be formulated as follows:\nTO=LLM (TI),\nwhere TIandTOare the input token sequence and output\ntoken sequence, respectively. In the context of LLM-based\ncode completion, TIcorresponds to the input prompt pmpt ,\nandTOcorresponds to the predicted completion comp (line\n1). When comp contains a deprecated API dep(line 3), we\nneed to perform fixing approaches, i.e.,theFIXprocedure, to\nreplace depwith the corresponding replacement rep(line 4).\nNote that during the CONTAINS procedure in line 3, API alias\nresolution is conducted similarly to the process described in\nSection III-B1.\nThe FIXprocedure can be achieved by reconstructing input,\nthrough either (i) replacing the deprecated API tokens or (ii)\ninserting an additional replacing prompt, and then regenerating\noutput:\n\u2022Approach 1 - REPLACE API: Replacing Deprecated API\nTokens then Regenerating. As shown in Algorithm 2,\ntheREPLACE DEPprocedure involves removing the tokens\ncorresponding to depand any subsequent tokens from comp ,\nthen appending the tokens of rep(line 2). This results in a\nprefix prefix that includes rep. The prefix is concatenated\nwith the pmpt , and the LLM generates the suffix (line 3),\ni.e.,arguments for repand the remaining tokens to complete\nthe code line. This concatenation forms the fixed completion\ncomp\u2217.\n\u2022Approach 2 - INSERT PROMPT : Inserting Additional\nReplacing Prompt then Regenerating. As shown in\nAlgorithm 3, the CREATE DEPPMPT procedure constructs\nan additional replacing prompt pmpt\u2032(line 2), formatted\nas inline comments to guide the LLM to use repinstead\nofdep. By expressing the replacing instruction into inline\ncomments, the re-written prompt ( i.e.,pmpt\u2295pmpt\u2032) can\nbe naturally processed by the LLM to continue writing the\ncode.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2155, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6": {"__data__": {"id_": "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6", "embedding": null, "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "ef3b30443b51b48b64b5dce381265aa1d3ab9bebb648daa062d7a98f9e5ce010", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "293dcdba-9c12-491c-b1ff-cd2bf7a49090", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "89ca6d30cffaac9f40bb8b19598b280880c4e5402aba1eb09130b0a686bcb77a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0ad9f12-1ecc-44ef-b5ea-503f59e077c4", "node_type": "1", "metadata": {}, "hash": "8fc17e33244b17cf015bd6ff47e698e6f5fc9c1fa2c169e14ad002be48e528f5", "class_name": "RelatedNodeInfo"}}, "text": "This results in a\nprefix prefix that includes rep. The prefix is concatenated\nwith the pmpt , and the LLM generates the suffix (line 3),\ni.e.,arguments for repand the remaining tokens to complete\nthe code line. This concatenation forms the fixed completion\ncomp\u2217.\n\u2022Approach 2 - INSERT PROMPT : Inserting Additional\nReplacing Prompt then Regenerating. As shown in\nAlgorithm 3, the CREATE DEPPMPT procedure constructs\nan additional replacing prompt pmpt\u2032(line 2), formatted\nas inline comments to guide the LLM to use repinstead\nofdep. By expressing the replacing instruction into inline\ncomments, the re-written prompt ( i.e.,pmpt\u2295pmpt\u2032) can\nbe naturally processed by the LLM to continue writing the\ncode. The replacing prompt is structured as follows, where\n\u201c{comp} \u201d, \u201c{dep} \u201d, and \u201c {rep} \u201d are placeholders for the\noriginal completion, deprecated API, and replacing API,\nrespectively, and \u201c ...\u201d represents the indentation to ensure\nsyntax correctness.Algorithm 2: Approach 1: Replacing Deprecated API\nTokens then Regenerating\n1Procedure F IX(pmpt, comp, dep, rep ):\n2 prefix \u2190REPLACE DEP(comp, dep, rep )\n3 suffix \u2190LLM (pmpt\u2295prefix )\n4 comp\u2217\u2190prefix \u2295suffix\n5 return comp\u2217\nAlgorithm 3: Approach 2: Inserting Additional Replac-\ning Prompt then Regenerating\n1Procedure F IX(pmpt, comp, dep, rep ):\n2 pmpt\u2032\u2190CREATE REPPMPT (comp, dep, rep )\n3 comp\u2217\u2190LLM (pmpt\u2295pmpt\u2032)\n4 return comp\u2217\n...# {comp}\n...# {dep} is deprecated, use {rep} instead and\n,\u2192revise the return value and arguments.\nThe created pmpt\u2032is then concatenated with pmpt and fed\ninto the LLM to generate a new completion comp\u2217(line 3).\nC. Evaluation\nWe conducted experiments to address the following research\nquestion:\n\u2022RQ4: How effectively can the proposed approaches fix\ndeprecated API usage in completions?\n1) Evaluation Procedure: For each LLM, we selected up-\nto-dated samples from Uwhere the LLM predicted bad\ncompletions using deprecated APIs, i.e.,\nT={(pmpt, dep \u2192rep)\u2208 U :annotate (LLM (pmpt )) = bad},\nto constitute the evaluation data. These samples were chosen\nbecause they have corresponding ground-truth completions\n(e.g., the line following the prompt in Figure 2), which are\nessential for assessing the effectiveness of the proposed fixing\napproaches.\nFor each sample, we employed the deprecation-aware code\ncompletion illustrated in Algorithm 1 with the two fixing\napproaches REPLACE API andINSERT PROMPT to prompt the\nLLM to generate a completion.", "mimetype": "text/plain", "start_char_idx": 1452, "end_char_idx": 3874, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0ad9f12-1ecc-44ef-b5ea-503f59e077c4": {"__data__": {"id_": "a0ad9f12-1ecc-44ef-b5ea-503f59e077c4", "embedding": null, "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "ef3b30443b51b48b64b5dce381265aa1d3ab9bebb648daa062d7a98f9e5ce010", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "95d6d6c5a27d0a91875c865df9b6bf7cca4c2dd226487385cc273f8b06b888a3", "class_name": "RelatedNodeInfo"}}, "text": "C. Evaluation\nWe conducted experiments to address the following research\nquestion:\n\u2022RQ4: How effectively can the proposed approaches fix\ndeprecated API usage in completions?\n1) Evaluation Procedure: For each LLM, we selected up-\nto-dated samples from Uwhere the LLM predicted bad\ncompletions using deprecated APIs, i.e.,\nT={(pmpt, dep \u2192rep)\u2208 U :annotate (LLM (pmpt )) = bad},\nto constitute the evaluation data. These samples were chosen\nbecause they have corresponding ground-truth completions\n(e.g., the line following the prompt in Figure 2), which are\nessential for assessing the effectiveness of the proposed fixing\napproaches.\nFor each sample, we employed the deprecation-aware code\ncompletion illustrated in Algorithm 1 with the two fixing\napproaches REPLACE API andINSERT PROMPT to prompt the\nLLM to generate a completion.\nWe used the following three metrics to assess the effective-\nness of the proposed approaches:\n\u2022Fixed Rate (FR) : This metric indicates the proportion of\ngood completions predicted by the fixing approaches.\n\u2022Edit Similarity (ES) [63]: This metric measures the\nsimilarity between the predicted completions and the\nground-truth completions by analyzing the edit operations\nrequired to transform one into the other.\n\u2022Exact Match (EM) : This metric calculates the rate of\npredicted completions that exactly match the ground-truth\ncompletions after normalizing the return values of function\ncalls ( i.e.,replacing each element in return value with \u201c_\u201d).", "mimetype": "text/plain", "start_char_idx": 3045, "end_char_idx": 4522, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c1d2bcf-de1f-45ca-b02f-c72a68c79c18": {"__data__": {"id_": "1c1d2bcf-de1f-45ca-b02f-c72a68c79c18", "embedding": null, "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "8398c17eb203a309a2624b8af02ecf36e02dbb0bdb0e9394df8573f42ef8117f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "422fff72-2d71-4cc4-ab75-56b8ca2a48d4", "node_type": "1", "metadata": {}, "hash": "1160874ea40d8e0d83c55bfc7d9f55470f8d10b452b31494eea7c2912bc5c3dd", "class_name": "RelatedNodeInfo"}}, "text": "2) Results and Analysis: The evaluation results of the\nproposed fixing approaches are presented in Table IV.\nREPLACE API.Using the REPLACE API fixing approach\n(Algorithm 2), all the LLMs achieve high fixed rates (FR),\nwith values exceeding 85%. Failures in fixing are mainly due\nto syntax errors or incorrect function calls caused by erroneous\ntokens following the replaced APIs. For example, consider a bad\ncompletion: \u201cmeta_graph_def=tf.saved_model.loader.load(...)\u201d\npredicted by the original completion procedure\n(line 1 of Algorithm 1). REPLACE API replaces the\ndeprecated API tf.saved_model.loader.load with its\nreplacement tf.saved_model.load , producing a prefix\nof \u201cmeta_graph_def=tf.saved_model.load\u201d (line 2 of\nAlgorithm 2). However, CodeGen-2b then predicts a suffix of\n\u201c_meta_graph_def(...)\u201d (line 3 of Algorithm 2), resulting in an\nerroneous function call: tf.saved_model.load_meta_graph_def() .\nThis issue arises because the replacement operation in\nREPLACE API can disrupt the naturalness of the code\ncontext [ 64] and the LLMs\u2019 decoding process. An additional\ninteresting finding is that for the three versions of CodeGen,\nthe FR decreases as the model size increases. This suggests\nthat larger models might be more sensitive to interventions in\nthe decoding process.\nThe completions generated by LLMs using the REPLACE API\napproach exhibit high edit similarity (ES), exceeding 80%,\nand exact match rates between 30% and 50%, with these\nrates increasing alongside model size. The inaccuracies in the\ncompletions often involve incorrect return values and arguments\nfor the replacing APIs. Incorrect return values arise because the\nreplacing API might include different elements compared to the\ndeprecated API, and the REPLACE API approach cannot resolve\nsuch inconsistencies in the prefix (line 2 of Algorithm 2). The\nincorrect arguments are primarily due to the LLMs\u2019 limitations\nin correctly utilizing replacing APIs, especially those with\ncomplex argument lists.\nINSERT PROMPT .When applying the I NSERT PROMPT fix-\ning approach (Algorithm 3), the LLMs exhibited significantly\nvaried fixed rates, ranging from 25.7% to 97.2%. This variation\nsuggests that larger models generally possess a stronger capacity\nto interpret and utilize inserted prompts formatted as inline\ncomments. An exception to this trend is DeepSeek-1.3b, which\nachieved a notably high FR of 93.5%. This success can be at-\ntributed to using the deepseek-coder-1.3b-instruct\nversion, which has robust zero-shot instruction-following\ncapabilities. Moreover, the FR differences among various LLMs\nhighlight their sensitivity to prompt construction [ 65,66]. This\nsensitivity indicates that different LLMs may require specialized\nadditional prompts in INSERT PROMPT for optimal performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2772, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "422fff72-2d71-4cc4-ab75-56b8ca2a48d4": {"__data__": {"id_": "422fff72-2d71-4cc4-ab75-56b8ca2a48d4", "embedding": null, "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "8398c17eb203a309a2624b8af02ecf36e02dbb0bdb0e9394df8573f42ef8117f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1c1d2bcf-de1f-45ca-b02f-c72a68c79c18", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "3a83263a366e608bba21265571c93a9d4018ccf421285235a635efc3729cd935", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a4770889-a936-4e84-ba0b-1a28c6935035", "node_type": "1", "metadata": {}, "hash": "4a11579eafdbe4a74409745918d3d6a278801198a3eccc430e7c5444986fedd6", "class_name": "RelatedNodeInfo"}}, "text": "INSERT PROMPT .When applying the I NSERT PROMPT fix-\ning approach (Algorithm 3), the LLMs exhibited significantly\nvaried fixed rates, ranging from 25.7% to 97.2%. This variation\nsuggests that larger models generally possess a stronger capacity\nto interpret and utilize inserted prompts formatted as inline\ncomments. An exception to this trend is DeepSeek-1.3b, which\nachieved a notably high FR of 93.5%. This success can be at-\ntributed to using the deepseek-coder-1.3b-instruct\nversion, which has robust zero-shot instruction-following\ncapabilities. Moreover, the FR differences among various LLMs\nhighlight their sensitivity to prompt construction [ 65,66]. This\nsensitivity indicates that different LLMs may require specialized\nadditional prompts in INSERT PROMPT for optimal performance.\nConsidering edit similarity and exact match, the completions\ngenerated by GPT-3.5 and DeepSeek-1.3b using the INSERT -\nPROMPT approach do not perform as well as their fixed rates\nsuggest. Despite being fine-tuned with an instruct-tuning corpus,\nthey are not specifically fine-tuned on Python code. As a result,\nthey can follow the instructions in the additional prompt to\nuse replacing APIs but struggle to use those APIs correctly.\nComparison. The comparison between REPLACE API andTABLE IV: Evaluation Results of Proposed Approaches\nModelREPLACE API I NSERT PROMPT\nFR(%) ES(%) EM(%) FR(%) ES(%) EM(%)\nCodeGen-350m 92.1 82.3 30.8 25.7 58.7 8.9\nCodeGen-2b 88.2 84.6 38.8 66.1 66.0 23.3\nCodeGen-6b 85.2 85.3 43.5 77.4 72.9 35.3\nDeepSeek-1.3b 99.6 80.9 31.7 93.5 77.7 24.4\nStarCoder-3b 90.9 85.0 42.2 85.3 72.2 29.1\nCodeLlama-7b 99.5 85.7 48.1 95.5 82.0 43.3\nGPT-3.5 \u2013 \u2013 \u2013 97.2 76.2 20.5\nINSERT PROMPT suggests that direct interventions in the\ndecoding process are more effective than zero-shot prompt\nengineering. However, the results also reveal the potential of\nINSERT PROMPT . First, REPLACE API cannot be applied to\nblack-box LLMs like GPT-3.5, as their decoding processes\ncannot be controlled by users. Second, the additional prompt\nemployed by INSERT PROMPT was not carefully tuned for each\nLLM and was performed in a zero-shot manner.", "mimetype": "text/plain", "start_char_idx": 1981, "end_char_idx": 4113, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a4770889-a936-4e84-ba0b-1a28c6935035": {"__data__": {"id_": "a4770889-a936-4e84-ba0b-1a28c6935035", "embedding": null, "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "8398c17eb203a309a2624b8af02ecf36e02dbb0bdb0e9394df8573f42ef8117f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "422fff72-2d71-4cc4-ab75-56b8ca2a48d4", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "74d4fd98fa7827ded6fe317df0aa2eb32b67c48b5088d8d60d5d31ee09065af6", "class_name": "RelatedNodeInfo"}}, "text": "However, the results also reveal the potential of\nINSERT PROMPT . First, REPLACE API cannot be applied to\nblack-box LLMs like GPT-3.5, as their decoding processes\ncannot be controlled by users. Second, the additional prompt\nemployed by INSERT PROMPT was not carefully tuned for each\nLLM and was performed in a zero-shot manner. In the future,\nfine-tuning the LLMs with instructions specifically designed\nfor fixing deprecated usage could enhance effectiveness.\nFinding 10: The proposed REPLACE API effectively\naddresses deprecated API usage for all open-source LLMs,\nachieving fix rates exceeding 85%. The fixed completions\nalso demonstrate acceptable accuracy compared to ground-\ntruth completions. While INSERT PROMPT does not cur-\nrently achieve sufficient effectiveness and accuracy in fixing\ncompletions containing deprecated API usage, it shows\npotential for future exploration.\nVI. D ISCUSSION\nA. Implications\nWe provide implications for future research on the synergy\nof library evolution and LLM-driven software development.\nValidating LLM-Generated Code Completions and Is-\nsuing Alerts for Deprecated API Usages. Our evaluation\nstudy reveals that LLMs frequently use deprecated APIs\nduring code completion. Such deprecated API usages can be\neasily overlooked [ 19], potentially introducing bugs or security\nvulnerabilities into software projects. Therefore, implementing\na validation mechanism for deprecated API usage in LLM-\ngenerated code completions is crucial to ensure the reliability of\nthe code. Such a validation mechanism can be further integrated\ninto the pose-processing of LLM-based code completion, such\nas issuing alerts to developers.\nFixing and Updating Outdated API Knowledge in LLMs\nby Model-Level Repair. The current fixing approaches mitigate\nthe issues by intervening in decoding process and rewriting\nprompts, without addressing the outdated knowledge about\ndeprecated API usages stored in the LLMs. Given the constant\nevolution of libraries, lightweight model repair techniques\nare potential solutions for fixing outdated knowledge. Model\nEditing is one such direction, which can be categorized into the\nfollowing main categories: Memory-based approaches [ 67,68,", "mimetype": "text/plain", "start_char_idx": 3786, "end_char_idx": 5984, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "19341c9c-8aee-4768-9f19-f07c9e5eb9e3": {"__data__": {"id_": "19341c9c-8aee-4768-9f19-f07c9e5eb9e3", "embedding": null, "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e8cc96cc-5a00-43f9-abca-e44edc04bb85", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "5fae8755a4dfe614611bce54083ffc33226715481b2b7a302ab2a4097180db23", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6455f91c-fd0c-43c0-ae49-cbba80e1c008", "node_type": "1", "metadata": {}, "hash": "c7f39913359275da5d57d0a2dc548f69d3a58911c154e6b7e70200445bc0ad78", "class_name": "RelatedNodeInfo"}}, "text": "69], Locating-then-editing approaches [ 70,71,72], and Meta-\nlearning approaches [ 73,74]. Compared to the proposed fixing\napproaches, model editing can directly update the outdated\nknowledge about deprecated API usages, even incorporating the\ninformation of entirely new replacing APIs ( i.e.,the replacing\nAPIs introduced after model training and unseen in the training\ncorpora) into the LLMs.\nLeveraging Retrieval-Augmented Generation for Up-to-\ndated Code Completion. As discussed in our study findings,\na key cause of the deprecated API usage in LLM-based\ncompletions is the lack of posterior knowledge about API\ndeprecations. Retrieval-Augmented Generation (RAG) is a\nsuitable technique that can perfectly align with the need for\nposterior knowledge [ 75]. We can explore the possibility of\nadopting RAG to mitigate deprecated API usage in LLM-based\ncode completion by retrieving related knowledge pieces, such\nas documentation and usage examples.\nDesigning Agent & Multi-Agent Systems for Incorporat-\ning Library Evolution into LLM-Driven Software Develop-\nment. In modern software development driven by LLMs, the\nissues brought by library evolution are encountered not only in\ncode completion. With advancements in AI agents [ 76,77,78],\nwe can potentially develop autonomous agents or multi-agent\nsystems capable of automatically discovering deprecated API\nusages, identifying correct replacements, upgrading dependent\nlibraries, and fixing the code. To ensure comprehensive\nrecognition of deprecated API usage and up-to-date fixes, we\nshould design an effective multi-agent collaboration pipeline.\nOne agent should scan the generated code to identify all\npieces related to API usage. Another agent should continuously\nfetch information online, checking the latest official API\ndocumentation to aid in discovery and correction. Finally, a\ndedicated agent should be responsible for implementing the\nnecessary library upgrades and code fixes. Such an agent system\ncan fundamentally address the issues discussed in this article.\nB. Threats to Validity\nInternal Threats. The primary threat to the internal validity\nof our study is the soundness of the static analysis used for\nfunction location and result annotation. Given that Python\nis a dynamic programming language, the lightweight object\ntype resolution method we employed may have missed some\nfunction calls of deprecated and replacing APIs during the\nmatching process. In the future, we aim to address this\nissue by implementing advanced type inference techniques.\nAdditionally, our study currently focuses on function-level API\ndeprecation, overlooking parameter-level deprecations. Future\nresearch should investigate a broader range of deprecated API\ncategories to provide a more comprehensive analysis.\nExternal Threats. A primary threat to the external validity\nof our study lies in the choice of Python libraries and the\nevaluated LLMs. To mitigate this threat, we reused libraries\nexamined in previous studies and introduced three popular\ndeep learning libraries to ensure diversity and timeliness.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3067, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6455f91c-fd0c-43c0-ae49-cbba80e1c008": {"__data__": {"id_": "6455f91c-fd0c-43c0-ae49-cbba80e1c008", "embedding": null, "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e8cc96cc-5a00-43f9-abca-e44edc04bb85", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "5fae8755a4dfe614611bce54083ffc33226715481b2b7a302ab2a4097180db23", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19341c9c-8aee-4768-9f19-f07c9e5eb9e3", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "a7494212043a5cef4e38c4df650cd41d39e10d83453616b199366c58bfe85536", "class_name": "RelatedNodeInfo"}}, "text": "The primary threat to the internal validity\nof our study is the soundness of the static analysis used for\nfunction location and result annotation. Given that Python\nis a dynamic programming language, the lightweight object\ntype resolution method we employed may have missed some\nfunction calls of deprecated and replacing APIs during the\nmatching process. In the future, we aim to address this\nissue by implementing advanced type inference techniques.\nAdditionally, our study currently focuses on function-level API\ndeprecation, overlooking parameter-level deprecations. Future\nresearch should investigate a broader range of deprecated API\ncategories to provide a more comprehensive analysis.\nExternal Threats. A primary threat to the external validity\nof our study lies in the choice of Python libraries and the\nevaluated LLMs. To mitigate this threat, we reused libraries\nexamined in previous studies and introduced three popular\ndeep learning libraries to ensure diversity and timeliness. For\nthe LLMs, we selected models covering various architectures,\nmodel sizes, training corpora, and training strategies to ensurethe generalizability of our findings. Another external threat is\nthat the study was conducted solely on the Python language,\nwhich may limit the applicability of our findings to other\nlanguages such as Java and C#. In the future, we plan to\nexplore the impact of library evolution on LLM-based code\ncompletion across a broader range of programming languages.\nVII. C ONCLUSION\nIn this work, we conducted an evaluation study to investigate\nthe statuses and causes of deprecated API usages in LLM-\nbased code completion. The study results all evaluated LLMs\nencounter challenges in predicting plausible API usages and\nface issues with deprecated API usages, influenced by the\ndistinct code context characteristics of the prompts and the\ncharacteristics of API deprecations during the evolution of\nthese libraries. We propose two lightweight fixing approaches\nto mitigate the deprecated API usages and can serve as baselines\nfor future research. We also provide implications for the\nresearch directions for the combination of library evolution\nand LLM-driven code completion and software development.", "mimetype": "text/plain", "start_char_idx": 2076, "end_char_idx": 4293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1030cf9d-37e2-4eda-9445-f3ba6b42ee30": {"__data__": {"id_": "1030cf9d-37e2-4eda-9445-f3ba6b42ee30", "embedding": null, "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440904ad-fc72-4c73-8017-96c6e54e06a8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b2fea5dac44284eed2010d04fdb998acb9f058a6c0475bfe87bbcde11b8b9715", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bdca76f3-30ad-4f70-a935-8298ff094aac", "node_type": "1", "metadata": {}, "hash": "42736d5a3014bd2f4903b1696489037c1c6ef7f9332712a87304822958c1808b", "class_name": "RelatedNodeInfo"}}, "text": "REFERENCES\n[1]M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P.\nde Oliveira Pinto, J. Kaplan, H. Edwards, Y . Burda,\nN. Joseph, G. Brockman, and Others, \u201cEvaluating\nlarge language models trained on code,\u201d CoRR ,\nvol. abs/2107.03374, 2021. [Online]. Available: https:\n//arxiv.org/abs/2107.03374\n[2]D. Fried, A. Aghajanyan, J. Lin, S. Wang, E. Wallace,\nF. Shi, R. Zhong, S. Yih, L. Zettlemoyer, and M. Lewis,\n\u201cIncoder: A generative model for code infilling and\nsynthesis,\u201d in The Eleventh International Conference on\nLearning Representations, ICLR 2023, Kigali, Rwanda,\nMay 1-5, 2023 . OpenReview.net, 2023. [Online].\nAvailable: https://openreview.net/pdf?id=hQwb-lbM6EL\n[3]E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang,\nY . Zhou, S. Savarese, and C. Xiong, \u201cCodegen: An open\nlarge language model for code with multi-turn program\nsynthesis,\u201d in The Eleventh International Conference on\nLearning Representations, ICLR 2023, Kigali, Rwanda,\nMay 1-5, 2023 . OpenReview.net, 2023. [Online].\nAvailable: https://openreview.net/pdf?id=iaYcJKpY2B_\n[4]R. Li, L. B. Allal, Y . Zi, N. Muennighoff, D. Kocetkov,\nC. Mou, M. Marone, C. Akiki, J. Li, J. Chim, and\nOthers, \u201cStarcoder: may the source be with you!\u201d\nCoRR , vol. abs/2305.06161, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2305.06161\n[5]B. Rozi\u00e8re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E.\nTan, Y .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bdca76f3-30ad-4f70-a935-8298ff094aac": {"__data__": {"id_": "bdca76f3-30ad-4f70-a935-8298ff094aac", "embedding": null, "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440904ad-fc72-4c73-8017-96c6e54e06a8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b2fea5dac44284eed2010d04fdb998acb9f058a6c0475bfe87bbcde11b8b9715", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1030cf9d-37e2-4eda-9445-f3ba6b42ee30", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7ca59ec150d0a4e4725ffba556787c2bdb080594ab7fbde3affc1cf7e4bc042e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "502b67dd-3c95-4e5c-9332-a9f66bc546dd", "node_type": "1", "metadata": {}, "hash": "5b449c7661cdfaae75e86a508aad22b0b8027a3b32032503bcd521fc826667b9", "class_name": "RelatedNodeInfo"}}, "text": "OpenReview.net, 2023. [Online].\nAvailable: https://openreview.net/pdf?id=iaYcJKpY2B_\n[4]R. Li, L. B. Allal, Y . Zi, N. Muennighoff, D. Kocetkov,\nC. Mou, M. Marone, C. Akiki, J. Li, J. Chim, and\nOthers, \u201cStarcoder: may the source be with you!\u201d\nCoRR , vol. abs/2305.06161, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2305.06161\n[5]B. Rozi\u00e8re, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E.\nTan, Y . Adi, J. Liu, T. Remez, J. Rapin, A. Kozhevnikov,\nI. Evtimov, J. Bitton, M. Bhatt, C. Canton-Ferrer,\nA. Grattafiori, W. Xiong, A. D\u00e9fossez, J. Copet, F. Azhar,\nH. Touvron, L. Martin, N. Usunier, T. Scialom, and\nG. Synnaeve, \u201cCode llama: Open foundation models\nfor code,\u201d CoRR , vol. abs/2308.12950, 2023. [Online].\nAvailable: https://doi.org/10.48550/arXiv.2308.12950\n[6]D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang,\nG. Chen, X. Bi, Y . Wu, Y . K. Li, F. Luo, Y . Xiong, and\nW. Liang, \u201cDeepseek-coder: When the large language\nmodel meets programming - the rise of code intelligence,\u201d\nCoRR , vol. abs/2401.14196, 2024. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2401.14196\n[7]A. Svyatkovskiy, S. K. Deng, S. Fu, and N. Sundaresan,\n\u201cIntellicode compose: Code generation using transformer,\u201d\ninProceedings of the 28th ACM joint meeting on Eu-\nropean software engineering conference and symposium\non the foundations of software engineering , 2020, pp.\n1433\u20131443.\n[8]H. Le, Y . Wang, A. D. Gotmare, S. Savarese, and\nS. C. H. Hoi, \u201cCoderl: Mastering code generation through\npretrained models and deep reinforcement learning,\u201d Ad-\nvances in Neural Information Processing Systems , vol. 35,\npp. 21 314\u201321 328, 2022.", "mimetype": "text/plain", "start_char_idx": 948, "end_char_idx": 2582, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "502b67dd-3c95-4e5c-9332-a9f66bc546dd": {"__data__": {"id_": "502b67dd-3c95-4e5c-9332-a9f66bc546dd", "embedding": null, "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440904ad-fc72-4c73-8017-96c6e54e06a8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b2fea5dac44284eed2010d04fdb998acb9f058a6c0475bfe87bbcde11b8b9715", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bdca76f3-30ad-4f70-a935-8298ff094aac", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "7b64a93977543e38ad010a7c53952e8403269ed3839fdd32d425efd5b620b040", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4", "node_type": "1", "metadata": {}, "hash": "d99568a61beb08dd24b66f8e2c5478699c8a9e3d142a82025e4f3de58be8fe03", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available:\nhttps://doi.org/10.48550/arXiv.2401.14196\n[7]A. Svyatkovskiy, S. K. Deng, S. Fu, and N. Sundaresan,\n\u201cIntellicode compose: Code generation using transformer,\u201d\ninProceedings of the 28th ACM joint meeting on Eu-\nropean software engineering conference and symposium\non the foundations of software engineering , 2020, pp.\n1433\u20131443.\n[8]H. Le, Y . Wang, A. D. Gotmare, S. Savarese, and\nS. C. H. Hoi, \u201cCoderl: Mastering code generation through\npretrained models and deep reinforcement learning,\u201d Ad-\nvances in Neural Information Processing Systems , vol. 35,\npp. 21 314\u201321 328, 2022.\n[9]Z. Zeng, H. Tan, H. Zhang, J. Li, Y . Zhang, and L. Zhang,\n\u201cAn extensive study on pre-trained models for program\nunderstanding and generation,\u201d in Proceedings of the\n31st ACM SIGSOFT international symposium on softwaretesting and analysis , 2022, pp. 39\u201351.\n[10] Z. Fan, X. Gao, M. Mirchev, A. Roychoudhury, and\nS. H. Tan, \u201cAutomated repair of programs from large\nlanguage models,\u201d in 2023 IEEE/ACM 45th International\nConference on Software Engineering (ICSE) . IEEE,\n2023, pp. 1469\u20131481.\n[11] Y . Wei, C. S. Xia, and L. Zhang, \u201cCopiloting the copilots:\nFusing large language models with completion engines\nfor automated program repair,\u201d in Proceedings of the 31st\nACM Joint European Software Engineering Conference\nand Symposium on the Foundations of Software Engineer-\ning, 2023, pp. 172\u2013184.\n[12] A. T. Nguyen and T. N. Nguyen, \u201cGraph-based statistical\nlanguage model for code,\u201d in 2015 IEEE/ACM 37th IEEE\nInternational Conference on Software Engineering , vol. 1.\nIEEE, 2015, pp. 858\u2013868.\n[13] V . Raychev, M. Vechev, and E. Yahav, \u201cCode completion\nwith statistical language models,\u201d in Proceedings of\nthe 35th ACM SIGPLAN conference on programming\nlanguage design and implementation , 2014, pp. 419\u2013428.\n[14] S. Ugare, T. Suresh, H. Kang, S. Misailovic, and G. Singh,\n\u201cImproving llm code generation with grammar augmenta-\ntion,\u201d arXiv preprint arXiv:2403.01632 , 2024.\n[15] D. Guo, S. Lu, N. Duan, Y .", "mimetype": "text/plain", "start_char_idx": 1985, "end_char_idx": 3992, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4": {"__data__": {"id_": "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4", "embedding": null, "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440904ad-fc72-4c73-8017-96c6e54e06a8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b2fea5dac44284eed2010d04fdb998acb9f058a6c0475bfe87bbcde11b8b9715", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "502b67dd-3c95-4e5c-9332-a9f66bc546dd", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "ec60588a4b91908faf5c635569a920df2e2a184f72bca457f44ddf235c7e8ecb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd9e42f4-89c5-445e-a844-89b3f3a9d7ac", "node_type": "1", "metadata": {}, "hash": "e91818a88762c6b55a95f36acab15b390ac9c8e65ea38aa68453ed04af449e12", "class_name": "RelatedNodeInfo"}}, "text": "1.\nIEEE, 2015, pp. 858\u2013868.\n[13] V . Raychev, M. Vechev, and E. Yahav, \u201cCode completion\nwith statistical language models,\u201d in Proceedings of\nthe 35th ACM SIGPLAN conference on programming\nlanguage design and implementation , 2014, pp. 419\u2013428.\n[14] S. Ugare, T. Suresh, H. Kang, S. Misailovic, and G. Singh,\n\u201cImproving llm code generation with grammar augmenta-\ntion,\u201d arXiv preprint arXiv:2403.01632 , 2024.\n[15] D. Guo, S. Lu, N. Duan, Y . Wang, M. Zhou, and J. Yin,\n\u201cUnixcoder: Unified cross-modal pre-training for code\nrepresentation,\u201d arXiv preprint arXiv:2203.03850 , 2022.\n[16] (2023) Github copilot. [Online]. Available: https:\n//github.com/features/copilot\n[17] R. G. Kula, A. Ouni, D. M. German, and K. Inoue, \u201cAn\nempirical study on the impact of refactoring activities on\nevolving client-used apis,\u201d Inf. Softw. Technol. , vol. 93,\nno. C, pp. 186\u2013199, 2018.\n[18] M. Hu and Y . Zhang, \u201cAn empirical study of the python/c\napi on evolution and bug patterns,\u201d Journal of Software:\nEvolution and Process , vol. 35, no. 2, p. e2507, 2023.\n[19] J. Wang, L. Li, K. Liu, and H. Cai, \u201cExploring how\ndeprecated python library apis are (not) handled,\u201d\ninESEC/FSE \u201920: 28th ACM Joint European\nSoftware Engineering Conference and Symposium on the\nFoundations of Software Engineering, Virtual Event, USA,\nNovember 8-13, 2020 , P. Devanbu, M. B. Cohen, and\nT. Zimmermann, Eds. ACM, 2020, pp. 233\u2013244. [Online].\nAvailable: https://doi.org/10.1145/3368089.3409735\n[20] Api lifecycle stages. [Online]. Avail-\nable: https://developers.meetmarigold.com/engage/terms/\nversioning-deprecation/#api-lifecycle-stages\n[21] Pytorch: A python package that provides tensor\ncomputation and deep neural networks. [Online].\nAvailable: https://pytorch.org/\n[22] D. Zan, B. Chen, D. Yang, Z. Lin, M. Kim,\nB. Guan, Y .", "mimetype": "text/plain", "start_char_idx": 3551, "end_char_idx": 5344, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd9e42f4-89c5-445e-a844-89b3f3a9d7ac": {"__data__": {"id_": "bd9e42f4-89c5-445e-a844-89b3f3a9d7ac", "embedding": null, "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "440904ad-fc72-4c73-8017-96c6e54e06a8", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "b2fea5dac44284eed2010d04fdb998acb9f058a6c0475bfe87bbcde11b8b9715", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "4cb9f158cec4af1094a9f432273d87e8a06631a861cac4ba876fe2802cf24ce2", "class_name": "RelatedNodeInfo"}}, "text": "ACM, 2020, pp. 233\u2013244. [Online].\nAvailable: https://doi.org/10.1145/3368089.3409735\n[20] Api lifecycle stages. [Online]. Avail-\nable: https://developers.meetmarigold.com/engage/terms/\nversioning-deprecation/#api-lifecycle-stages\n[21] Pytorch: A python package that provides tensor\ncomputation and deep neural networks. [Online].\nAvailable: https://pytorch.org/\n[22] D. Zan, B. Chen, D. Yang, Z. Lin, M. Kim,\nB. Guan, Y . Wang, W. Chen, and J. Lou, \u201cCERT:\ncontinual pre-training on sketches for library-oriented\ncode generation,\u201d in Proceedings of the Thirty-First\nInternational Joint Conference on Artificial Intelligence,\nIJCAI 2022, Vienna, Austria, 23-29 July 2022 , L. D.\nRaedt, Ed. ijcai.org, 2022, pp. 2369\u20132375. [Online].", "mimetype": "text/plain", "start_char_idx": 4923, "end_char_idx": 5652, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "343c4a20-d73d-4824-ba0a-66ea69aa63f6": {"__data__": {"id_": "343c4a20-d73d-4824-ba0a-66ea69aa63f6", "embedding": null, "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "79378453da1335b794b09213d58e75d8143b780ec9dd3a01f151c3c66f029366", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "557d35e6-79de-437b-a2ce-74ea32be819d", "node_type": "1", "metadata": {}, "hash": "0a3a552bbdb7da9cc50b9ce7c436f450d67a7e284ab0fb531a72fcf6a6010cd2", "class_name": "RelatedNodeInfo"}}, "text": "Available: https://doi.org/10.24963/ijcai.2022/329\n[23] K. Zhang, G. Li, J. Li, Z. Li, and Z. Jin, \u201cToolcoder:\nTeach code generation models to use API search tools,\u201d\nCoRR , vol. abs/2305.04032, 2023. [Online]. Available:\nhttps://doi.org/10.48550/arXiv.2305.04032\n[24] F. F. Xu, U. Alon, G. Neubig, and V . J. Hellendoorn, \u201cA\nsystematic evaluation of large language models of code,\u201d\ninProceedings of the 6th ACM SIGPLAN International\nSymposium on Machine Programming , 2022, pp. 1\u201310.\n[25] J. Liu, C. S. Xia, Y . Wang, and L. Zhang, \u201cIs your code\ngenerated by chatgpt really correct? rigorous evaluation\nof large language models for code generation,\u201d Advances\nin Neural Information Processing Systems , vol. 36, 2024.\n[26] M. Ciniselli, N. Cooper, L. Pascarella, A. Mastropaolo,\nE. Aghajani, D. Poshyvanyk, M. Di Penta, and G. Bavota,\n\u201cAn empirical study on the usage of transformer models\nfor code completion,\u201d IEEE Transactions on Software\nEngineering , vol. 48, no. 12, pp. 4818\u20134837, 2021.\n[27] M. Ciniselli, N. Cooper, L. Pascarella, D. Poshyvanyk,\nM. Di Penta, and G. Bavota, \u201cAn empirical study on\nthe usage of bert models for code completion,\u201d in 2021\nIEEE/ACM 18th International Conference on Mining\nSoftware Repositories (MSR) . IEEE, 2021, pp. 108\u2013119.\n[28] H. Ding, V . Kumar, Y . Tian, Z. Wang, R. Kwiatkowski,\nX. Li, M. K. Ramanathan, B. Ray, P. Bhatia, S. Sen-\ngupta et al. , \u201cA static evaluation of code completion by\nlarge language models,\u201d arXiv preprint arXiv:2306.03203 ,\n2023.\n[29] M. Izadi, J. Katzy, T. Van Dam, M. Otten, R. M.\nPopescu, and A. Van Deursen, \u201cLanguage models for code\ncompletion: A practical evaluation,\u201d in Proceedings of the\nIEEE/ACM 46th International Conference on Software\nEngineering , 2024, pp. 1\u201313.\n[30] F. Liu, Y .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1761, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "557d35e6-79de-437b-a2ce-74ea32be819d": {"__data__": {"id_": "557d35e6-79de-437b-a2ce-74ea32be819d", "embedding": null, "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "79378453da1335b794b09213d58e75d8143b780ec9dd3a01f151c3c66f029366", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "343c4a20-d73d-4824-ba0a-66ea69aa63f6", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "4e0ef0eba613c84a099495f1d2266f3e5799c0a895affb557201cf8684972ed9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb", "node_type": "1", "metadata": {}, "hash": "1be64bf7bfd937a71069f29ef82a9390316d8f5c6dee3154bcf1f2c7525c4c72", "class_name": "RelatedNodeInfo"}}, "text": "IEEE, 2021, pp. 108\u2013119.\n[28] H. Ding, V . Kumar, Y . Tian, Z. Wang, R. Kwiatkowski,\nX. Li, M. K. Ramanathan, B. Ray, P. Bhatia, S. Sen-\ngupta et al. , \u201cA static evaluation of code completion by\nlarge language models,\u201d arXiv preprint arXiv:2306.03203 ,\n2023.\n[29] M. Izadi, J. Katzy, T. Van Dam, M. Otten, R. M.\nPopescu, and A. Van Deursen, \u201cLanguage models for code\ncompletion: A practical evaluation,\u201d in Proceedings of the\nIEEE/ACM 46th International Conference on Software\nEngineering , 2024, pp. 1\u201313.\n[30] F. Liu, Y . Liu, L. Shi, H. Huang, R. Wang, Z. Yang,\nand L. Zhang, \u201cExploring and evaluating hallucina-\ntions in llm-powered code generation,\u201d arXiv preprint\narXiv:2404.00971 , 2024.\n[31] A. A. Sawant, M. Aniche, A. van Deursen, and A. Bac-\nchelli, \u201cUnderstanding developers\u2019 needs on deprecation\nas a language feature,\u201d in ICSE , 2018, pp. 561\u2013571.\n[32] A. A. Sawant, G. Huang, G. Vilen, S. Stojkovski, and\nA. Bacchelli, \u201cWhy are features deprecated? an investiga-\ntion into the motivation behind deprecation,\u201d in ICSME ,\n2018, pp. 13\u201324.\n[33] A. Mirian, N. Bhagat, C. Sadowski, A. P. Felt, S. Savage,\nand G. M. V oelker, \u201cWeb feature deprecation: a case\nstudy for chrome,\u201d in ICSE-SEIP , 2019, pp. 302\u2013311.\n[34] A. A. Sawant, R. Robbes, and A. Bacchelli, \u201cTo react,\nor not to react: Patterns of reaction to api deprecation,\u201d\nEmpirical Software Engineering , vol. 24, no. 6, pp. 3824\u2013\n3870, 2019.\n[35] R. Robbes, M. Lungu, and D. R\u00f6thlisberger, \u201cHow do\ndevelopers react to api deprecation? the case of a smalltalk\necosystem,\u201d in FSE, 2012, pp. 1\u201311.", "mimetype": "text/plain", "start_char_idx": 1238, "end_char_idx": 2800, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb": {"__data__": {"id_": "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb", "embedding": null, "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "79378453da1335b794b09213d58e75d8143b780ec9dd3a01f151c3c66f029366", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "557d35e6-79de-437b-a2ce-74ea32be819d", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "efeb1b01f97d77657085170494b0f3f92dcd53372be69eb73a71c98f0d54495f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0190e81-87d6-46bb-8c1c-47396e601f8f", "node_type": "1", "metadata": {}, "hash": "ff099a42d8c7f3b395ae9f31324dff0c3ede3173c6db965c79aab75b47d07470", "class_name": "RelatedNodeInfo"}}, "text": "302\u2013311.\n[34] A. A. Sawant, R. Robbes, and A. Bacchelli, \u201cTo react,\nor not to react: Patterns of reaction to api deprecation,\u201d\nEmpirical Software Engineering , vol. 24, no. 6, pp. 3824\u2013\n3870, 2019.\n[35] R. Robbes, M. Lungu, and D. R\u00f6thlisberger, \u201cHow do\ndevelopers react to api deprecation? the case of a smalltalk\necosystem,\u201d in FSE, 2012, pp. 1\u201311.\n[36] M. Linares-V\u00e1squez, G. Bavota, C. Bernal-C\u00e1rdenas,\nM. Di Penta, R. Oliveto, and D. Poshyvanyk, \u201cApi changeand fault proneness: A threat to the success of android\napps,\u201d in ESEC/FSE , 2013, pp. 477\u2013487.\n[37] T. McDonnell, B. Ray, and M. Kim, \u201cAn empirical study\nof api stability and adoption in the android ecosystem,\u201d\ninICSM , 2013, pp. 70\u201379.\n[38] A. Hora, R. Robbes, N. Anquetil, A. Etien, S. Ducasse,\nand M. T. Valente, \u201cHow do developers react to api\nevolution? the pharo ecosystem case,\u201d in ICSME , 2015,\npp. 251\u2013260.\n[39] A. A. Sawant, R. Robbes, and A. Bacchelli, \u201cOn the\nreaction to deprecation of 25,357 clients of 4+ 1 popular\njava apis,\u201d in ICSME , 2016, pp. 400\u2013410.\n[40] I. Balaban, F. Tip, and R. Fuhrer, \u201cRefactoring support for\nclass library migration,\u201d in OOPSLA , 2005, pp. 265\u2013279.\n[41] J. Henkel and A. Diwan, \u201cCatchup! capturing and replay-\ning refactorings to support api evolution,\u201d in ICSE , 2005,\npp. 274\u2013283.\n[42] Z. Xing and E. Stroulia, \u201cApi-evolution support with diff-\ncatchup,\u201d IEEE Transactions on Software Engineering ,\nvol. 33, no. 12, pp. 818\u2013836, 2007.\n[43] B. Dagenais and M. P. Robillard, \u201cSemdiff: Analysis\nand recommendation support for api evolution,\u201d in ICSE ,\n2009, pp. 599\u2013602.\n[44] T. Sch\u00e4fer, J. Jonas, and M. Mezini, \u201cMining framework\nusage changes from instantiation code,\u201d in ICSE , 2008,\npp. 471\u2013480.", "mimetype": "text/plain", "start_char_idx": 2450, "end_char_idx": 4156, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a0190e81-87d6-46bb-8c1c-47396e601f8f": {"__data__": {"id_": "a0190e81-87d6-46bb-8c1c-47396e601f8f", "embedding": null, "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "79378453da1335b794b09213d58e75d8143b780ec9dd3a01f151c3c66f029366", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "2a9979eba419c4ceaa63d2f0eb680a83f0ba1fbe7139959ef7a32e461d4deeb6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "74fa9ea5-cb0c-4c15-93db-bd058b4b0f1a", "node_type": "1", "metadata": {}, "hash": "84f08d091152faafc04950b89337af7f4a7a1886c1208ab9a984264d8add1300", "class_name": "RelatedNodeInfo"}}, "text": "265\u2013279.\n[41] J. Henkel and A. Diwan, \u201cCatchup! capturing and replay-\ning refactorings to support api evolution,\u201d in ICSE , 2005,\npp. 274\u2013283.\n[42] Z. Xing and E. Stroulia, \u201cApi-evolution support with diff-\ncatchup,\u201d IEEE Transactions on Software Engineering ,\nvol. 33, no. 12, pp. 818\u2013836, 2007.\n[43] B. Dagenais and M. P. Robillard, \u201cSemdiff: Analysis\nand recommendation support for api evolution,\u201d in ICSE ,\n2009, pp. 599\u2013602.\n[44] T. Sch\u00e4fer, J. Jonas, and M. Mezini, \u201cMining framework\nusage changes from instantiation code,\u201d in ICSE , 2008,\npp. 471\u2013480.\n[45] M. W. Godfrey and L. Zou, \u201cUsing origin analysis to\ndetect merging and splitting of source code entities,\u201d IEEE\nTransactions on Software Engineering , vol. 31, no. 2, pp.\n166\u2013181, 2005.\n[46] W. Wu, Y .-G. Gu\u00e9h\u00e9neuc, G. Antoniol, and M. Kim,\n\u201cAura: a hybrid approach to identify framework evolution,\u201d\ninICSE , 2010, pp. 325\u2013334.\n[47] K. Huang, B. Chen, L. Pan, S. Wu, and X. Peng,\n\u201cRepfinder: Finding replacements for missing apis in\nlibrary update,\u201d in ASE, 2021.\n[48] J. Sallou, T. Durieux, and A. Panichella, \u201cBreaking the\nsilence: the threats of using llms in software engineering,\u201d\ninProceedings of the 2024 ACM/IEEE 44th International\nConference on Software Engineering: New Ideas and\nEmerging Results , 2024, pp. 102\u2013106.\n[49] Most popular programming languages. [On-\nline]. Available: https://www.orientsoftware.com/blog/\nmost-popular-programming-languages/\n[50] (2023) Pytorch documentation 1.9.0. [Online]. Available:\nhttps://pytorch.org/docs/1.9.0/\n[51] Openai api reference. [Online]. Available: https://\nsourcegraph.com/search\n[52] Pep 221 \u2013 import as. [Online]. Available: https:\n//peps.python.org/pep-0221/\n[53] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,\nY . Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale,\nand Others, \u201cLlama 2: Open foundation and fine-tuned\nchat models,\u201d CoRR , vol. abs/2307.09288, 2023. [Online].", "mimetype": "text/plain", "start_char_idx": 3598, "end_char_idx": 5517, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74fa9ea5-cb0c-4c15-93db-bd058b4b0f1a": {"__data__": {"id_": "74fa9ea5-cb0c-4c15-93db-bd058b4b0f1a", "embedding": null, "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "79378453da1335b794b09213d58e75d8143b780ec9dd3a01f151c3c66f029366", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0190e81-87d6-46bb-8c1c-47396e601f8f", "node_type": "1", "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "e7d3c683653de4ffb95b6d7983490d2c73dd89b9609fe523307c03fc689ec515", "class_name": "RelatedNodeInfo"}}, "text": "[Online]. Available:\nhttps://pytorch.org/docs/1.9.0/\n[51] Openai api reference. [Online]. Available: https://\nsourcegraph.com/search\n[52] Pep 221 \u2013 import as. [Online]. Available: https:\n//peps.python.org/pep-0221/\n[53] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,\nY . Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale,\nand Others, \u201cLlama 2: Open foundation and fine-tuned\nchat models,\u201d CoRR , vol. abs/2307.09288, 2023. [Online].\nAvailable: https://doi.org/10.48550/arXiv.2307.09288\n[54] Gpt-3.5 turbo. [Online]. Available: https://platform.openai.", "mimetype": "text/plain", "start_char_idx": 5068, "end_char_idx": 5636, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1e10088-4cfc-43ce-939e-19fcb73305d2": {"__data__": {"id_": "a1e10088-4cfc-43ce-939e-19fcb73305d2", "embedding": null, "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "87ff029e5630ed1bbb22d2ff6a09d6400c47d7b9ccb1784e90ef72be59682215", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4", "node_type": "1", "metadata": {}, "hash": "2c8a19586681178bc77ed09001ea4721b3dfc27ed6af15492e1c6fbf2578ed2e", "class_name": "RelatedNodeInfo"}}, "text": "com/docs/models/gpt-3-5-turbo\n[55] Hugging face - host git-based models, datasets and\nspaces on the hugging face hub. [Online]. Available:\nhttps://huggingface.co/models\n[56] Sourcegraph: Code search and an ai assistant with\nthe context of the code graph. [Online]. Available:\nhttps://platform.openai.com/docs/api-reference/chat\n[57] J. Wei, X. Wang, D. Schuurmans, M. Bosma,\nB. Ichter, F. Xia, E. H. Chi, Q. V . Le, and D. Zhou,\n\u201cChain-of-thought prompting elicits reasoning in large\nlanguage models,\u201d in Advances in Neural Information\nProcessing Systems 35: Annual Conference on Neural\nInformation Processing Systems 2022, NeurIPS 2022,\nNew Orleans, LA, USA, November 28 - December 9,\n2022 , S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,\nK. Cho, and A. Oh, Eds., 2022. [Online]. Available:\nhttp://papers.nips.cc/paper_files/paper/2022/hash/\n9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.\nhtml\n[58] A. K. Lampinen, I. Dasgupta, S. C. Y . Chan,\nK. W. Mathewson, M. H. Tessler, A. Creswell, J. L.\nMcClelland, J. Wang, and F. Hill, \u201cCan language\nmodels learn from explanations in context?\u201d in Findings\nof the Association for Computational Linguistics:\nEMNLP 2022, Abu Dhabi, United Arab Emirates,\nDecember 7-11, 2022 , Y . Goldberg, Z. Kozareva,\nand Y . Zhang, Eds. Association for Computational\nLinguistics, 2022, pp. 537\u2013563. [Online]. Available:\nhttps://doi.org/10.18653/v1/2022.findings-emnlp.38\n[59] F. Petroni, T. Rockt\u00e4schel, S. Riedel, P. S. H. Lewis,\nA. Bakhtin, Y . Wu, and A. H. Miller, \u201cLanguage models\nas knowledge bases?\u201d in Proceedings of the 2019\nConference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference\non Natural Language Processing, EMNLP-IJCNLP 2019,\nHong Kong, China, November 3-7, 2019 , K. Inui, J. Jiang,\nV . Ng, and X. Wan, Eds. Association for Computational\nLinguistics, 2019, pp. 2463\u20132473. [Online].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1882, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4": {"__data__": {"id_": "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4", "embedding": null, "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "87ff029e5630ed1bbb22d2ff6a09d6400c47d7b9ccb1784e90ef72be59682215", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1e10088-4cfc-43ce-939e-19fcb73305d2", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "78e6ff2bc5a6db0fc97e313b1865d4f419e807416a256c38293141fb610e8d5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d84e019-eeef-4928-b5a0-84839d1809b6", "node_type": "1", "metadata": {}, "hash": "3092b0bed12f364fc7f01ff45a58f926a1d2d3639aba2ebe063eb64c26decbe1", "class_name": "RelatedNodeInfo"}}, "text": "537\u2013563. [Online]. Available:\nhttps://doi.org/10.18653/v1/2022.findings-emnlp.38\n[59] F. Petroni, T. Rockt\u00e4schel, S. Riedel, P. S. H. Lewis,\nA. Bakhtin, Y . Wu, and A. H. Miller, \u201cLanguage models\nas knowledge bases?\u201d in Proceedings of the 2019\nConference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference\non Natural Language Processing, EMNLP-IJCNLP 2019,\nHong Kong, China, November 3-7, 2019 , K. Inui, J. Jiang,\nV . Ng, and X. Wan, Eds. Association for Computational\nLinguistics, 2019, pp. 2463\u20132473. [Online]. Available:\nhttps://doi.org/10.18653/v1/D19-1250\n[60] B. Cao, H. Lin, X. Han, L. Sun, L. Yan, M. Liao, T. Xue,\nand J. Xu, \u201cKnowledgeable or educated guess? revisiting\nlanguage models as knowledge bases,\u201d in Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing,\nACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021 , C. Zong, F. Xia, W. Li,\nand R. Navigli, Eds. Association for Computational\nLinguistics, 2021, pp. 1860\u20131874. [Online]. Available:\nhttps://doi.org/10.18653/v1/2021.acl-long.146\n[61] J. M. Johnson and T. M. Khoshgoftaar, \u201cSurvey\non deep learning with class imbalance,\u201d J. Big\nData , vol. 6, p. 27, 2019. [Online]. Available:\nhttps://doi.org/10.1186/s40537-019-0192-5\n[62] X. Liu, J. Wu, and Z. Zhou, \u201cExploratory undersampling\nfor class-imbalance learning,\u201d IEEE Trans. Syst. ManCybern. Part B , vol. 39, no. 2, pp. 539\u2013550, 2009.\n[Online]. Available: https://doi.org/10.1109/TSMCB.2008.", "mimetype": "text/plain", "start_char_idx": 1325, "end_char_idx": 2914, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d84e019-eeef-4928-b5a0-84839d1809b6": {"__data__": {"id_": "0d84e019-eeef-4928-b5a0-84839d1809b6", "embedding": null, "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "87ff029e5630ed1bbb22d2ff6a09d6400c47d7b9ccb1784e90ef72be59682215", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "fd068aba283f56748113f1cf252a0a2e6aca2d9bd1fe610300c0c6e724244ca3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c95d9ff8-758e-444f-9a20-30c51743aaed", "node_type": "1", "metadata": {}, "hash": "47acef41290f139067d93e740e199b72254a2c0bdd4914c1fe7e0df24844f4e6", "class_name": "RelatedNodeInfo"}}, "text": "1860\u20131874. [Online]. Available:\nhttps://doi.org/10.18653/v1/2021.acl-long.146\n[61] J. M. Johnson and T. M. Khoshgoftaar, \u201cSurvey\non deep learning with class imbalance,\u201d J. Big\nData , vol. 6, p. 27, 2019. [Online]. Available:\nhttps://doi.org/10.1186/s40537-019-0192-5\n[62] X. Liu, J. Wu, and Z. Zhou, \u201cExploratory undersampling\nfor class-imbalance learning,\u201d IEEE Trans. Syst. ManCybern. Part B , vol. 39, no. 2, pp. 539\u2013550, 2009.\n[Online]. Available: https://doi.org/10.1109/TSMCB.2008.\n2007853\n[63] A. Svyatkovskiy, S. K. Deng, S. Fu, and\nN. Sundaresan, \u201cIntellicode compose: code generation\nusing transformer,\u201d in ESEC/FSE \u201920: 28th ACM\nJoint European Software Engineering Conference\nand Symposium on the Foundations of Software\nEngineering, Virtual Event, USA, November 8-13, 2020 ,\nP. Devanbu, M. B. Cohen, and T. Zimmermann,\nEds. ACM, 2020, pp. 1433\u20131443. [Online]. Available:\nhttps://doi.org/10.1145/3368089.3417058\n[64] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. T.\nDevanbu, \u201cOn the naturalness of software,\u201d in 34th\nInternational Conference on Software Engineering, ICSE\n2012, June 2-9, 2012, Zurich, Switzerland , M. Glinz,\nG. C. Murphy, and M. Pezz\u00e8, Eds. IEEE Computer\nSociety, 2012, pp. 837\u2013847. [Online]. Available:\nhttps://doi.org/10.1109/ICSE.2012.6227135\n[65] T. Gao, A. Fisch, and D. Chen, \u201cMaking pre-trained\nlanguage models better few-shot learners,\u201d in Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing,\nACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021 , C. Zong, F. Xia, W. Li,\nand R. Navigli, Eds. Association for Computational\nLinguistics, 2021, pp. 3816\u20133830. [Online].", "mimetype": "text/plain", "start_char_idx": 2427, "end_char_idx": 4163, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c95d9ff8-758e-444f-9a20-30c51743aaed": {"__data__": {"id_": "c95d9ff8-758e-444f-9a20-30c51743aaed", "embedding": null, "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "87ff029e5630ed1bbb22d2ff6a09d6400c47d7b9ccb1784e90ef72be59682215", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0d84e019-eeef-4928-b5a0-84839d1809b6", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "e28fec0551f85930064257be8d185ffb219f8683fe57116ed3e73884cbd4491d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "411b3637-622c-40eb-9bf0-551b3d3ecaa5", "node_type": "1", "metadata": {}, "hash": "4dbcf03284bb3c8ca46eb8262792096048bbccaab40d9377d98533b373800bde", "class_name": "RelatedNodeInfo"}}, "text": "IEEE Computer\nSociety, 2012, pp. 837\u2013847. [Online]. Available:\nhttps://doi.org/10.1109/ICSE.2012.6227135\n[65] T. Gao, A. Fisch, and D. Chen, \u201cMaking pre-trained\nlanguage models better few-shot learners,\u201d in Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing,\nACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021 , C. Zong, F. Xia, W. Li,\nand R. Navigli, Eds. Association for Computational\nLinguistics, 2021, pp. 3816\u20133830. [Online]. Available:\nhttps://doi.org/10.18653/v1/2021.acl-long.295\n[66] Z. Jiang, F. F. Xu, J. Araki, and G. Neubig,\n\u201cHow can we know what language models know,\u201d\nvol. 8, 2020, pp. 423\u2013438. [Online]. Available:\nhttps://doi.org/10.1162/tacl_a_00324\n[67] E. Mitchell, C. Lin, A. Bosselut, C. D. Manning,\nand C. Finn, \u201cMemory-based model editing at scale,\u201d\ninInternational Conference on Machine Learning,\nICML 2022, 17-23 July 2022, Baltimore, Maryland,\nUSA, ser. Proceedings of Machine Learning Research,\nK. Chaudhuri, S. Jegelka, L. Song, C. Szepesv\u00e1ri,\nG. Niu, and S. Sabato, Eds., vol. 162. PMLR,\n2022, pp. 15 817\u201315 831. [Online]. Available: https:\n//proceedings.mlr.press/v162/mitchell22a.html\n[68] S. Murty, C. D. Manning, S. M. Lundberg, and M. T.\nRibeiro, \u201cFixing model bugs with natural language\npatches,\u201d in Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\nEMNLP 2022, Abu Dhabi, United Arab Emirates,\nDecember 7-11, 2022 , Y . Goldberg, Z. Kozareva,\nand Y . Zhang, Eds. Association for Computational\nLinguistics, 2022, pp. 11 600\u201311 613. [Online]. Available:\nhttps://doi.org/10.18653/v1/2022.emnlp-main.797\n[69] A. Madaan, N. Tandon, P. Clark, and Y .", "mimetype": "text/plain", "start_char_idx": 3598, "end_char_idx": 5352, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "411b3637-622c-40eb-9bf0-551b3d3ecaa5": {"__data__": {"id_": "411b3637-622c-40eb-9bf0-551b3d3ecaa5", "embedding": null, "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "87ff029e5630ed1bbb22d2ff6a09d6400c47d7b9ccb1784e90ef72be59682215", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c95d9ff8-758e-444f-9a20-30c51743aaed", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "9cacac94d9d7f81212973c8ce09961de6401a8c6fa81ff8242dc554d5928437a", "class_name": "RelatedNodeInfo"}}, "text": "Available: https:\n//proceedings.mlr.press/v162/mitchell22a.html\n[68] S. Murty, C. D. Manning, S. M. Lundberg, and M. T.\nRibeiro, \u201cFixing model bugs with natural language\npatches,\u201d in Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\nEMNLP 2022, Abu Dhabi, United Arab Emirates,\nDecember 7-11, 2022 , Y . Goldberg, Z. Kozareva,\nand Y . Zhang, Eds. Association for Computational\nLinguistics, 2022, pp. 11 600\u201311 613. [Online]. Available:\nhttps://doi.org/10.18653/v1/2022.emnlp-main.797\n[69] A. Madaan, N. Tandon, P. Clark, and Y . Yang,\n\u201cMemory-assisted prompt editing to improve GPT-3 after\ndeployment,\u201d in Proceedings of the 2022 Conference\non Empirical Methods in Natural Language Processing,\nEMNLP 2022, Abu Dhabi, United Arab Emirates,", "mimetype": "text/plain", "start_char_idx": 4786, "end_char_idx": 5562, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "24b1966f-af41-4611-9b78-f569671c40e1": {"__data__": {"id_": "24b1966f-af41-4611-9b78-f569671c40e1", "embedding": null, "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "456d6b054c34edf9071aa04c2668d202454bbad2ed2e7770d827fb805b6de75f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b", "node_type": "1", "metadata": {}, "hash": "6d89683884a00b98f46167345d9530a9ec6161208c3782af6575e5a3c0779e86", "class_name": "RelatedNodeInfo"}}, "text": "December 7-11, 2022 , Y . Goldberg, Z. Kozareva,\nand Y . Zhang, Eds. Association for Computational\nLinguistics, 2022, pp. 2833\u20132861. [Online]. Available:\nhttps://doi.org/10.18653/v1/2022.emnlp-main.183\n[70] K. Meng, D. Bau, A. Andonian, and Y . Belinkov,\n\u201cLocating and editing factual associations in GPT,\u201d in\nAdvances in Neural Information Processing Systems\n35: Annual Conference on Neural Information\nProcessing Systems 2022, NeurIPS 2022, New Orleans,\nLA, USA, November 28 - December 9, 2022 ,\nS. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,\nK. Cho, and A. Oh, Eds., 2022. [Online]. Available:\nhttp://papers.nips.cc/paper_files/paper/2022/hash/\n6f1d43d5a82a37e89b0665b33bf3a182-Abstract-Conference.\nhtml\n[71] K. Meng, A. S. Sharma, A. J. Andonian, Y . Belinkov,\nand D. Bau, \u201cMass-editing memory in a transformer,\u201d\ninThe Eleventh International Conference on Learning\nRepresentations, ICLR 2023, Kigali, Rwanda, May\n1-5, 2023 . OpenReview.net, 2023. [Online]. Available:\nhttps://openreview.net/pdf?id=MkbcAHIYgyS\n[72] X. Li, S. Li, S. Song, J. Yang, J. Ma, and J. Yu, \u201cPMET:\nprecise model editing in a transformer,\u201d in Thirty-Eighth\nAAAI Conference on Artificial Intelligence, AAAI 2024,\nThirty-Sixth Conference on Innovative Applications of\nArtificial Intelligence, IAAI 2024, Fourteenth Symposium\non Educational Advances in Artificial Intelligence, EAAI\n2014, February 20-27, 2024, Vancouver, Canada , M. J.\nWooldridge, J. G. Dy, and S. Natarajan, Eds. AAAI\nPress, 2024, pp. 18 564\u201318 572. [Online]. Available:\nhttps://doi.org/10.1609/aaai.v38i17.29818\n[73] N. D. Cao, W. Aziz, and I. Titov, \u201cEditing factual\nknowledge in language models,\u201d in Proceedings\nof the 2021 Conference on Empirical Methods inNatural Language Processing, EMNLP 2021, Virtual\nEvent / Punta Cana, Dominican Republic, 7-11\nNovember, 2021 , M. Moens, X. Huang, L. Specia,\nand S. W. Yih, Eds.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1866, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b": {"__data__": {"id_": "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b", "embedding": null, "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "456d6b054c34edf9071aa04c2668d202454bbad2ed2e7770d827fb805b6de75f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "24b1966f-af41-4611-9b78-f569671c40e1", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "db24671b2898c277eb3216ec205f300f06bc1d84db30069eb0074b77ebe40bdf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "92b689cf-b73d-4b66-82f3-dc36039677c1", "node_type": "1", "metadata": {}, "hash": "085a40e70360330b932cca557d6644ac458b630750f4a8125d74d87376188bcd", "class_name": "RelatedNodeInfo"}}, "text": "AAAI\nPress, 2024, pp. 18 564\u201318 572. [Online]. Available:\nhttps://doi.org/10.1609/aaai.v38i17.29818\n[73] N. D. Cao, W. Aziz, and I. Titov, \u201cEditing factual\nknowledge in language models,\u201d in Proceedings\nof the 2021 Conference on Empirical Methods inNatural Language Processing, EMNLP 2021, Virtual\nEvent / Punta Cana, Dominican Republic, 7-11\nNovember, 2021 , M. Moens, X. Huang, L. Specia,\nand S. W. Yih, Eds. Association for Computational\nLinguistics, 2021, pp. 6491\u20136506. [Online]. Available:\nhttps://doi.org/10.18653/v1/2021.emnlp-main.522\n[74] E. Mitchell, C. Lin, A. Bosselut, C. Finn, and\nC. D. Manning, \u201cFast model editing at scale,\u201d in\nThe Tenth International Conference on Learning\nRepresentations, ICLR 2022, Virtual Event, April 25-\n29, 2022 . OpenReview.net, 2022. [Online]. Available:\nhttps://openreview.net/forum?id=0DcZxeWfOPt\n[75] P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni,\nV . Karpukhin, N. Goyal, H. K\u00fcttler, M. Lewis, W. Yih,\nT. Rockt\u00e4schel, S. Riedel, and D. Kiela, \u201cRetrieval-\naugmented generation for knowledge-intensive NLP\ntasks,\u201d in Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information\nProcessing Systems 2020, NeurIPS 2020, December\n6-12, 2020, virtual , H. Larochelle, M. Ranzato,\nR. Hadsell, M. Balcan, and H. Lin, Eds., 2020. [Online].\nAvailable: https://proceedings.neurips.cc/paper/2020/hash/\n6b493230205f780e1bc26945df7481e5-Abstract.html\n[76] S. Gronauer and K. Diepold, \u201cMulti-agent deep reinforce-\nment learning: a survey,\u201d Artificial Intelligence Review ,\nvol. 55, no. 2, pp. 895\u2013943, 2022.\n[77] Y . Talebirad and A. Nadiri, \u201cMulti-agent collaboration:\nHarnessing the power of intelligent llm agents,\u201d arXiv\npreprint arXiv:2306.03314 , 2023.", "mimetype": "text/plain", "start_char_idx": 1457, "end_char_idx": 3181, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "92b689cf-b73d-4b66-82f3-dc36039677c1": {"__data__": {"id_": "92b689cf-b73d-4b66-82f3-dc36039677c1", "embedding": null, "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "456d6b054c34edf9071aa04c2668d202454bbad2ed2e7770d827fb805b6de75f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b", "node_type": "1", "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}, "hash": "e1959fbc0840bb095c68dc2d076ebf033d2a45ef288f49987b3320e8b61132a5", "class_name": "RelatedNodeInfo"}}, "text": "[Online].\nAvailable: https://proceedings.neurips.cc/paper/2020/hash/\n6b493230205f780e1bc26945df7481e5-Abstract.html\n[76] S. Gronauer and K. Diepold, \u201cMulti-agent deep reinforce-\nment learning: a survey,\u201d Artificial Intelligence Review ,\nvol. 55, no. 2, pp. 895\u2013943, 2022.\n[77] Y . Talebirad and A. Nadiri, \u201cMulti-agent collaboration:\nHarnessing the power of intelligent llm agents,\u201d arXiv\npreprint arXiv:2306.03314 , 2023.\n[78] B. Ellis, J. Cook, S. Moalla, M. Samvelyan, M. Sun,\nA. Mahajan, J. Foerster, and S. Whiteson, \u201cSmacv2:\nAn improved benchmark for cooperative multi-agent\nreinforcement learning,\u201d Advances in Neural Information\nProcessing Systems , vol. 36, 2024.", "mimetype": "text/plain", "start_char_idx": 2759, "end_char_idx": 3431, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"e8aa655b-29e6-4704-840b-85c2837539bd": {"doc_hash": "f5417f99347ab77e8aca5a0389e48b56f9d044939c464ddaa3fc877e6bc3ff92", "ref_doc_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c"}, "0d64b766-68be-49b4-b9d1-eb4881b0f0d8": {"doc_hash": "07e53b52fbcef0dbe7417c6a2f7f861d654677c4378fe765b2fe43505fdb83ff", "ref_doc_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c"}, "ed7f7466-a6bf-4152-9e52-2b80bced6b35": {"doc_hash": "9f12eeb33e87d23d518fc221e225d50abfccc964a17542a43494abbac619f3cb", "ref_doc_id": "2c1f022c-8f8e-459b-88d4-c8484cf7d82c"}, "985bf3e8-9ac6-4377-9830-bd40e63cc4df": {"doc_hash": "926e1557e002152025526ae0e37b8a62aae361018e19dea60287ed4c17199973", "ref_doc_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4"}, "30c4eaaf-3038-4969-ae1c-67dfff2da784": {"doc_hash": "5f7289c6677109ebcea62411ee2f5389ab97dccc3c31c185c1f61902cdbbf00d", "ref_doc_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4"}, "c705b20e-0dc7-4f37-9b58-b2ab0ebae75e": {"doc_hash": "7ad3d63b2409ed548a431457a54a35b1c026ea28764472cd469beea00e5bf749", "ref_doc_id": "390258c1-2e52-449a-b7f6-1205e8dee4f4"}, "fb2ebb7c-593a-4b86-ac70-23bd48011946": {"doc_hash": "d07c3b2a338b80b70ca30a6c1bcb43bc9279731425d15b447292cb993cc19b10", "ref_doc_id": "44e499e2-84d9-471a-bb89-e79885547d8c"}, "6bffa0af-c2fd-4965-8d55-8c53d0135ecf": {"doc_hash": "55c598e9aa5f85818729cadfc654d65ff00d594bf4774208ca9266790f9000d6", "ref_doc_id": "44e499e2-84d9-471a-bb89-e79885547d8c"}, "6962cab4-99cf-4faa-9046-7e4ec07da786": {"doc_hash": "fce47b44f4e444f4f63fa6aea74e28f9aa0a9bbb420c2bca02044e590d64aaed", "ref_doc_id": "44e499e2-84d9-471a-bb89-e79885547d8c"}, "d69a6ae0-a550-4168-a970-644ba5fe7867": {"doc_hash": "82aaf5654ce62dfc1115e7683da00a96e4f05ed749122081d281290fc4297f2e", "ref_doc_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5"}, "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6": {"doc_hash": "fd1ee196804d48d9d9d8a46af01d967729a64651ea889848d980aec54bbe0668", "ref_doc_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5"}, "8a751a7e-8269-4a3b-ab57-23056b03605d": {"doc_hash": "c1b24138dbe73bee14f10f2b1fccd24d4da852b168bb9552e1dc3833ccd31356", "ref_doc_id": "cfc1c96b-a5ea-4982-8815-d387ba85b8e5"}, "dc767552-1244-45fc-93a1-f8e8727c5606": {"doc_hash": "5589b3ddf255dc5ab3b28275e17efaad286ea8cd7d925e33300cba5a8706c1f1", "ref_doc_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77"}, "a6d6f873-ddda-43c4-816a-74094468b294": {"doc_hash": "49e274767cd20a3ed32dc2e909b879cbde32b68cbc0e26c191e1630a45553891", "ref_doc_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77"}, "5ac7e86f-5390-4fba-827e-5b7841194cd1": {"doc_hash": "1c7014f1200c1413722d1d33ad0504e9b5aa38dd84dd2418a340bee686e9134f", "ref_doc_id": "7cf426dc-ee1e-4bac-a1e2-a94db0496e77"}, "03742b21-750a-4466-a34a-1cda4a78c6ca": {"doc_hash": "098a56ce5e28a117f576e2b8e5e0b61eb84571e9bee00e98aca818fa22151366", "ref_doc_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972"}, "3a5e0295-b273-4f53-a41b-d6d107627d14": {"doc_hash": "d84015b91217a50d7e26602059cd17fc536945c9c778c0de4e2a909408eb3202", "ref_doc_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972"}, "287659e0-6a62-46b2-b623-10c48f3be32b": {"doc_hash": "372da90aa7b860bce4a47f3a8569eb22bf22960b8a5518dbfc55299ea3544ea5", "ref_doc_id": "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972"}, "36e3e2f2-34b3-485d-8c4c-e6f3c11cc2d4": {"doc_hash": "da9e68fb2d89ffcf4849e160d3121ba6fac5e07607e6df6b0231f7c4fab63f52", "ref_doc_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a"}, "94565e18-a11a-43e1-a068-323f08a8f7cc": {"doc_hash": "b386a45ce1d82b49ec1021e4c40f43eb69b3f98960ce03db3bf8449deb0bf716", "ref_doc_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a"}, "f7ec9e23-6b59-48f1-88ea-f51ced473ada": {"doc_hash": "d0e988fcf9a27e2866dafa32c94e203ebdac852a39e98312ca18757ed3418dcc", "ref_doc_id": "c020dc39-3696-43c7-85d9-b19ae2f4ea3a"}, "f8ff5c42-8485-434c-9d51-4050e60bc1f9": {"doc_hash": "c021250f61185b0ae0b1ff971b70880fd55754c880fbe3c102db51f0479fdefa", "ref_doc_id": "568c0afc-7a11-41a6-b60d-1a63d39797b9"}, "ebfd879e-a450-47b2-b02a-1f3d3fbc805a": {"doc_hash": "ba5ad3da13fa05ac144758860adeac8c4e938e0179be57856168fbeb6f3d8210", "ref_doc_id": "568c0afc-7a11-41a6-b60d-1a63d39797b9"}, "293dcdba-9c12-491c-b1ff-cd2bf7a49090": {"doc_hash": "89ca6d30cffaac9f40bb8b19598b280880c4e5402aba1eb09130b0a686bcb77a", "ref_doc_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e"}, "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6": {"doc_hash": "95d6d6c5a27d0a91875c865df9b6bf7cca4c2dd226487385cc273f8b06b888a3", "ref_doc_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e"}, "a0ad9f12-1ecc-44ef-b5ea-503f59e077c4": {"doc_hash": "1513b3030163d2970910d6a93048c88cd6529a420d0d76c7be87cca4473cd2df", "ref_doc_id": "6aeaeb89-b38d-437d-8d18-3f68b2e6248e"}, "1c1d2bcf-de1f-45ca-b02f-c72a68c79c18": {"doc_hash": "3a83263a366e608bba21265571c93a9d4018ccf421285235a635efc3729cd935", "ref_doc_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5"}, "422fff72-2d71-4cc4-ab75-56b8ca2a48d4": {"doc_hash": "74d4fd98fa7827ded6fe317df0aa2eb32b67c48b5088d8d60d5d31ee09065af6", "ref_doc_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5"}, "a4770889-a936-4e84-ba0b-1a28c6935035": {"doc_hash": "7ba5a48161ffd92205ccde6a8e293058f9f0e3d6e9236e7c9800ea234f5fa669", "ref_doc_id": "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5"}, "19341c9c-8aee-4768-9f19-f07c9e5eb9e3": {"doc_hash": "a7494212043a5cef4e38c4df650cd41d39e10d83453616b199366c58bfe85536", "ref_doc_id": "e8cc96cc-5a00-43f9-abca-e44edc04bb85"}, "6455f91c-fd0c-43c0-ae49-cbba80e1c008": {"doc_hash": "775f120dedb562814eced41acb37b8e7aae68a166d5c6f8f053d5127be27c6c0", "ref_doc_id": "e8cc96cc-5a00-43f9-abca-e44edc04bb85"}, "1030cf9d-37e2-4eda-9445-f3ba6b42ee30": {"doc_hash": "7ca59ec150d0a4e4725ffba556787c2bdb080594ab7fbde3affc1cf7e4bc042e", "ref_doc_id": "440904ad-fc72-4c73-8017-96c6e54e06a8"}, "bdca76f3-30ad-4f70-a935-8298ff094aac": {"doc_hash": "7b64a93977543e38ad010a7c53952e8403269ed3839fdd32d425efd5b620b040", "ref_doc_id": "440904ad-fc72-4c73-8017-96c6e54e06a8"}, "502b67dd-3c95-4e5c-9332-a9f66bc546dd": {"doc_hash": "ec60588a4b91908faf5c635569a920df2e2a184f72bca457f44ddf235c7e8ecb", "ref_doc_id": "440904ad-fc72-4c73-8017-96c6e54e06a8"}, "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4": {"doc_hash": "4cb9f158cec4af1094a9f432273d87e8a06631a861cac4ba876fe2802cf24ce2", "ref_doc_id": "440904ad-fc72-4c73-8017-96c6e54e06a8"}, "bd9e42f4-89c5-445e-a844-89b3f3a9d7ac": {"doc_hash": "f258ddf3edd5b5cb2344d3208369aaba4fe4d13fc31257b4f9c3c297b3338c34", "ref_doc_id": "440904ad-fc72-4c73-8017-96c6e54e06a8"}, "343c4a20-d73d-4824-ba0a-66ea69aa63f6": {"doc_hash": "4e0ef0eba613c84a099495f1d2266f3e5799c0a895affb557201cf8684972ed9", "ref_doc_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe"}, "557d35e6-79de-437b-a2ce-74ea32be819d": {"doc_hash": "efeb1b01f97d77657085170494b0f3f92dcd53372be69eb73a71c98f0d54495f", "ref_doc_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe"}, "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb": {"doc_hash": "2a9979eba419c4ceaa63d2f0eb680a83f0ba1fbe7139959ef7a32e461d4deeb6", "ref_doc_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe"}, "a0190e81-87d6-46bb-8c1c-47396e601f8f": {"doc_hash": "e7d3c683653de4ffb95b6d7983490d2c73dd89b9609fe523307c03fc689ec515", "ref_doc_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe"}, "74fa9ea5-cb0c-4c15-93db-bd058b4b0f1a": {"doc_hash": "9bc661367bc882b83cb645b24a39dccb631d73239e1c0c0706f948ff648de85e", "ref_doc_id": "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe"}, "a1e10088-4cfc-43ce-939e-19fcb73305d2": {"doc_hash": "78e6ff2bc5a6db0fc97e313b1865d4f419e807416a256c38293141fb610e8d5d", "ref_doc_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da"}, "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4": {"doc_hash": "fd068aba283f56748113f1cf252a0a2e6aca2d9bd1fe610300c0c6e724244ca3", "ref_doc_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da"}, "0d84e019-eeef-4928-b5a0-84839d1809b6": {"doc_hash": "e28fec0551f85930064257be8d185ffb219f8683fe57116ed3e73884cbd4491d", "ref_doc_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da"}, "c95d9ff8-758e-444f-9a20-30c51743aaed": {"doc_hash": "9cacac94d9d7f81212973c8ce09961de6401a8c6fa81ff8242dc554d5928437a", "ref_doc_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da"}, "411b3637-622c-40eb-9bf0-551b3d3ecaa5": {"doc_hash": "392407aa8da0066241ae087f8a37e27946d7b5a70c41e3bce6dd6f79e465b7c5", "ref_doc_id": "ed7c60d4-0c49-41d7-a4e1-365dfcd012da"}, "24b1966f-af41-4611-9b78-f569671c40e1": {"doc_hash": "db24671b2898c277eb3216ec205f300f06bc1d84db30069eb0074b77ebe40bdf", "ref_doc_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc"}, "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b": {"doc_hash": "e1959fbc0840bb095c68dc2d076ebf033d2a45ef288f49987b3320e8b61132a5", "ref_doc_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc"}, "92b689cf-b73d-4b66-82f3-dc36039677c1": {"doc_hash": "302b1a3b0f363a10ec73e44d5b606896b46bd5ba80790d79caf131a9e7f68c5c", "ref_doc_id": "de9c2ed1-2bbc-4a38-9812-ab21add265dc"}}, "docstore/ref_doc_info": {"2c1f022c-8f8e-459b-88d4-c8484cf7d82c": {"node_ids": ["e8aa655b-29e6-4704-840b-85c2837539bd", "0d64b766-68be-49b4-b9d1-eb4881b0f0d8", "ed7f7466-a6bf-4152-9e52-2b80bced6b35"], "metadata": {"page_label": "1", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "390258c1-2e52-449a-b7f6-1205e8dee4f4": {"node_ids": ["985bf3e8-9ac6-4377-9830-bd40e63cc4df", "30c4eaaf-3038-4969-ae1c-67dfff2da784", "c705b20e-0dc7-4f37-9b58-b2ab0ebae75e"], "metadata": {"page_label": "2", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "44e499e2-84d9-471a-bb89-e79885547d8c": {"node_ids": ["fb2ebb7c-593a-4b86-ac70-23bd48011946", "6bffa0af-c2fd-4965-8d55-8c53d0135ecf", "6962cab4-99cf-4faa-9046-7e4ec07da786"], "metadata": {"page_label": "3", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "cfc1c96b-a5ea-4982-8815-d387ba85b8e5": {"node_ids": ["d69a6ae0-a550-4168-a970-644ba5fe7867", "7f1296b4-95e2-4bbe-92ec-b806ed12a9a6", "8a751a7e-8269-4a3b-ab57-23056b03605d"], "metadata": {"page_label": "4", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "7cf426dc-ee1e-4bac-a1e2-a94db0496e77": {"node_ids": ["dc767552-1244-45fc-93a1-f8e8727c5606", "a6d6f873-ddda-43c4-816a-74094468b294", "5ac7e86f-5390-4fba-827e-5b7841194cd1"], "metadata": {"page_label": "5", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "81202e8f-6cbf-45f4-ba89-6e8f6bfd1972": {"node_ids": ["03742b21-750a-4466-a34a-1cda4a78c6ca", "3a5e0295-b273-4f53-a41b-d6d107627d14", "287659e0-6a62-46b2-b623-10c48f3be32b"], "metadata": {"page_label": "6", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "c020dc39-3696-43c7-85d9-b19ae2f4ea3a": {"node_ids": ["36e3e2f2-34b3-485d-8c4c-e6f3c11cc2d4", "94565e18-a11a-43e1-a068-323f08a8f7cc", "f7ec9e23-6b59-48f1-88ea-f51ced473ada"], "metadata": {"page_label": "7", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "568c0afc-7a11-41a6-b60d-1a63d39797b9": {"node_ids": ["f8ff5c42-8485-434c-9d51-4050e60bc1f9", "ebfd879e-a450-47b2-b02a-1f3d3fbc805a"], "metadata": {"page_label": "8", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "6aeaeb89-b38d-437d-8d18-3f68b2e6248e": {"node_ids": ["293dcdba-9c12-491c-b1ff-cd2bf7a49090", "bd8d4ae5-6d58-4f35-a2b7-acb5ae8ecfd6", "a0ad9f12-1ecc-44ef-b5ea-503f59e077c4"], "metadata": {"page_label": "9", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "5dd74fc1-9a8a-41d1-b74b-b6a4fb2e00e5": {"node_ids": ["1c1d2bcf-de1f-45ca-b02f-c72a68c79c18", "422fff72-2d71-4cc4-ab75-56b8ca2a48d4", "a4770889-a936-4e84-ba0b-1a28c6935035"], "metadata": {"page_label": "10", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "e8cc96cc-5a00-43f9-abca-e44edc04bb85": {"node_ids": ["19341c9c-8aee-4768-9f19-f07c9e5eb9e3", "6455f91c-fd0c-43c0-ae49-cbba80e1c008"], "metadata": {"page_label": "11", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "440904ad-fc72-4c73-8017-96c6e54e06a8": {"node_ids": ["1030cf9d-37e2-4eda-9445-f3ba6b42ee30", "bdca76f3-30ad-4f70-a935-8298ff094aac", "502b67dd-3c95-4e5c-9332-a9f66bc546dd", "19ed2b0b-ebdf-456f-bd9e-a7107ca25af4", "bd9e42f4-89c5-445e-a844-89b3f3a9d7ac"], "metadata": {"page_label": "12", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "f94eca1a-cd7e-4186-8321-f9eb9ffcdbbe": {"node_ids": ["343c4a20-d73d-4824-ba0a-66ea69aa63f6", "557d35e6-79de-437b-a2ce-74ea32be819d", "39de02e5-c8dc-449e-a7d7-8ab9e9fca1cb", "a0190e81-87d6-46bb-8c1c-47396e601f8f", "74fa9ea5-cb0c-4c15-93db-bd058b4b0f1a"], "metadata": {"page_label": "13", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "ed7c60d4-0c49-41d7-a4e1-365dfcd012da": {"node_ids": ["a1e10088-4cfc-43ce-939e-19fcb73305d2", "cc6e2508-dfdc-4449-92b6-6cb0bd4119a4", "0d84e019-eeef-4928-b5a0-84839d1809b6", "c95d9ff8-758e-444f-9a20-30c51743aaed", "411b3637-622c-40eb-9bf0-551b3d3ecaa5"], "metadata": {"page_label": "14", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}, "de9c2ed1-2bbc-4a38-9812-ab21add265dc": {"node_ids": ["24b1966f-af41-4611-9b78-f569671c40e1", "0bdfaa3e-8c51-4247-8c25-ea3bcba24c0b", "92b689cf-b73d-4b66-82f3-dc36039677c1"], "metadata": {"page_label": "15", "file_name": "2406_09834v1.pdf", "Title of this paper": "How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study", "Authors": "Chong Wang, Kaifeng Huang, Jian Zhang, Yebo Feng, Lyuye Zhang, Yang Liu, Xin Peng", "Date published": "06/14/2024", "URL": "http://arxiv.org/abs/2406.09834v1", "summary": "Large language models (LLMs), pre-trained or fine-tuned on large code\ncorpora, have shown effectiveness in generating code completions. However, in\nLLM-based code completion, LLMs may struggle to use correct and up-to-date\nApplication Programming Interfaces (APIs) due to the rapid and continuous\nevolution of libraries. While existing studies have highlighted issues with\npredicting incorrect APIs, the specific problem of deprecated API usage in\nLLM-based code completion has not been thoroughly investigated.\n  To address this gap, we conducted the first evaluation study on deprecated\nAPI usage in LLM-based code completion. This study involved seven advanced\nLLMs, 145 API mappings from eight popular Python libraries, and 28,125\ncompletion prompts. The study results reveal the \\textit{status quo} and\n\\textit{root causes} of deprecated API usage in LLM-based code completion from\nthe perspectives of \\textit{model}, \\textit{prompt}, and \\textit{library}.\nBased on these findings, we propose two lightweight fixing approaches,\n\\textsc{ReplaceAPI} and \\textsc{InsertPrompt}, which can serve as baseline\napproaches for future research on mitigating deprecated API usage in LLM-based\ncompletion. Additionally, we provide implications for future research on\nintegrating library evolution with LLM-driven software development."}}}}