{"docstore/data": {"608317b7-9505-4d1b-9167-5975acf1e1be": {"__data__": {"id_": "608317b7-9505-4d1b-9167-5975acf1e1be", "embedding": null, "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c26d813-bbc5-4e75-ba6b-c5c360a91cc7", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "f15ed8dc322116b9cbb511e3eb740b742035169a3070599d42db1079757666fd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4de40ce2-9fe8-44f8-9f66-55c0452e7f07", "node_type": "1", "metadata": {}, "hash": "0df26a2e1cdd5991b842ef07904f1b46e2b0e88d7c325b745f16cc7f88b23ea5", "class_name": "RelatedNodeInfo"}}, "text": "Incremental Learning of Stock Trends via Meta-Learning\nwith Dynamic Adaptation\nShiluo Huang1,Zheng Liu2,Ye Deng1and Qing Li\u22171\n1Southwestern University of Finance and Economics, Chengdu, China\n2Tsinghua University, Beijing, China\nAbstract\nForecasting the trend of stock prices is an enduring\ntopic at the intersection of finance and computer\nscience. Periodical updates to forecasters have\nproven effective in handling concept drifts arising\nfrom non-stationary markets. However, the existing\nmethods neglect either emerging patterns in recent\ndata or recurring patterns in historical data, both of\nwhich are empirically advantageous for future fore-\ncasting. To address this issue, we propose meta-\nlearning with dynamic adaptation (MetaDA) for the\nincremental learning of stock trends, which peri-\nodically performs dynamic model adaptation uti-\nlizing the emerging and recurring patterns simul-\ntaneously. We initially organize the stock trend\nforecasting into meta-learning tasks and train a\nforecasting model following meta-learning proto-\ncols. During model adaptation, MetaDA efficiently\nadapts the forecasting model with the latest data\nand a selected portion of historical data, which is\ndynamically identified by a task inference mod-\nule. The task inference module first extracts task-\nlevel embeddings from the historical tasks, and then\nidentifies the informative data with a task infer-\nence network. MetaDA has been evaluated on real-\nworld stock datasets, achieving state-of-the-art per-\nformance with satisfactory efficiency.\n1 Introduction\nStock trend forecasting is a classical but challenging prob-\nlem, drawing the attention of both economists and computer\nscientists [Balvers et al. , 1990; Lin et al. , 2021 ]. How-\never, the stock market is a recognized non-stationary envi-\nronment where data distribution varies over time [Yamanishi\nand Takeuchi, 2002; Liang et al. , 2021 ]. Such a phenomenon\nof distribution shift or concept drift [Zhan et al. , 2022;\nGunasekara et al. , 2023 ]presents a great challenge to the\nstock forecasting models. Meanwhile, stock data are typical\nstreaming data: new stock data are generated as stock trading\nis conducted, resulting in an ever-growing dataset. Periodical\nmodel adaptation based on the latest datasets could prepare\n\u2217Corresponding Authorthe forecaster for future tasks and alleviate the model aging\nissue [Liet al. , 2022; Zhao et al. , 2023 ]. Up to now, there are\ntwo commonly used paradigms of model adaptation: Rolling\nRetraining (RR) [Liet al. , 2022 ]and Incremental Learning\n(IL)[Zhao et al. , 2023 ].\nRR retrains the model periodically, where a model is re-\ntrained with all the data in hand. In this way, RR could retain\nrecurring patterns within the historical data [Su\u00b4arez-Cetrulo\net al. , 2023 ]. The RR method focusing on predictable con-\ncept drift has achieved competitive performance in forecast-\ning stock price trends [Liet al. , 2022 ], which empirically in-\ndicates the existence of recurring patterns in the stock data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3009, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4de40ce2-9fe8-44f8-9f66-55c0452e7f07": {"__data__": {"id_": "4de40ce2-9fe8-44f8-9f66-55c0452e7f07", "embedding": null, "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c26d813-bbc5-4e75-ba6b-c5c360a91cc7", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "f15ed8dc322116b9cbb511e3eb740b742035169a3070599d42db1079757666fd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "608317b7-9505-4d1b-9167-5975acf1e1be", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "04287b619b6ea7928c20076ceb8ad8dcf31987396e75d3f84cec5ec71e076b93", "class_name": "RelatedNodeInfo"}}, "text": ", 2022; Zhao et al. , 2023 ]. Up to now, there are\ntwo commonly used paradigms of model adaptation: Rolling\nRetraining (RR) [Liet al. , 2022 ]and Incremental Learning\n(IL)[Zhao et al. , 2023 ].\nRR retrains the model periodically, where a model is re-\ntrained with all the data in hand. In this way, RR could retain\nrecurring patterns within the historical data [Su\u00b4arez-Cetrulo\net al. , 2023 ]. The RR method focusing on predictable con-\ncept drift has achieved competitive performance in forecast-\ning stock price trends [Liet al. , 2022 ], which empirically in-\ndicates the existence of recurring patterns in the stock data.\nHowever, the latest samples are reserved for the validation set\nin RR, which limits the model\u2019s access to emerging patterns\nwithin the latest data. Meanwhile, it is straightforward to find\nthat RR will become increasingly computation-consuming as\nthe size of the dataset grows.\nIn contrast with RR, IL fine-tunes (adapts) the forecasting\nmodel with the latest data. The existing IL method [Zhao et\nal., 2023 ]can be viewed as a combination of meta-learning\n[Finn et al. , 2017 ]and online learning [Finn et al. , 2019;\nYang et al. , 2021 ], where data is organized into meta-learning\ntasks. Compared with RR, IL efficiently adapts the model\nwith a small number of gradient steps using incremental data.\nThe performance of IL methods is competitive, which indi-\ncates the significance of emerging patterns within the latest\ndata [Gama et al. , 2014b; Zhao et al. , 2020 ]. However, the\nabove model adaptation procedure disregards the historical\ndata. As a domain-incremental problem [van de Ven et al. ,\n2022 ], stock trend forecasting still suffers from catastrophic\nforgetting [Kirkpatrick et al. , 2017 ]due to the existence of re-\ncurring patterns. The exclusion of historical data could there-\nfore limit the performance of existing IL methods.\nIn short, the existing methods either fail to explicitly retrain\nthe forecasting model with emerging patterns in the latest data\nor disregard the recurring patterns within historical data. To\nthis end, we propose meta-learning with dynamic adaptation\n(MetaDA) for incremental learning of stock trends, which\nperforms dynamic model adaptation considering both the re-\ncurring and emerging patterns. The adaptation efficiency of\nthe proposed method is comparable to that of IL methods, as\nonly the informative historical data is included in model adap-\ntation. MetaDA organizes the data generated between two\nmodel adaptations into a set, and the sets are further trans-arXiv:2401.03865v3  [cs.CE]  17 Jan 2024", "mimetype": "text/plain", "start_char_idx": 2383, "end_char_idx": 4967, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "13fe6094-04fe-4e3f-90d4-e216f709551b": {"__data__": {"id_": "13fe6094-04fe-4e3f-90d4-e216f709551b", "embedding": null, "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "05a6c5c87f7dfe3ddc2f7cc4045a7e294efff4e0f048f7fd34122a7c7019e996", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea", "node_type": "1", "metadata": {}, "hash": "7511e45098588f65a5e317291ffb9435e30d671628350ea97b80d527a24eb678", "class_name": "RelatedNodeInfo"}}, "text": "formed into meta-learning tasks. The target of model adap-\ntation is to boost the performance on the upcoming data. We\nintroduce a task inference network to estimate the patterns\nof upcoming stock data, and identify the historical data con-\ntaining recurring patterns to complement the latest training\ndata. To transform the sets of data into learnable pattern fea-\ntures, we also propose a task embedding method that extracts\ntask-level representations from individual stock data. Dur-\ning model adaptation, a task-level feature is derived from a\nlookback window and then processed by the task inference\nnetwork for the estimation of future patterns. A historical\ntask that has the most similar pattern to the estimated pat-\ntern will be selected. The selected historical data will be used\nfor model adaptation, along with the latest arriving training\nset. The proposed method could therefore exploit the benefi-\ncial patterns within both the latest data and the historical data.\nExperiments on the real-world stock datasets indicate that the\nproposed method has achieved state-of-the-art performance\ncompared with existing IL and RR methods. The highlights\nof this paper are listed as follows.\n\u2022 As far as we know, MetaDA is the first method to incorpo-\nrate both emerging and historical data into the incremental\nlearning of stock trends.\n\u2022 We propose a task inference module for the selection of in-\nformative historical data, which predicts the overall pattern\nof the subsequent data.\n\u2022 The proposed method is evaluated on real-world datasets,\nand achieves competitive performance compared with the\nstate-of-the-art methods.\n2 Related Work\nConcept Drifts in Stock Data. Financial time series includ-\ning stock data are inherently un-stationary, as the distribution\nof financial data changes over time [\u02c7Zliobait \u02d9eet al. , 2016;\nGibbs and Candes, 2021 ]. Such changes in the relation be-\ntween the input features and target variable are usually known\nas concept drift [Gama et al. , 2014a ]or distribution shift\n[Fang et al. , 2020 ], which can be formally defined as follows.\n\u2203X:Pt1(X, y)\u0338=Pt2(X, y), (1)\nwhere Pt1(X, y)stands for the joint distribution of input X\nand target y, at time t1. The concept drifts of stock data\nhave been visualized via t-SNE [van der Maaten and Hin-\nton, 2008 ], and indicated in Figure 1. One of the commonly\nused assumptions in the concept drift community is that the\nconcept drift is unpredictable (random). Studies following\nthe above unpredictable assumption rely on the latest data for\nmodel adaptation [Luet al. , 2019 ]. In stock trend forecast-\ning, an incremental learning method that fine-tunes the model\nusing the latest data exclusively has achieved state-of-the-art\nresults [Zhao et al. , 2023 ]. However, the empirical results of\nrecent studies [Liet al. , 2022 ]indicate that predictable (or\nrecurring) concept drifts exist in stock data. It seems that the\npredictable and unpredictable concept drifts exist in the stock\ntime series simultaneously.\nStock Trend Forecasting Against Concept Drift.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3047, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea": {"__data__": {"id_": "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea", "embedding": null, "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "05a6c5c87f7dfe3ddc2f7cc4045a7e294efff4e0f048f7fd34122a7c7019e996", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13fe6094-04fe-4e3f-90d4-e216f709551b", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "9c19e15b48bfb98f4a1b7acc6f5204d970aff6ef4ee67722c9c644763498bdfc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a4e6c4ca-d583-4241-b718-fbe6e47507c4", "node_type": "1", "metadata": {}, "hash": "1c0f40a4717554b9de663e6f17197182d9b2ae3efbbf9fafcfdc0a25b01b0199", "class_name": "RelatedNodeInfo"}}, "text": "One of the commonly\nused assumptions in the concept drift community is that the\nconcept drift is unpredictable (random). Studies following\nthe above unpredictable assumption rely on the latest data for\nmodel adaptation [Luet al. , 2019 ]. In stock trend forecast-\ning, an incremental learning method that fine-tunes the model\nusing the latest data exclusively has achieved state-of-the-art\nresults [Zhao et al. , 2023 ]. However, the empirical results of\nrecent studies [Liet al. , 2022 ]indicate that predictable (or\nrecurring) concept drifts exist in stock data. It seems that the\npredictable and unpredictable concept drifts exist in the stock\ntime series simultaneously.\nStock Trend Forecasting Against Concept Drift. Up to\nnow, there are only limited studies focused on handling the\nconcept drifts of stock data. DoubleAdapt [Zhao et al. , 2023 ]\n\u2026\u2026\n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc52\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56+1 \n \n\ud835\udc9f\ud835\udc61\ud835\udc52\ud835\udc56+1 \n \u2026\u2026\n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56+2 \n \n\ud835\udc9f\ud835\udc61\ud835\udc52\ud835\udc56+2 \n \n\ud835\udcaf\ud835\udc56+2 \n \n\ud835\udcaf\ud835\udc56+1 \n \n\ud835\udcaf\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56+1 \n \n\u210b\ud835\udc56 \n \n\u210b\ud835\udc56+1 \n \n\u210b\ud835\udc56+2 \n Adaptation\n iAdaptation \ni+1Adaptation \ni+2\ntimeStock data\u2026\u2026\u2026\u2026\n\ud835\udc47\ud835\udc56 \n \n\ud835\udc47\ud835\udc56+1 \n \n\ud835\udc47\ud835\udc56+2 \n \n\u2026\u2026\n \u2026\u2026Figure 1: The incremental learning of stock trends, where the fore-\ncasting model is periodically updated via model adaptation. In the\nith model adaptation, the latest labeled data (training set) Di\ntr, the\nupcoming data (testing set) Di\nte, and the historical data Hiform the\nith learning task Ti. We aim to improve the overall performance on\ntesting sets across future tasks. The stock data are also visualized\nvia t-SNE and the results are presented at the bottom of the figure.\nexplores both the data adaptation and model adaptation for\nthe incremental learning of stock data, which transforms in-\ncremental tasks into a bi-level optimization problem in the\nparadigm of meta-learning. But DoubleAdapt fails to han-\ndle the predictable concept drifts, as it adapts the model only\nwith the latest data. DDG-DA [Liet al. , 2022 ]focuses on\npredictable concept drifts. DDG-DA estimates the data distri-\nbution of the next time step and then generates training sam-\nples based on historical data. As an RR method, DDG-DA\nutilizes the recent data as the validation set and fails to up-\ndate the forecasting model with the latest data.", "mimetype": "text/plain", "start_char_idx": 2326, "end_char_idx": 4531, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a4e6c4ca-d583-4241-b718-fbe6e47507c4": {"__data__": {"id_": "a4e6c4ca-d583-4241-b718-fbe6e47507c4", "embedding": null, "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "05a6c5c87f7dfe3ddc2f7cc4045a7e294efff4e0f048f7fd34122a7c7019e996", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "5e817a50dfb99383eed447b2a357be53ad9ce5a5ee7b1a3b14473e9791853638", "class_name": "RelatedNodeInfo"}}, "text": "The stock data are also visualized\nvia t-SNE and the results are presented at the bottom of the figure.\nexplores both the data adaptation and model adaptation for\nthe incremental learning of stock data, which transforms in-\ncremental tasks into a bi-level optimization problem in the\nparadigm of meta-learning. But DoubleAdapt fails to han-\ndle the predictable concept drifts, as it adapts the model only\nwith the latest data. DDG-DA [Liet al. , 2022 ]focuses on\npredictable concept drifts. DDG-DA estimates the data distri-\nbution of the next time step and then generates training sam-\nples based on historical data. As an RR method, DDG-DA\nutilizes the recent data as the validation set and fails to up-\ndate the forecasting model with the latest data. To the best\nof our knowledge, the previous studies have seldom incorpo-\nrated both the latest and historical data to handle predictable\nand unpredictable concept drifts simultaneously.\n3 Preliminaries\nStock Price Trend Forecasting. The price trend of stock iat\ntimetis defined as the ratio of price change to the stock price\nat time t[Xuet al. , 2021; Zhao et al. , 2023 ].\nrt\ni=pricet+1\ni\u2212pricet\ni\npricet\ni, (2)\nwhere pricet\niis the stock price at time tandrt\niis the price\ntrend. It should be noted that pricet\nicould be the closing\nprice, opening price, and volume-weighted price.\nDenoting the feature (maybe factors) of stock iat time tas\nxt\ni\u2208R1\u00d7d, stock trend forecasters aim at predicting the price\ntrend rt\nibased on xt\ni. In practice, xt\nicould involve a collection\nof indicators in the past few days, like opening price, closing\nprice, and trading volume. Supposing there are nobserved\nstocks, the features of stocks form a data matrix Xt\u2208Rn\u00d7d\nat time t, while the stock trends at time tcan be summarized\nin a target vector \u0393t\u2208Rn\u00d71. Stock forecasters learn the\nhistorical data {(Xi,\u0393i)}t\ni=1, and predict future stock trends\n{\u0393i}t+\u03c4\ni=t+1with upcoming stock features {Xi}t+\u03c4\ni=t+1.\nIncremental Learning of Stock Trends. As shown in Fig-\nure 1, the stock data is divided into segments based on model\nadaptation intervals, forming a sequence of meta-learning\ntasks. In this paper, a meta-learning task consists of the\ntraining set, the testing set, and the historical data. Let", "mimetype": "text/plain", "start_char_idx": 3777, "end_char_idx": 6017, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "875dd254-e4e8-4016-9f29-66ab4503d607": {"__data__": {"id_": "875dd254-e4e8-4016-9f29-66ab4503d607", "embedding": null, "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "92598070c895936b280ccf3a2a1a4db6fad7cb00b1035e51cf250141749e45a9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c9e9911f-8d4a-4ab1-bfe7-7444b430870d", "node_type": "1", "metadata": {}, "hash": "2d2a5a148e670c6279734f98367bfa813ad96513ad1e8bf66ab11f1b20b6251b", "class_name": "RelatedNodeInfo"}}, "text": "Ti={Di\ntr,Di\nte,Hi}denote the ith learning task. Di\ntrand\nDi\nteare the training and testing sets respectively, while Hi\nstands for the historical data. The aim of ith model adapta-\ntion is to boost the prediction performance on Di\ntebased on\nDi\ntrandHi. For the ith model adaptation, Di\ntrconsists of the\nstock data generated between the i\u22121th and the ith model\nadaptation, while testing set Di\ntecontains the stock features\ngenerated between the ith and i+1th model adaptation. As-\nsuming that the date of ith model adaptation is Ti, the testing\nset can be denoted as Di\nte={Xj}Ti+1\u22121\nj=Ti. After collecting\nthe true labels (price trends) of Di\nte,Di\nteand the correspond-\ning labels serve as the training set of i+ 1 th task, namely\nDi+1\ntr={(Xj,\u0393j)}Ti+1\u22121\nj=Ti. The training set of the former\ntask will be collected into historical data Hi+1={Dj\ntr}i\nj=1.\nProblem Formulation. Considering an adaptation interval of\nTada=Ti+1\u2013Ti, the stock trend forecasting is divided into a\nsequence of model adaptation tasks T={T1,T2, ...,Ti, ...}\nwithTi={Di\ntr,Di\nte,Hi}. Given a forecasting model\nF(\u00b7,\u0398)with parameter \u0398,F(\u00b7,\u0398)is periodically fine-tuned\nfollowing the model adaptation process. In the ith task, the\nforecasting model F(\u00b7,\u0398)is adjusted with {Di\ntr,Hi}, then\ninferences the price trends of upcoming data Di\nte, and finally\nlearns the latest data after the arrival of true labels. We aim\nto achieve the highest forecasting performance across all the\nmodel adaptation tasks.\nAs both the predictable and un-predictable concept drifts\nexist in stock trend forecasting, updating the model with the\nhistorical ( H) or latest ( Dtr) data exclusively might lead to\ndomain gap between the adaptation data and the upcoming\ndata. Accordingly, model adaptation considering the infor-\nmative information within both HandDtris likely to boost\nthe forecasting performance.\n4 MetaDA\nThe proposed method follows a training-adapting procedure:\nMetaDA first learns the labeled data in hand and then dy-\nnamically adapts the forecasting model F(\u00b7,\u0398)for the up-\ncoming concept drifts. Given the adaptation interval Tada,\nboth the training and adapting data are organized into a list of\ntasksT. The forecasting model F(\u00b7,\u0398)first iteratively learns\nthe training tasks which derives the initial parameter \u03980. A\ntask inference module is established based on F(\u00b7,\u03980). Dur-\ning the dynamic model adaptation, the task inference mod-\nule identifies historical data that might contain recurring pat-\nterns according to the current input. The forecasting model is\nthen adapted based on the identified and the latest data. Be-\nfore starting the next model adaptation, the forecasting model\nlearns the latest labeled data using a single gradient step.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2721, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c9e9911f-8d4a-4ab1-bfe7-7444b430870d": {"__data__": {"id_": "c9e9911f-8d4a-4ab1-bfe7-7444b430870d", "embedding": null, "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "92598070c895936b280ccf3a2a1a4db6fad7cb00b1035e51cf250141749e45a9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "875dd254-e4e8-4016-9f29-66ab4503d607", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "c225cb3cc23b70664fe8987662b257b203615c552e79166a1c4b16d6e1bda62a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b67487c5-eaa4-4138-a10a-fadfe062d03a", "node_type": "1", "metadata": {}, "hash": "c0c9141cdf1e6e1222bf1a93fe23a0620790d415efaa6bbcb213aef86761b2cc", "class_name": "RelatedNodeInfo"}}, "text": "4 MetaDA\nThe proposed method follows a training-adapting procedure:\nMetaDA first learns the labeled data in hand and then dy-\nnamically adapts the forecasting model F(\u00b7,\u0398)for the up-\ncoming concept drifts. Given the adaptation interval Tada,\nboth the training and adapting data are organized into a list of\ntasksT. The forecasting model F(\u00b7,\u0398)first iteratively learns\nthe training tasks which derives the initial parameter \u03980. A\ntask inference module is established based on F(\u00b7,\u03980). Dur-\ning the dynamic model adaptation, the task inference mod-\nule identifies historical data that might contain recurring pat-\nterns according to the current input. The forecasting model is\nthen adapted based on the identified and the latest data. Be-\nfore starting the next model adaptation, the forecasting model\nlearns the latest labeled data using a single gradient step.\nBoth the training and adapting processes are based on\nmodel adaptation , which can be viewed as the atomic opera-\ntion of the above procedure. The working pipeline of a single\nmodel adaptation is presented in Figure 2. The following sub-\nsections will introduce the task inference module (4.1), meta-\nlearning-based IL (4.2), and the details of training-adapting\nprocedure (4.3).\n\u210b\ud835\udc56 \n Task Inference Network\n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56-2 \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56-1 \n ...\nTask Embedding\n...\n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc56\u22122 \n \n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc56\u22121 \n \n\u2133\ud835\udc56 \n \nTask Embedding Sequence\n\u2130\ud835\udc56 \n \nPredicted Embedding\n\ud835\udc38\ud835\udc5d \n \n\u210e\u2217 \n \nTask Inference Module Meta -Learning -based IL\n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc56 \n \n\ud835\udc9f\ud835\udc61\ud835\udc52\ud835\udc56 \n Forecasting Model\n\ud835\udc9f\ud835\udc61\ud835\udc5f\u210e\u2217 \n Adaptation\nAdapted Forecasting \nModel\n\ud835\udc39(\u2219,\ud835\udee9\ud835\udc56\u22121) \n \n\u0393 \ud835\udc61\ud835\udc52\ud835\udc56 \n \n\ud835\udc39(\u2219,\ud835\udee9\u2032) \n \nUpdated Forecasting \nModel\n\u0393\ud835\udc61\ud835\udc52\ud835\udc56 \n Gradient descent\n\ud835\udc39(\u2219,\ud835\udee9\ud835\udc56) \n \n...\n{\ud835\udc4b\ud835\udc58\u2208\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc57} \n \n\ud835\udc9f\ud835\udc61\ud835\udc5f1 \n ...\n\ud835\udc9f\ud835\udc61\ud835\udc5f\ud835\udc57 \n \n\ud835\udc38\ud835\udc61\ud835\udc5f1 \n \n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc57 \n \n...\n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc57 \n \n\u2130\ud835\udc56 \n \n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc56 \n \n\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc56\u2212\ud835\udc3f+1 \n \n......Figure 2: The overview of MetaDA\u2019s working pipeline in the ith\nmodel adaptation. A set of historical data Dh\u2217\ntris first selected by the\ntask inference module.", "mimetype": "text/plain", "start_char_idx": 1861, "end_char_idx": 3736, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b67487c5-eaa4-4138-a10a-fadfe062d03a": {"__data__": {"id_": "b67487c5-eaa4-4138-a10a-fadfe062d03a", "embedding": null, "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "92598070c895936b280ccf3a2a1a4db6fad7cb00b1035e51cf250141749e45a9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c9e9911f-8d4a-4ab1-bfe7-7444b430870d", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "86fc9a3ab3d8483bd64bb60fb79ecd256ef9f055999bc9bada459791dbd4993b", "class_name": "RelatedNodeInfo"}}, "text": "A set of historical data Dh\u2217\ntris first selected by the\ntask inference module. Model adaptation is then conducted based on\nDh\u2217\ntrand the latest labeled data Di\ntr. The forecasting model subse-\nquently predicts stock trend on Di\nte, and learns the data after the\narrival of labels \u0393i\nte.\n4.1 Task Inference Module\nAs shown in Figure 2, the task inference module can be fur-\nther divided into two key components: task embedding and\ntask inference network. For convenience, the two major com-\nponents are introduced in the scenario of ith model adapta-\ntion. Task inference module aims to select a proper task Dh\u2217\ntr\nfrom historical data Hi, preparing the model F(\u00b7; \u0398) for the\npredictive concept drifts.\nTask Embedding. The objective of the task embedding is\nto project the training sets {Dj\ntr}i\nj=1into learnable vectors\n{Ej\ntr}i\nj=1, namely the task-level embeddings. The corre-\nsponding stock features {X|X\u2208 Dj\ntr}i\nj=1are first encoded\ninto hidden features, which are denoted as sample-level em-\nbeddings. The sample-level embeddings are extracted as:\nek= Encoder( Xk), (3)\nwhere ek={si\u2208R1\u00d7q}nk\ni=1denotes the sample-level em-\nbeddings corresponding to Xkin the training sets, and nk\nis the number of samples at date k. It should be noted that\nthe number of samples (stock data) at each date is variable\ndue to stock suspensions and other unforeseen circumstances,\nnamely \u2200k, l:nk\u0338\u2261nl.\nAfter encoding the stock data, the ensuing problem is how\nto extract effective task-level embedding Ej\ntrfrom sample-\nlevel embeddings. As each ek={si}nk\ni=1contains an uncer-\ntain number of sample-level embeddings, the extractor should\nbe independent of sample numbers. In this paper, we in-\ntroduce an attention-based aggregating layer for task embed-\nding, where sample-level embeddings are aggregated with a\nweighted average process.\nEj\ntr=Tj\u22121X\nk=Tj\u22121nkX\ni=1\u03b1i(siV1+\u03f5), (4)\nwhere V1\u2208Rq\u00d7qand\u03f5\u2208R1\u00d7qare the parameters of lin-\near projection. The aggregating weights \u03b1are learned by the", "mimetype": "text/plain", "start_char_idx": 3658, "end_char_idx": 5634, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73a6065a-ef36-4ec4-99e2-29ececf78f3b": {"__data__": {"id_": "73a6065a-ef36-4ec4-99e2-29ececf78f3b", "embedding": null, "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bc66c833-82ec-4329-a18b-1fdf2186f019", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "77d3aef6a1bd192c0b98aac700da571a6449ab6daafd577b6ea1e0f386d7c6ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b2bd1f08-2841-4294-9fdb-e6d35c002ed5", "node_type": "1", "metadata": {}, "hash": "088798ae197e8b51b76b4161cb47bbcef391fe4334fe1d6f774dcf5f4d299850", "class_name": "RelatedNodeInfo"}}, "text": "embedding model and processed with softmax to make it in-\nvariant to the sample numbers of tasks:\n\u03b1i=exp{tanh(siV2)v3}\nPTj\u22121\nk=Tj\u22121Pnk\ni=1exp{tanh(siV2)v3}. (5)\nIn Eq. 5, V2\u2208Rq\u00d7pandv3\u2208Rp\u00d71. The above equation\ncorresponds to a version of attention mechanism [Linet al. ,\n2017 ], which could discover similarities among the sample-\nlevel embeddings. The learnable parameters of task embed-\nding are represented by \u03a01={V1,V2,v3}\nTask Inference Network. The previous study indicates the\nexistence of predictable concept drift in the stock data. We\ntherefore assume that the patterns of tasks are partially pre-\ndictable: the pattern of upcoming task can be inferred from\na sequence of historical tasks. The aforementioned task em-\nbeddings are first organized into embedding sequences. In the\nith model adaptation, the task embedding sequence is formu-\nlated as follows.\nEi={Ei\u2212L+1\ntr ,\u00b7\u00b7\u00b7,Ei\u22121\ntr,Ei\ntr}, (6)\nwhere Eiis the task embedding sequence for predicting the\nupcoming task, and Lis the size of lookback window. Mean-\nwhile, the embeddings of all the previous tasks are collected\ninto a memory list, which is denoted as follows\nMi={E1\ntr,\u00b7\u00b7\u00b7,Ei\u22122\ntr,Ei\u22121\ntr}, (7)\nwhere Midenotes the memory list of ith model adaptation.\nTo predict the embedding of the upcoming task, the embed-\nding sequence is fed into the task inference network, which\nderives an estimated embedding Ei\np.\nEi\np=Ftin(Ei,\u03a02) (8)\nwhere Ftin(\u00b7,\u03a02)denotes the task inference network with\nmodel parameter \u03a02. The predicted embedding is utilized\nto select a historical task that contains the task-level pattern\nmost similar to the predicted pattern. The index of selected\nhistorical task is denoted as h\u2217and determined as:\nmin\nh\u2217\u2225Eh\u2217\ntr\u2212Ei\np\u22252\nF, s.t. Eh\u2217\ntr\u2208 Mi. (9)\nThe reliability of h\u2217is further estimated and the inference\nresults with low reliability will be ignored. Eh\u2217\ntris included\nfor model adaptation only if the similarity between Ei\npand\nEi\ntris in\u03bath percentile.\n4.2 Meta-Learning-based IL\nIn this paper, the incremental learning of stock trends is\norganized in the paradigm of meta-learning [Zhao et al. ,\n2023 ]. Meta-Learning-based IL contains a forecasting model\nF(\u00b7; \u0398) which incorporates a data adapter fda(\u00b7;\u03b8da), a la-\nbel adapter fla(\u00b7;\u03b8la)and a forecaster f(\u00b7;\u03b8f).\u03b8daand\u03b8la\nare the parameters of the data adapter and label adapter corre-\nspondingly, while \u03b8fis the parameter of the forecaster.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2385, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b2bd1f08-2841-4294-9fdb-e6d35c002ed5": {"__data__": {"id_": "b2bd1f08-2841-4294-9fdb-e6d35c002ed5", "embedding": null, "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bc66c833-82ec-4329-a18b-1fdf2186f019", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "77d3aef6a1bd192c0b98aac700da571a6449ab6daafd577b6ea1e0f386d7c6ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "73a6065a-ef36-4ec4-99e2-29ececf78f3b", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "5a1c197a0df3e5c9fc1d92615bf6a11b0b220000bec82d87d61865906eff11ec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3540039d-3615-4adc-a89c-9396c99976cf", "node_type": "1", "metadata": {}, "hash": "7b1dd87c6dbafb92a3cc1d1ac7d70ee099e553562995022c26d344ca0866b1e2", "class_name": "RelatedNodeInfo"}}, "text": "Eh\u2217\ntr\u2208 Mi. (9)\nThe reliability of h\u2217is further estimated and the inference\nresults with low reliability will be ignored. Eh\u2217\ntris included\nfor model adaptation only if the similarity between Ei\npand\nEi\ntris in\u03bath percentile.\n4.2 Meta-Learning-based IL\nIn this paper, the incremental learning of stock trends is\norganized in the paradigm of meta-learning [Zhao et al. ,\n2023 ]. Meta-Learning-based IL contains a forecasting model\nF(\u00b7; \u0398) which incorporates a data adapter fda(\u00b7;\u03b8da), a la-\nbel adapter fla(\u00b7;\u03b8la)and a forecaster f(\u00b7;\u03b8f).\u03b8daand\u03b8la\nare the parameters of the data adapter and label adapter corre-\nspondingly, while \u03b8fis the parameter of the forecaster. \u0398is\nthe collection of above parameters with \u0398 ={\u03b8da, \u03b8la, \u03b8f}.\nIn the ith model adaptation, the forecaster is first up-\ndated with Di\nada. IfDh\u2217\ntris included for adaptation, Di\nada=\n{(X,\u0393)\u2208 Di\ntr\u222a Dh\u2217\ntr}. Otherwise, Di\nada=Di\ntr. The initialparameters of forecasting model in the ith model adaptation\nare updated parameters of i\u22121th model adaptation, denoted\nas\u0398i\u22121={\u03b8i\u22121\nda, \u03b8i\u22121\nla, \u03b8i\u22121\nf}. The stock data are first trans-\nformed with the data adapter and label adapter for the allevi-\nation of concept drift. Suppose there are data X\u2208Rn\u00d7dand\ncorresponding labels \u0393\u2208Rn\u00d71,\n\u02dcX(\u03b8da)=fda(X;\u03b8da) :=X+NX\ni\u03b2i(XW i+bi),\n\u02dc\u0393(\u03b8la)=fla(\u0393;\u03b8la) :=NX\ni\u03b2i(\u0393\u00b7hi+zi),(10)\nwhere Wi\u2208Rd\u00d7dandbiare the parameters of ith linear\nprojection for data adaptation. hi\u2208Randziare the parame-\nters of ith linear projection for label adapter, while Nis the\nnumber of projection. \u03b2i\u2208Rn\u00d7nis the weight matrix of ith\nprojection.\n\u03b2i=diag(\u03b2(i,1), \u03b2(i,2),\u00b7\u00b7\u00b7, \u03b2(i,n)), (11)\nwhere \u03b2(i,j)represents the weight of ith projection with re-\nspect to the jth sample:\n\u03b2(i,j)=exp(cos <xj,pi> /\u03c92)PN\ni=1exp(cos <xj,pi> /\u03c92), (12)\nwhere cos<\u00b7,\u00b7>denotes the cosine similarity, and piis a\nlearnable parameter corresponding to ith projection. Mean-\nwhile, xjdenotes the jth sample within X.\u03c9is the softmax\ntemperature. In general, we have \u03b8da={\u0393i,bi,pi}N\ni=1and\n\u03b8la={hj, zj,pj}N\nj=1.", "mimetype": "text/plain", "start_char_idx": 1719, "end_char_idx": 3722, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3540039d-3615-4adc-a89c-9396c99976cf": {"__data__": {"id_": "3540039d-3615-4adc-a89c-9396c99976cf", "embedding": null, "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bc66c833-82ec-4329-a18b-1fdf2186f019", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "77d3aef6a1bd192c0b98aac700da571a6449ab6daafd577b6ea1e0f386d7c6ab", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b2bd1f08-2841-4294-9fdb-e6d35c002ed5", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "cbd22d08480cddffe6c3b0de44596559f67e81dc1159a155d8ff790e0b3f65b0", "class_name": "RelatedNodeInfo"}}, "text": "\u03b2i\u2208Rn\u00d7nis the weight matrix of ith\nprojection.\n\u03b2i=diag(\u03b2(i,1), \u03b2(i,2),\u00b7\u00b7\u00b7, \u03b2(i,n)), (11)\nwhere \u03b2(i,j)represents the weight of ith projection with re-\nspect to the jth sample:\n\u03b2(i,j)=exp(cos <xj,pi> /\u03c92)PN\ni=1exp(cos <xj,pi> /\u03c92), (12)\nwhere cos<\u00b7,\u00b7>denotes the cosine similarity, and piis a\nlearnable parameter corresponding to ith projection. Mean-\nwhile, xjdenotes the jth sample within X.\u03c9is the softmax\ntemperature. In general, we have \u03b8da={\u0393i,bi,pi}N\ni=1and\n\u03b8la={hj, zj,pj}N\nj=1.\nThe parameter of forecaster \u03b8i\u22121\nfis then updated with a sin-\ngle gradient step using \u02dcDi\nada={(\u02dcX(\u03b8i\u22121\nda),\u02dc\u0393(\u03b8i\u22121\nla))|(X,\u0393)\u2208\nDi\nada}. In this paper, the meta-learning process has optimized\n\u0398for quick adaptation to the upcoming tasks. A single gra-\ndient step is therefore enough to boost the performance.\n\u03b8\u2032\nf\u2190\u03b8i\u22121\nf\u2212\u03b7\u2207\u03b8fLada(\u02dcDi\nada;\u03b8i\u22121\nf), (13)\nwhere \u03b7is the learning rate of forecaster, and Ladais the loss\nfunction for model adaptation. The parameters of adapted\nforecasting model are denoted as \u0398\u2032={\u03b8i\u22121\nda, \u03b8i\u22121\nla, \u03b8\u2032\nf},\nwhich are utilized for subsequent prediction on Di\nte. Given\nX\u2208 Di\nte, the stock trend is predicted as following:\n\u02c6\u0393=F(X; \u0398\u2032) =f\u22121\nla(f(\u02dcX(\u03b8i\u22121\nda);\u03b8\u2032\nf);\u03b8i\u22121\nla), (14)\nwhere f\u22121\nla=PN\ni\u03b2iBi(\u0393\u2212zi)/hiis the inverse of label\nadapter that projects the results back into the original space.\nAfter the arrival of true labels, Di\nteand its corresponding\nlabels form Di+1\ntr. An online gradient step is carried out to\nupdate the forecasting model, deriving the initial parameters\nof the i+ 1th model adaptation (namely \u0398i).\n\u03b8i\nf\u2190\u03b8i\u22121\nf\u2212\u03b7\u2207\u03b8fLogd(Di+1\ntr; \u0398\u2032),\n\u03b8i\nda\u2190\u03b8i\u22121\nda\u2212\u03b7a\u2207\u03b8daLogd(Di+1\ntr; \u0398\u2032),\n\u03b8i\nla\u2190\u03b8i\u22121\nla\u2212\u03b7a\u2207\u03b8laLogd(Di+1\ntr; \u0398\u2032),(15)\nwhere Logdis the loss function for online gradient descent,\nand\u03b7ais the learning rate of adapters.", "mimetype": "text/plain", "start_char_idx": 3238, "end_char_idx": 4988, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b14d2b8a-abd4-4a58-8552-881abeffb17d": {"__data__": {"id_": "b14d2b8a-abd4-4a58-8552-881abeffb17d", "embedding": null, "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "363af885b93e0e28171d689c690c92e47c1a628e187739a6650bc2656debc003", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "18bbae4d-8841-4dd3-94ac-a902ec306596", "node_type": "1", "metadata": {}, "hash": "6daad6b00ecc94bb7bc11a959e22dbdb315558fbdcc0074505cf949ce9e31798", "class_name": "RelatedNodeInfo"}}, "text": "4.3 Training-Adapting Procedure\nIn this subsection, the detailed training-adapting procedure\nof MetaDA is presented, which could be divided into three\nstages: training of forecasting model, training of task infer-\nence module, and adaptation.\nTraining of Forecasting Model. In this stage, we aim to ob-\ntain the initial parameters \u03980that can efficiently adapt to the\nupcoming tasks. The training set and validation set are split\ninto tasks according to the adaptation interval Tada, deriving\na training sequence Ttrand a validation sequence Tval. Each\ntaskTjwithin TtrandTvalsatisfies Tj={Dj\ntr,Dj\nte,Hj},\nsame as the above sections. Within a training epoch, the fore-\ncasting model performs the model adaptation process on each\ntaskTj\u2208 Ttr. It should be noted that only the latest data are\nused for model adaptation in this stage, namely Di\nada=Di\ntr.\nFor the training of forecasting model, the loss function for\nmodel adaptation and online learning is defined as:\nLada(\u02dcD;\u03b8f) =Lmse(f(X;\u03b8f),\u0393|\u02dcD)\nLogd(D; \u0398) = Lmse(F(X; \u0398),\u0393|D) +Rla,(16)\nwhere Lmse(F(X; \u0398),\u0393|D)denotes the mean square error\nlossP\n(X,\u0393)\u2208D\u2225F(X; \u0398)\u2212\u0393\u22252\nF/ND, and NDis the num-\nber of samples within D.Rla=1\n2P\n\u0393\u2208D\u2225\u0393\u2212\u02dc\u0393\u22252\nF/NDis\na regularizer of label adaptation. In a single epoch, F(\u00b7; \u0398)\nlearns all the tasks within Ttrand the corresponding parame-\nter is saved as \u0398tmp. The forecasting model is then evaluated\nonTvalfollowing the same model adaptation process. Fi-\nnally, the saved parameter \u0398tmpis restored, and a new learn-\ning epoch on the Ttris started. The training stops when the\nperformance of F(\u00b7; \u0398) decreases on Tvalfor several contin-\nuous epochs, deriving the initial parameters \u03980.\nTraining of Task Inference Module. The task inference\nmodule is subsequently trained based on \u03980. We exploit the\nencoding part of f(\u00b7;\u03b80\nf), which denoted as fe(\u00b7;\u03b80\nf), for the\nsample-level encoding.\nek=fe(\u02dcXk\n(\u03b80\nda);\u03b80\nf). (17)\nThe parameters of the sample-level encoder remain un-\nchanged. The task embeddings are organized into aforemen-\ntioned task embedding sequences defined in Eq. 6. The learn-\nable parameters of the task inference module (namely \u03a01and\n\u03a02) are optimized collaboratively.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2160, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "18bbae4d-8841-4dd3-94ac-a902ec306596": {"__data__": {"id_": "18bbae4d-8841-4dd3-94ac-a902ec306596", "embedding": null, "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "363af885b93e0e28171d689c690c92e47c1a628e187739a6650bc2656debc003", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b14d2b8a-abd4-4a58-8552-881abeffb17d", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "ced0c20428629b7254a27bbbb9ceea350f1933ce901a6c1035873d8add40c57c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22d8f877-7329-4d6a-b2e3-1f52d57f8411", "node_type": "1", "metadata": {}, "hash": "ca9341e9bd35010fca98e64a6aac4fee7813bb283ce819e5d7d677f4e9168898", "class_name": "RelatedNodeInfo"}}, "text": "The training stops when the\nperformance of F(\u00b7; \u0398) decreases on Tvalfor several contin-\nuous epochs, deriving the initial parameters \u03980.\nTraining of Task Inference Module. The task inference\nmodule is subsequently trained based on \u03980. We exploit the\nencoding part of f(\u00b7;\u03b80\nf), which denoted as fe(\u00b7;\u03b80\nf), for the\nsample-level encoding.\nek=fe(\u02dcXk\n(\u03b80\nda);\u03b80\nf). (17)\nThe parameters of the sample-level encoder remain un-\nchanged. The task embeddings are organized into aforemen-\ntioned task embedding sequences defined in Eq. 6. The learn-\nable parameters of the task inference module (namely \u03a01and\n\u03a02) are optimized collaboratively. Given a task embedding\nsequence EiofTi, the task inference network Ftin(\u00b7; \u03a02)will\noutput a predicted embedding Ei\np. We hope the predicted em-\nbedding Ei\nphas a significant similarity to the embedding of\nupcoming data Di\nteand has less similarities to the other task\nembeddings. A triplet loss function is therefore introduced,\nwhich is defined as follows.\nLtri(Ep,Et,En) =\nmax(\u2225Ep\u2212Et\u22252\u2212 \u2225Ep\u2212En\u22252+\u03b3,0),(18)\nwhere Endenotes the negative embedding and Etis the tar-\nget embedding, namely the embedding of Di\nte.\u03b3is the mar-\ngin of triplet loss. The task embeddings of Ttrare corre-\nspondingly organized into triplets, from which we derive thetraining triplets Triptr.\nTriptr={tripi}Ntr\ni=L,\ntripi={(Ei\np,Ei+1\ntr,Ek\ntr)|Ek\ntr\u2208 Ei\nneg},\nEi\nneg={Ek\ntr|k\u0338=i, k\u0338=i+ 1}Ntr\nk=1,(19)\nwhere Ntris the number of tasks in the Ttr, andtripidenotes\nthe triplets corresponding to the ith task. Ei+1\ntris equal to Ei\nte\nand therefore used as the target embedding of Ei\np, while the\nrest embeddings except Ei\ntrserve as negative embeddings.\nWithin a single epoch, triplets of each task are learned with\na learning rate of \u03b7tand the learned parameters are saved as\n{\u03a0tmp\n1,\u03a0tmp\n2}. The task inference model is then evaluated on\nthe validation set based on {\u03a0tmp\n1,\u03a0tmp\n2}and\u03980. Different\nfrom the training of forecasting model, Dh\u2217\ntris introduced for\nmodel adaptation. When the evaluation performance on Tval\ndecreases for several continuous epochs, the training process\nof task inference module stops.\nAdapting. After the training stage, the forecasting model first\nperforms the model adaptation process on all the tasks within\nTvalin sequence. When forecasting the trends of streaming\nstock data, MetaDA conducts model adaptation periodically\nfollowing the process described in section 4.1 and 4.2.", "mimetype": "text/plain", "start_char_idx": 1526, "end_char_idx": 3944, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "22d8f877-7329-4d6a-b2e3-1f52d57f8411": {"__data__": {"id_": "22d8f877-7329-4d6a-b2e3-1f52d57f8411", "embedding": null, "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "363af885b93e0e28171d689c690c92e47c1a628e187739a6650bc2656debc003", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "18bbae4d-8841-4dd3-94ac-a902ec306596", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "27cfef25b745d8812a22456e98197a73677d998c7b9429730102e79064270986", "class_name": "RelatedNodeInfo"}}, "text": "Within a single epoch, triplets of each task are learned with\na learning rate of \u03b7tand the learned parameters are saved as\n{\u03a0tmp\n1,\u03a0tmp\n2}. The task inference model is then evaluated on\nthe validation set based on {\u03a0tmp\n1,\u03a0tmp\n2}and\u03980. Different\nfrom the training of forecasting model, Dh\u2217\ntris introduced for\nmodel adaptation. When the evaluation performance on Tval\ndecreases for several continuous epochs, the training process\nof task inference module stops.\nAdapting. After the training stage, the forecasting model first\nperforms the model adaptation process on all the tasks within\nTvalin sequence. When forecasting the trends of streaming\nstock data, MetaDA conducts model adaptation periodically\nfollowing the process described in section 4.1 and 4.2.\n5 Experiments\nIn this section, the proposed MetaDA is evaluated with sev-\neral experiments, aiming to answer the following research\nquestions. The implementation is publicly available1.\nQ1.How does MetaDA perform compared with state-of-the-\nart methods?\nQ2.Are the proposed components in MetaDA effective?\nQ3.Can MetaDA learn the incremental data efficiently?\n5.1 Experimental Settings\nDatasets. Two widely-used stock datasets are introduced\nfor evaluation, namely CSI-300 [Gao et al. , 2023 ]and CSI-\n500 [Xuet al. , 2021 ]. Both datasets are collected in the\nChinese A-share market and contain the stock data from\n01/01/2008 to 31/07/2020. CSI-300 consists of the 300\nlargest stocks, while CSI-500 consists of the 500 largest\nremaining stocks. The datasets are split into training sets\n(01/01/2008 to 31/12/2014), validation sets (01/01/2015 to\n31/12/2016), and testing sets (01/01/2017 to 31/07/2020).\nThe stock feature of Alpha360 in Qlib [Yang et al. , 2020 ]is\nutilized for stock forecasting. On each trading day, Alpha360\nrecords 6 indicators in the past 60 days, including opening\nprice, closing price, highest price, lowest price, trading vol-\nume, and volume-weighted average price.\nMetrics. Four widely used metrics are introduced for the\nevaluation of predicted stock trends, namely Information Co-\nefficient (IC), IC information ratio (ICIR), rank IC, and rank\nICIR. IC at date tis defined as the Pearson correlation be-\ntween the estimated labels and the raw labels. The average\nIC across all the testing dates is reported in this paper. ICIR\n1provided in Supplementary Material for anonymity", "mimetype": "text/plain", "start_char_idx": 3185, "end_char_idx": 5551, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49f5fdcc-f00d-48c1-bd72-3cd03cde09df": {"__data__": {"id_": "49f5fdcc-f00d-48c1-bd72-3cd03cde09df", "embedding": null, "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "8ee7631d95ac47b62fd80296a30d977e65935c9d184d2c7f00a68abe05fb0594", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "372afef2-81cd-4bbe-9605-25ab658832d7", "node_type": "1", "metadata": {}, "hash": "334423d7be7e4a4c613fe5466c2f44d3667c0fd2fa992fdba291a6f276a72175", "class_name": "RelatedNodeInfo"}}, "text": "Forecaster MethodCSI-300 CSI-500\nIC ICIR RIC RICIR eAR eARIR IC ICIR RIC RICIR eAR eARIR\nLSTMDDG-DA 0.0452 0.3610 0.0546 0.4460 0.1193 1.6619 0.0530 0.4832 0.0670 0.6610 0.1204 2.5623\nIL 0.0484 0.3476 0.0633 0.4663 0.1563 2.2458 0.0529 0.4518 0.0719 0.6790 0.1380 2.8764\nC-MAML 0.0473 0.3641 0.0587 0.4577 0.1449 2.0385 0.0473 0.4019 0.0647 0.6120 0.1021 2.1079\nMetaCoG 0.0348 0.2417 0.0497 0.3532 0.0891 0.0891 0.0523 0.4658 0.0662 0.6590 0.1192 2.6571\nDoubleAda 0.0520 0.3891 0.0651 0.4969 0.1577 0.1577 0.0554 0.4721 0.0737 0.7035 0.1422 2.9799\nMetaDA 0.0525 0.4010 0.0657 0.5179 0.1661 2.4854 0.0577 0.5165 0.0745 0.7418 0.1474 3.1736\nGRUDDG-DA 0.0532 0.4027 0.0604 0.4722 0.0961 1.3743 0.0508 0.4668 0.0640 0.6266 0.1078 2.4081\nIL 0.0536 0.3815 0.0664 0.4968 0.1641 2.3646 0.0554 0.4716 0.0730 0.6891 0.1372 2.8210\nC-MAML 0.0547 0.4135 0.0643 0.4940 0.1670 2.4145 0.0532 0.4497 0.0710 0.6725 0.1214 2.5133\nMetaCoG 0.0461 0.3365 0.0583 0.4430 0.1360 1.9555 0.0530 0.4883 0.0669 0.6777 0.1153 2.6131\nDoubleAda 0.0570 0.4186 0.0686 0.5198 0.1733 2.4994 0.0584 0.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1064, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "372afef2-81cd-4bbe-9605-25ab658832d7": {"__data__": {"id_": "372afef2-81cd-4bbe-9605-25ab658832d7", "embedding": null, "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "8ee7631d95ac47b62fd80296a30d977e65935c9d184d2c7f00a68abe05fb0594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "49f5fdcc-f00d-48c1-bd72-3cd03cde09df", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "55359dc4a4acc7995a3258903574342dfa8fbb9d409e71cefb477dbd5a654477", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba7d0edd-44ec-48b0-9ebe-61124b8c959e", "node_type": "1", "metadata": {}, "hash": "7627286744c7d8cdaed5b1a597c3bf4f386425a9b12566f965186a75fdd7d640", "class_name": "RelatedNodeInfo"}}, "text": "0554 0.4716 0.0730 0.6891 0.1372 2.8210\nC-MAML 0.0547 0.4135 0.0643 0.4940 0.1670 2.4145 0.0532 0.4497 0.0710 0.6725 0.1214 2.5133\nMetaCoG 0.0461 0.3365 0.0583 0.4430 0.1360 1.9555 0.0530 0.4883 0.0669 0.6777 0.1153 2.6131\nDoubleAda 0.0570 0.4186 0.0686 0.5198 0.1733 2.4994 0.0584 0.5070 0.0755 0.7331 0.1470 3.0941\nMetaDA 0.0584 0.4400 0.0683 0.5372 0.1792 2.7146 0.0606 0.5361 0.0757 0.7412 0.1506 3.1794\nTransformerDDG-DA 0.0161 0.1043 0.0353 0.2516 0.0301 0.4360 0.0119 0.0851 0.0372 0.3025 0.0244 0.4472\nIL 0.0333 0.2269 0.0489 0.3493 0.0970 1.3328 0.0395 0.3155 0.0614 0.5401 0.1000 1.8332\nC-MAML 0.0346 0.2422 0.0495 0.3637 0.0992 1.3547 0.0415 0.3217 0.0603 0.5279 0.0806 1.4656\nMetaCoG 0.0163 0.1015 0.0229 0.1390 0.0228 0.2473 0.0110 0.0888 0.0230 0.1909 0.0275 0.5949\nDoubleAda 0.0359 0.2437 0.0510 0.3660 0.1146 1.4721 0.0490 0.3853 0.0659 0.5664 0.0866 1.5697\nMetaDA 0.0430 0.3061 0.0555 0.4216 0.1270 1.9027 0.0552 0.4404 0.0652 0.5732 0.1031 1.8928\nTable 1: The overall performance comparison on the CSI-300 and CSI-500 datasets, where IC, ICIR, RIC, RICIR, eAR, and eARIR are\nutilized as metrics.", "mimetype": "text/plain", "start_char_idx": 780, "end_char_idx": 1893, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ba7d0edd-44ec-48b0-9ebe-61124b8c959e": {"__data__": {"id_": "ba7d0edd-44ec-48b0-9ebe-61124b8c959e", "embedding": null, "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "8ee7631d95ac47b62fd80296a30d977e65935c9d184d2c7f00a68abe05fb0594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "372afef2-81cd-4bbe-9605-25ab658832d7", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "e20ceaa11ce7993e26c8e216206e2ca0db2ed9a85e8ad934c5df21d6626a909a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f42ded87-0bdb-40b6-93f2-7c15c63752d8", "node_type": "1", "metadata": {}, "hash": "226f2ce50d3183097fdc392be9424b8bdee60daadbf19b1a4c83940e7d80b851", "class_name": "RelatedNodeInfo"}}, "text": "0888 0.0230 0.1909 0.0275 0.5949\nDoubleAda 0.0359 0.2437 0.0510 0.3660 0.1146 1.4721 0.0490 0.3853 0.0659 0.5664 0.0866 1.5697\nMetaDA 0.0430 0.3061 0.0555 0.4216 0.1270 1.9027 0.0552 0.4404 0.0652 0.5732 0.1031 1.8928\nTable 1: The overall performance comparison on the CSI-300 and CSI-500 datasets, where IC, ICIR, RIC, RICIR, eAR, and eARIR are\nutilized as metrics. The best results are highlighted in bold, and the second-best results are underlined.\nis defined as E(IC)/\u03c3(IC), where \u03c3(\u00b7)denotes standard de-\nviation. Rank IC (RIC) and rank ICIR (RICIR) are calculated\nin a similar way, where the ranks of labels are used. Port-\nfolio metrics are also included for evaluation, including the\nexcess annualized return (eAR) and the excess AR\u2019s infor-\nmation ratio (eARIR), where TopkDropout strategy [Yang et\nal., 2020 ]is utilized. Friedman test [Dem \u02c7sar, 2006 ]has been\nintroduced for quantitative analysis across the above datasets\nand metrics. For all the aforementioned metrics, higher val-\nues represent better performance.\nBaselines. Several state-of-the-art model-agnostic retraining\nmethods are introduced for comparison:\n\u2022DDG-DA [Liet al. , 2022 ]: This rolling retraining method\nre-weights the historical data according to the predicted\ndata distribution, and periodically retrains the forecasting\nmodel with the re-weighted data.\n\u2022IL[Zhao et al. , 2023 ]: IL, short for incremental learning,\nperiodically updates the model with the latest data using\nonline gradient descent.\n\u2022C-MAML [Caccia et al. , 2020 ]: Based on model-agnostic\nmeta-learning (MAML), this method first trains a general\nmodel across various training tasks, and performs model\nadaptation with the latest data periodically.\n\u2022MetaCoG [Heet al. , 2020 ]: Introducing a continuously up-\ndated per-parameter mask, this MAML-based method se-\nlects task-specific parameters according to the context.\n\u2022DoubleAda [Zhao et al. , 2023 ]: This MAML-based\nmethod performs additional data and label adaptations to\nalleviate the impact of concept drifts, which uses the latest\ndata exclusively for model adaptation.\n\u2022MetaDA : Following the paradigm of MAML, the proposed\nmethod performs model adaptation with both the latest data\nand the selected historical data.Implementation. The time interval Tadabetween two model\nadaptation is 15 trading days. Adam optimizer is utilized for\ntraining, where \u03b7=\u03b7t= 0.001and\u03b7a= 0.01.", "mimetype": "text/plain", "start_char_idx": 1527, "end_char_idx": 3913, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f42ded87-0bdb-40b6-93f2-7c15c63752d8": {"__data__": {"id_": "f42ded87-0bdb-40b6-93f2-7c15c63752d8", "embedding": null, "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "8ee7631d95ac47b62fd80296a30d977e65935c9d184d2c7f00a68abe05fb0594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ba7d0edd-44ec-48b0-9ebe-61124b8c959e", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "9f65aca09c4b8b476be1a5be4a201046acbabed4904ff0c065f9e1418643d762", "class_name": "RelatedNodeInfo"}}, "text": "\u2022MetaCoG [Heet al. , 2020 ]: Introducing a continuously up-\ndated per-parameter mask, this MAML-based method se-\nlects task-specific parameters according to the context.\n\u2022DoubleAda [Zhao et al. , 2023 ]: This MAML-based\nmethod performs additional data and label adaptations to\nalleviate the impact of concept drifts, which uses the latest\ndata exclusively for model adaptation.\n\u2022MetaDA : Following the paradigm of MAML, the proposed\nmethod performs model adaptation with both the latest data\nand the selected historical data.Implementation. The time interval Tadabetween two model\nadaptation is 15 trading days. Adam optimizer is utilized for\ntraining, where \u03b7=\u03b7t= 0.001and\u03b7a= 0.01. During all\nthe following experiments, a single-layer GRU [Chung et al. ,\n2014 ]is used as the task inference network with \u03bafixed at\n80,\u03b3fixed at 1 and Nfixed at 8. In the following parts, the\naverage results of 5 repeated experiments are reported.\n5.2 Performance Comparison (Q1)\nTo explore the performance of MetaDA across different fore-\ncasters, the above methods are evaluated with different fore-\ncasters ( f(\u00b7, \u03b8f)for MetaDA). Three widely used deep neu-\nral networks with Qlib\u2019s default structure are used, including\nLSTM [Hochreiter and Schmidhuber, 1997 ], GRU [Chung et\nal., 2014 ], and Transformer [Vaswani et al. , 2017 ].\nWe first carry out comparison experiments where IC, ICIR,\nRIC, RICIR, eAR, and eARIR are utilized for evaluation. The\nexperimental results are presented in Table 1. The proposed\nMetaDA achieves the best results in most scenarios, indicat-\ning our method can enable more accurate stock trend pre-\ndiction across various datasets and models. Since multiple\nmetrics, forecasters, and datasets have been included, Fried-\nman test is further introduced to evaluate the overall perfor-\nmance across different scenarios. The results of Friedman\ntest at 90% significance are shown in Figure 3. MetaDA\nachieves the best average rank among the tested methods, and\nhas significantly outperformed several comparison methods\nlike DDG-DA and C-MAML. When it comes to the latest IL\nmethods, the proposed method still achieves a better average\nrank with a considerable margin. Compared to DoubleAda,\nMetaDA has further improved the prediction of stock trends\nby revising the selected historical data. In this way, MetaDA\ncan effectively update the forecaster with the latest data while\nalleviating the impacts of catastrophic forgetting. Moreover,", "mimetype": "text/plain", "start_char_idx": 3231, "end_char_idx": 5680, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2032e0e1-e63d-4425-b171-4fe678a4e34a": {"__data__": {"id_": "2032e0e1-e63d-4425-b171-4fe678a4e34a", "embedding": null, "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aa5201a8209f73e1c60556d7d04c9651a9da4999304c1c91d53c448cd740ec81", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ac4705c-a1cd-4204-851d-7b6c7182ab48", "node_type": "1", "metadata": {}, "hash": "dc1527ede2091af3b18e2e126c2c31579f260b0c045b23bf93e2802582b0ffc8", "class_name": "RelatedNodeInfo"}}, "text": "LSTM GRU Transformer\nIC ICIR RIC RICIR IC ICIR RIC RICIR IC ICIR RIC RICIR\nIL/CSI-300 0.0484 0.3476 0.0633 0.4663 0.0536 0.3815 0.0664 0.4968 0.0333 0.2269 0.0489 0.3493\nMetaIL/CSI-300 0.0517 0.3927 0.0644 0.5019 0.0573 0.4306 0.0678 0.5304 0.0406 0.2863 0.0526 0.3902\nMetaDA/CSI-300 0.0525 0.4010 0.0657 0.5179 0.0584 0.4400 0.0683 0.5372 0.0430 0.3061 0.0555 0.4216\nIL/CSI-500 0.0529 0.4518 0.0719 0.6790 0.0554 0.4716 0.0730 0.6891 0.0395 0.3155 0.0614 0.5401\nMetaIL/CSI-500 0.0576 0.5081 0.0740 0.7230 0.0597 0.5207 0.0759 0.7307 0.0524 0.4265 0.0653 0.5817\nMetaDA/CSI-500 0.0577 0.5165 0.0745 0.7418 0.0606 0.5361 0.0757 0.7412 0.0552 0.4404 0.0652 0.5732\nTable 2: The results of ablation experiments on CSI-300 and CSI-500 datasets, where MetaIL is short for Meta-Learning-based IL.\n01234567\nDDG-DA IL C-MAML MetaCoG DoubleAda MetaDARank\nFigure 3: The results of Friedman test at 90% significance level,\nwhich is a general analysis across different datasets, forecasters, and\nmetrics. If the bars of two methods do not overlap, it indicates that\nthey are significantly different.\n3600370038003900400041004200\n3600370038003900400041004200\n4400460048005000520054005600\n\ud835\udc9f\ud835\udc61\ud835\udc5f\u210e\u2217\n(01/06/ 2015 -19/06/ 2015 ) \n\ud835\udc9f\ud835\udc61\ud835\udc52196(27/02/2020-18/03/ 2020) \n\ud835\udc9f\ud835\udc61\ud835\udc5f196(06/02/2020-26/02/2020) \nFigure 4: The CSI-300 index (SH000300) of D196\ntr,D196\nte, and corre-\nsponding Dh\u2217\ntr, which has a stock price trend similar to that of D196\nte.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1415, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ac4705c-a1cd-4204-851d-7b6c7182ab48": {"__data__": {"id_": "4ac4705c-a1cd-4204-851d-7b6c7182ab48", "embedding": null, "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aa5201a8209f73e1c60556d7d04c9651a9da4999304c1c91d53c448cd740ec81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2032e0e1-e63d-4425-b171-4fe678a4e34a", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "b4e210f97ecbeed5159ccb150852fcb4cc4e5eedd454006227a40fe7cc1c4ff1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "81776a8f-b57a-46fc-950b-bed973dcf3e8", "node_type": "1", "metadata": {}, "hash": "eaf1469242ade50f663a40fa830b28cc72244ad894737569a3cde8e36273a2c6", "class_name": "RelatedNodeInfo"}}, "text": "If the bars of two methods do not overlap, it indicates that\nthey are significantly different.\n3600370038003900400041004200\n3600370038003900400041004200\n4400460048005000520054005600\n\ud835\udc9f\ud835\udc61\ud835\udc5f\u210e\u2217\n(01/06/ 2015 -19/06/ 2015 ) \n\ud835\udc9f\ud835\udc61\ud835\udc52196(27/02/2020-18/03/ 2020) \n\ud835\udc9f\ud835\udc61\ud835\udc5f196(06/02/2020-26/02/2020) \nFigure 4: The CSI-300 index (SH000300) of D196\ntr,D196\nte, and corre-\nsponding Dh\u2217\ntr, which has a stock price trend similar to that of D196\nte.\nWith the introduction of Dh\u2217\ntr, IC has increased by 50 % on this task.\nthe performance of MetaDA can be further boosted by intro-\nducing a better forecaster or a better task inference module.\n5.3 Ablation Study (Q2)\nThe results of ablation study on CSI-300 and CSI-500\ndatasets have been presented in Table 2. Three methods\nare introduced for ablation study, namely IL baseline (IL),\nMetaIL, and MetaDA. MetaIL denotes meta-learning-based\nIL and represents the MetaDA without task inference mod-\nule, which relies exclusively on the latest data for model\nadaptation. Both MetaDA and MetaIL have achieved per-\nformance better than IL, which indicates the effectiveness of\nmeta-learning-based IL framework. Compared with MetaIL,\nthe introduction of dynamic adaptation has boosted the per-\nformance of MetaDA in most scenarios. MetaIL achieves\nbetter RIC on the CSI-500 datasets with certain forecasters.\nThe methods focusing on recurring patterns (DDG-DA and\nMetaCoG) have suffered significant performance degradation\non the CSI-500 datasets, which indicates that the recurring\npatterns become less effective. Such performance degrada-\ntion is occasional, and the introduction of selected historical\ndata has improved performance in most scenarios. A typicalLSTM GRU Transformer\nDDG-DA 4974.4 4983.2 3732.2\nIL 1.9 1.9 4.0\nC-MAML 5.4 5.7 13.4\nMetaCoG 3.9 4.0 8.9\nDoubleAda 2.9 3.5 6.1\nMetaDA 3.9 3.9 8.2\nTable 3: The total time cost (in seconds) of model adapta-\ntion/retraining on the CSI-300 dataset.\nexample is indicated in Figure 4, where the introduction of\nhistorical data has significantly improved the prediction. With\nDh\u2217\ntr, the IC on task T196has increased by 50% (from 0.0427\nto 0.0660, GRU). In general, the ablation study has proven\nthe effectiveness of the proposed components in MetaDA.", "mimetype": "text/plain", "start_char_idx": 991, "end_char_idx": 3216, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81776a8f-b57a-46fc-950b-bed973dcf3e8": {"__data__": {"id_": "81776a8f-b57a-46fc-950b-bed973dcf3e8", "embedding": null, "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aa5201a8209f73e1c60556d7d04c9651a9da4999304c1c91d53c448cd740ec81", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ac4705c-a1cd-4204-851d-7b6c7182ab48", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "cf3b0db8ce073f74483e3a82064797335cc7d01092a09e4852a8ef868d4cb898", "class_name": "RelatedNodeInfo"}}, "text": "example is indicated in Figure 4, where the introduction of\nhistorical data has significantly improved the prediction. With\nDh\u2217\ntr, the IC on task T196has increased by 50% (from 0.0427\nto 0.0660, GRU). In general, the ablation study has proven\nthe effectiveness of the proposed components in MetaDA.\n5.4 Model Adaptation Efficiency (Q3)\nHigher adaptation efficiency means that the models can be\nfrequently adjusted on a larger scale, which could poten-\ntially improve stock trend forecasting. The efficiency of\nmodel adaptation is therefore evaluated, with the empirical\ntime costs presented in Table 3. The efficiency of MetaDA\nis comparable with the state-of-the-art methods. As only\nthe selected historical data is added to the model adaptation,\nthe efficiency degradation of MetaDA is limited compared to\nthe baselines of incremental learning. Meanwhile, the pro-\nposed method is significantly faster than the rolling retraining\nmethod. The above results have indicated that MetaDA has\nachieved considerable adaptation efficiency.\n6 Conclusion\nIn this paper, meta-learning with dynamic adaptation\n(MetaDA) is proposed for the incremental learning of stock\ntrends. MetaDA is the first incremental learning method\nthat considers both the predictable and unpredictable concept\ndrifts. This work has provided two insights for alleviating the\nimpact of stock concept drifts. Firstly, dynamic adaptation is\nincorporated into the framework of meta-learning-based IL,\nwhich utilizes the latest and the historical data. Secondly,\nwe propose a task inference module to identify the historical\ndata that might contain recurring patterns. On the real-world\ndatasets, MetaDA has achieved state-of-the-art performance\nwith considerable efficiency. In the future, we are going to\nincorporate side information such as news into the incremen-\ntal learning framework for stock trend forecasting.", "mimetype": "text/plain", "start_char_idx": 2917, "end_char_idx": 4798, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76971a2d-b1a6-4d88-b839-ed33a5105f1d": {"__data__": {"id_": "76971a2d-b1a6-4d88-b839-ed33a5105f1d", "embedding": null, "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b29ca7f3-9b62-44ac-805d-685f35879420", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aaabda7eb94b9c9ae3449664100aeb6413f6b887c8ed4cc36308288b8545816f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f", "node_type": "1", "metadata": {}, "hash": "c70c19d00c77f0727709b8d136b74e212f78cebbd5ca8ac6cea2b9f97fd1a2a1", "class_name": "RelatedNodeInfo"}}, "text": "Ethical Statement\nThere are no ethical issues.\nAcknowledgments\nReferences\n[Balvers et al. , 1990 ]Ronald J Balvers, Thomas F Cosi-\nmano, and Bill McDonald. Predicting stock returns in\nan efficient market. The Journal of Finance , 45(4):1109\u2013\n1128, 1990.\n[Caccia et al. , 2020 ]Massimo Caccia, Pau Rodriguez, Olek-\nsiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Page-\nCaccia, Issam Hadj Laradji, Irina Rish, Alexandre La-\ncoste, David V \u00b4azquez, and Laurent Charlin. Online fast\nadaptation and knowledge accumulation (osaka): a new\napproach to continual learning. In Advances in Neural In-\nformation Processing Systems , volume 33, pages 16532\u2013\n16545, 2020.\n[Chung et al. , 2014 ]Junyoung Chung, Caglar Gulcehre,\nKyunghyun Cho, and Yoshua Bengio. Empirical evalua-\ntion of gated recurrent neural networks on sequence mod-\neling. In NIPS 2014 Workshop on Deep Learning, Decem-\nber 2014 , 2014.\n[Dem \u02c7sar, 2006 ]Janez Dem \u02c7sar. Statistical comparisons of\nclassifiers over multiple data sets. Journal of Machine\nLearning Research , 7(1):1\u201330, 2006.\n[Fang et al. , 2020 ]Tongtong Fang, Nan Lu, Gang Niu, and\nMasashi Sugiyama. Rethinking importance weighting for\ndeep learning under distribution shift. In Advances in\nNeural Information Processing Systems , volume 33, pages\n11996\u201312007, 2020.\n[Finn et al. , 2017 ]Chelsea Finn, Pieter Abbeel, and Sergey\nLevine. Model-agnostic meta-learning for fast adapta-\ntion of deep networks. In Proceedings of the 34th Inter-\nnational Conference on Machine Learning , pages 1126\u2013\n1135. PMLR, 06\u201311 Aug 2017.\n[Finn et al. , 2019 ]Chelsea Finn, Aravind Rajeswaran, Sham\nKakade, and Sergey Levine. Online meta-learning. In Pro-\nceedings of the 36th International Conference on Machine\nLearning , volume 97, pages 1920\u20131930. PMLR, 09\u201315\nJun 2019.\n[Gama et al. , 2014a ]Jo\u02dcao Gama, Indre \u02c7Zliobaite, Albert\nBifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia.\nA survey on concept drift adaptation. ACM Computing\nSurveys , 46(4), mar 2014.\n[Gama et al. , 2014b ]Jo\u02dcao Gama, Indrundefined\n\u02c7Zliobaitundefined, Albert Bifet, Mykola Pechenizkiy,\nand Abdelhamid Bouchachia. A survey on concept drift\nadaptation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2137, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f": {"__data__": {"id_": "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f", "embedding": null, "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b29ca7f3-9b62-44ac-805d-685f35879420", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aaabda7eb94b9c9ae3449664100aeb6413f6b887c8ed4cc36308288b8545816f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76971a2d-b1a6-4d88-b839-ed33a5105f1d", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "e8ae5c8a7147dd73fa0cf8062f5b82c75fcb6fffce1916ad5b7aa2b7df3b9e5d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "14c62c2c-9c8a-42f7-b1f3-145675b17f32", "node_type": "1", "metadata": {}, "hash": "59f55e750940689caa5bf974539fd8cc6bf4b1c161125e5eb2ab3bae5d5bf242", "class_name": "RelatedNodeInfo"}}, "text": "Online meta-learning. In Pro-\nceedings of the 36th International Conference on Machine\nLearning , volume 97, pages 1920\u20131930. PMLR, 09\u201315\nJun 2019.\n[Gama et al. , 2014a ]Jo\u02dcao Gama, Indre \u02c7Zliobaite, Albert\nBifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia.\nA survey on concept drift adaptation. ACM Computing\nSurveys , 46(4), mar 2014.\n[Gama et al. , 2014b ]Jo\u02dcao Gama, Indrundefined\n\u02c7Zliobaitundefined, Albert Bifet, Mykola Pechenizkiy,\nand Abdelhamid Bouchachia. A survey on concept drift\nadaptation. ACM Computing Surveys (CSUR) , 46(4), mar\n2014.\n[Gao et al. , 2023 ]Siyu Gao, Yunbo Wang, and Xiaokang\nYang. Stockformer: Learning hybrid trading machines\nwith predictive coding. In Proceedings of the Thirty-\nSecond International Joint Conference on Artificial Intel-\nligence, IJCAI-23 , pages 4766\u20134774, 8 2023.[Gibbs and Candes, 2021 ]Isaac Gibbs and Emmanuel Can-\ndes. Adaptive conformal inference under distribution shift.\nInAdvances in Neural Information Processing Systems ,\nvolume 34, pages 1660\u20131672, 2021.\n[Gunasekara et al. , 2023 ]Nuwan Gunasekara, Bernhard\nPfahringer, Heitor Murilo Gomes, and Albert Bifet.\nSurvey on online streaming continual learning. In\nProceedings of the Thirty-Second International Joint\nConference on Artificial Intelligence, IJCAI-23 , pages\n6628\u20136637, 8 2023.\n[Heet al. , 2020 ]Xu He, Jakub Sygnowski, Alexandre\nGalashov, Andrei Alex Rusu, Yee Whye Teh, and Razvan\nPascanu. Task agnostic continual learning via meta learn-\ning. In 4th Lifelong Machine Learning Workshop at ICML\n2020 , 2020.\n[Hochreiter and Schmidhuber, 1997 ]Sepp Hochreiter and\nJ\u00a8urgen Schmidhuber. Long short-term memory. Neural\nComputation , 9(8):1735\u20131780, 1997.\n[Kirkpatrick et al. , 2017 ]James Kirkpatrick, Razvan Pas-\ncanu, Neil Rabinowitz, Joel Veness, Guillaume Des-\njardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago\nRamalho, Agnieszka Grabska-Barwinska, Demis Hass-\nabis, Claudia Clopath, Dharshan Kumaran, and Raia Had-\nsell. Overcoming catastrophic forgetting in neural net-\nworks. Proceedings of the National Academy of Sciences ,\n114(13):3521\u20133526, 2017.\n[Liet al.", "mimetype": "text/plain", "start_char_idx": 1631, "end_char_idx": 3728, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "14c62c2c-9c8a-42f7-b1f3-145675b17f32": {"__data__": {"id_": "14c62c2c-9c8a-42f7-b1f3-145675b17f32", "embedding": null, "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b29ca7f3-9b62-44ac-805d-685f35879420", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "aaabda7eb94b9c9ae3449664100aeb6413f6b887c8ed4cc36308288b8545816f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f", "node_type": "1", "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "98a616943d40940d197a75bf0dfeefe0d29654a7d7f44a4fe0ad6787149ecdf4", "class_name": "RelatedNodeInfo"}}, "text": "[Hochreiter and Schmidhuber, 1997 ]Sepp Hochreiter and\nJ\u00a8urgen Schmidhuber. Long short-term memory. Neural\nComputation , 9(8):1735\u20131780, 1997.\n[Kirkpatrick et al. , 2017 ]James Kirkpatrick, Razvan Pas-\ncanu, Neil Rabinowitz, Joel Veness, Guillaume Des-\njardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago\nRamalho, Agnieszka Grabska-Barwinska, Demis Hass-\nabis, Claudia Clopath, Dharshan Kumaran, and Raia Had-\nsell. Overcoming catastrophic forgetting in neural net-\nworks. Proceedings of the National Academy of Sciences ,\n114(13):3521\u20133526, 2017.\n[Liet al. , 2022 ]Wendi Li, Xiao Yang, Weiqing Liu, Yingce\nXia, and Jiang Bian. Ddg-da: Data distribution generation\nfor predictable concept drift adaptation. Proceedings of the\nAAAI Conference on Artificial Intelligence , 36(4):4092\u2013\n4100, Jun. 2022.\n[Liang et al. , 2021 ]Qianqiao Liang, Mengying Zhu, Xi-\naolin Zheng, and Yan Wang. An adaptive news-driven\nmethod for cvar-sensitive online portfolio selection in non-\nstationary financial markets. In Proceedings of the Thir-\ntieth International Joint Conference on Artificial Intelli-\ngence, IJCAI-21 , pages 2708\u20132715, 8 2021.\n[Linet al. , 2017 ]Zhouhan Lin, Minwei Feng, Ci-\ncero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive\nsentence embedding. In International Conference on\nLearning Representations , 2017.\n[Linet al. , 2021 ]Hengxu Lin, Dong Zhou, Weiqing Liu, and\nJiang Bian. Learning multiple stock trading patterns with\ntemporal routing adaptor and optimal transport. In Pro-\nceedings of the 27th ACM SIGKDD Conference on Knowl-\nedge Discovery & Data Mining , page 1017\u20131026, 2021.\n[Luet al. , 2019 ]Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Jo \u02dcao\nGama, and Guangquan Zhang. Learning under concept\ndrift: A review. IEEE Transactions on Knowledge and\nData Engineering , 31(12):2346\u20132363, 2019.\n[Su\u00b4arez-Cetrulo et al. , 2023 ]Andr \u00b4es L. Su \u00b4arez-Cetrulo,\nDavid Quintana, and Alejandro Cervantes. A survey\non machine learning for recurring concept drifting data\nstreams. Expert Systems with Applications , 213:118934,\n2023.", "mimetype": "text/plain", "start_char_idx": 3167, "end_char_idx": 5253, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "123f5af3-dae1-475f-b140-0bbbcb349573": {"__data__": {"id_": "123f5af3-dae1-475f-b140-0bbbcb349573", "embedding": null, "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58bc9e7c-c56b-4dd4-9fe4-5405b0657f1f", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "24592560ad539c3bcb47c1ed942fea2658406e7d14a0b553297915ebe184d32c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d8b5bae6-caa6-4daa-8dfd-e72004d92fd3", "node_type": "1", "metadata": {}, "hash": "259924f9f3492f94d5ec50efcca9d7fdd5cbd69ee48c3982e2deb0a6778353b2", "class_name": "RelatedNodeInfo"}}, "text": "[van de Ven et al. , 2022 ]Gido M van de Ven, Tinne Tuyte-\nlaars, and Andreas S Tolias. Three types of incremental\nlearning. Nature Machine Intelligence , 4(12):1185\u20131197,\n2022.\n[van der Maaten and Hinton, 2008 ]Laurens van der Maaten\nand Geoffrey Hinton. Visualizing data using t-sne. Journal\nof Machine Learning Research , 9(86):2579\u20132605, 2008.\n[Vaswani et al. , 2017 ]Ashish Vaswani, Noam Shazeer, Niki\nParmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141 ukasz Kaiser, and Illia Polosukhin. Attention is all you\nneed. In Advances in Neural Information Processing Sys-\ntems, volume 30, 2017.\n[Xuet al. , 2021 ]Wentao Xu, Weiqing Liu, Chang Xu, Jiang\nBian, Jian Yin, and Tie-Yan Liu. Rest: Relational event-\ndriven stock trend forecasting. In Proceedings of the Web\nConference 2021 , WWW \u201921, page 1\u201310, 2021.\n[Yamanishi and Takeuchi, 2002 ]Kenji Yamanishi and Jun-\nichi Takeuchi. A unifying framework for detecting outliers\nand change points from non-stationary time series data. In\nProceedings of the 8th ACM SIGKDD International Con-\nference on Knowledge Discovery & Data Mining , page\n676\u2013681, 2002.\n[Yang et al. , 2020 ]Xiao Yang, Weiqing Liu, Dong Zhou,\nJiang Bian, and Tie-Yan Liu. Qlib: An ai-\noriented quantitative investment platform. arXiv preprint\narXiv:2009.11189 , 2020.\n[Yang et al. , 2021 ]Zhenhuan Yang, Yunwen Lei, Puyu\nWang, Tianbao Yang, and Yiming Ying. Simple stochastic\nand online gradient descent algorithms for pairwise learn-\ning. In Advances in Neural Information Processing Sys-\ntems, volume 34, pages 20160\u201320171, 2021.\n[Zhan et al. , 2022 ]Donglin Zhan, Yusheng Dai, Yiwei\nDong, Jinghai He, Zhenyi Wang, and James Anderson.\nMeta-adaptive stock movement prediction with two-stage\nrepresentation learning. In NeurIPS 2022 Workshop on\nDistribution Shifts: Connecting Methods and Applica-\ntions , 2022.\n[Zhao et al. , 2020 ]Peng Zhao, Le-Wen Cai, and Zhi-Hua\nZhou. Handling concept drift via model reuse. Machine\nlearning , 109:533\u2013568, 2020.\n[Zhao et al. , 2023 ]Lifan Zhao, Shuming Kong, and Yanyan\nShen. Doubleadapt: A meta-learning approach to incre-\nmental learning for stock trend forecasting.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2130, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8b5bae6-caa6-4daa-8dfd-e72004d92fd3": {"__data__": {"id_": "d8b5bae6-caa6-4daa-8dfd-e72004d92fd3", "embedding": null, "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "58bc9e7c-c56b-4dd4-9fe4-5405b0657f1f", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "24592560ad539c3bcb47c1ed942fea2658406e7d14a0b553297915ebe184d32c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "123f5af3-dae1-475f-b140-0bbbcb349573", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}, "hash": "f391dcbf22a59647ce65b6a658efd57dbfee3da434ada40abe8d4825dc6e734b", "class_name": "RelatedNodeInfo"}}, "text": "[Zhan et al. , 2022 ]Donglin Zhan, Yusheng Dai, Yiwei\nDong, Jinghai He, Zhenyi Wang, and James Anderson.\nMeta-adaptive stock movement prediction with two-stage\nrepresentation learning. In NeurIPS 2022 Workshop on\nDistribution Shifts: Connecting Methods and Applica-\ntions , 2022.\n[Zhao et al. , 2020 ]Peng Zhao, Le-Wen Cai, and Zhi-Hua\nZhou. Handling concept drift via model reuse. Machine\nlearning , 109:533\u2013568, 2020.\n[Zhao et al. , 2023 ]Lifan Zhao, Shuming Kong, and Yanyan\nShen. Doubleadapt: A meta-learning approach to incre-\nmental learning for stock trend forecasting. In Proceed-\nings of the 29th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining , page 3492\u20133503, 2023.\n[\u02c7Zliobait \u02d9eet al. , 2016 ]Indr\u02d9e\u02c7Zliobait \u02d9e, Mykola Pechenizkiy,\nand Joao Gama. An overview of concept drift applications.\nBig data analysis: new algorithms for a new society , pages\n91\u2013114, 2016.", "mimetype": "text/plain", "start_char_idx": 1554, "end_char_idx": 2444, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"608317b7-9505-4d1b-9167-5975acf1e1be": {"doc_hash": "04287b619b6ea7928c20076ceb8ad8dcf31987396e75d3f84cec5ec71e076b93", "ref_doc_id": "0c26d813-bbc5-4e75-ba6b-c5c360a91cc7"}, "4de40ce2-9fe8-44f8-9f66-55c0452e7f07": {"doc_hash": "ce7b81e844c18e144cfe7c8caa2cc24f9a0ce080d6e2e37fd5fae77fe22ce252", "ref_doc_id": "0c26d813-bbc5-4e75-ba6b-c5c360a91cc7"}, "13fe6094-04fe-4e3f-90d4-e216f709551b": {"doc_hash": "9c19e15b48bfb98f4a1b7acc6f5204d970aff6ef4ee67722c9c644763498bdfc", "ref_doc_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9"}, "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea": {"doc_hash": "5e817a50dfb99383eed447b2a357be53ad9ce5a5ee7b1a3b14473e9791853638", "ref_doc_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9"}, "a4e6c4ca-d583-4241-b718-fbe6e47507c4": {"doc_hash": "f519193b2cc06672743b169703f9da81b18ce41c953029e07fd30078ae3c663f", "ref_doc_id": "d4af14a0-0a71-42f6-8301-453d0c3529d9"}, "875dd254-e4e8-4016-9f29-66ab4503d607": {"doc_hash": "c225cb3cc23b70664fe8987662b257b203615c552e79166a1c4b16d6e1bda62a", "ref_doc_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b"}, "c9e9911f-8d4a-4ab1-bfe7-7444b430870d": {"doc_hash": "86fc9a3ab3d8483bd64bb60fb79ecd256ef9f055999bc9bada459791dbd4993b", "ref_doc_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b"}, "b67487c5-eaa4-4138-a10a-fadfe062d03a": {"doc_hash": "d49f8d6ef9cf2511b5601fda83d6a30520042871c183c92a693f8b1905114d31", "ref_doc_id": "9afe1349-f332-4dc6-9d95-9fd3c6726e9b"}, "73a6065a-ef36-4ec4-99e2-29ececf78f3b": {"doc_hash": "5a1c197a0df3e5c9fc1d92615bf6a11b0b220000bec82d87d61865906eff11ec", "ref_doc_id": "bc66c833-82ec-4329-a18b-1fdf2186f019"}, "b2bd1f08-2841-4294-9fdb-e6d35c002ed5": {"doc_hash": "cbd22d08480cddffe6c3b0de44596559f67e81dc1159a155d8ff790e0b3f65b0", "ref_doc_id": "bc66c833-82ec-4329-a18b-1fdf2186f019"}, "3540039d-3615-4adc-a89c-9396c99976cf": {"doc_hash": "423ea9bab49ea77ba119aff11326f95017d72e7ef68af60fa7f55f519224e2f1", "ref_doc_id": "bc66c833-82ec-4329-a18b-1fdf2186f019"}, "b14d2b8a-abd4-4a58-8552-881abeffb17d": {"doc_hash": "ced0c20428629b7254a27bbbb9ceea350f1933ce901a6c1035873d8add40c57c", "ref_doc_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e"}, "18bbae4d-8841-4dd3-94ac-a902ec306596": {"doc_hash": "27cfef25b745d8812a22456e98197a73677d998c7b9429730102e79064270986", "ref_doc_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e"}, "22d8f877-7329-4d6a-b2e3-1f52d57f8411": {"doc_hash": "9a04fb4903b21b5d874f20101bc095717269e439fa8be8a4cebd726283123312", "ref_doc_id": "d444b67c-e86a-4d03-9c58-c9fd359dbc0e"}, "49f5fdcc-f00d-48c1-bd72-3cd03cde09df": {"doc_hash": "55359dc4a4acc7995a3258903574342dfa8fbb9d409e71cefb477dbd5a654477", "ref_doc_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea"}, "372afef2-81cd-4bbe-9605-25ab658832d7": {"doc_hash": "e20ceaa11ce7993e26c8e216206e2ca0db2ed9a85e8ad934c5df21d6626a909a", "ref_doc_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea"}, "ba7d0edd-44ec-48b0-9ebe-61124b8c959e": {"doc_hash": "9f65aca09c4b8b476be1a5be4a201046acbabed4904ff0c065f9e1418643d762", "ref_doc_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea"}, "f42ded87-0bdb-40b6-93f2-7c15c63752d8": {"doc_hash": "b457b607e39d2597194672f552c7c991ad0129a6ac7eca310e31294bf2f1b4dc", "ref_doc_id": "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea"}, "2032e0e1-e63d-4425-b171-4fe678a4e34a": {"doc_hash": "b4e210f97ecbeed5159ccb150852fcb4cc4e5eedd454006227a40fe7cc1c4ff1", "ref_doc_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe"}, "4ac4705c-a1cd-4204-851d-7b6c7182ab48": {"doc_hash": "cf3b0db8ce073f74483e3a82064797335cc7d01092a09e4852a8ef868d4cb898", "ref_doc_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe"}, "81776a8f-b57a-46fc-950b-bed973dcf3e8": {"doc_hash": "e2714a0df3c53f42c5378bd0e04525e24b8dab4563eff41f49ee9a72516ac0a1", "ref_doc_id": "860e83ad-c889-4f8a-ad7d-58778c95e4fe"}, "76971a2d-b1a6-4d88-b839-ed33a5105f1d": {"doc_hash": "e8ae5c8a7147dd73fa0cf8062f5b82c75fcb6fffce1916ad5b7aa2b7df3b9e5d", "ref_doc_id": "b29ca7f3-9b62-44ac-805d-685f35879420"}, "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f": {"doc_hash": "98a616943d40940d197a75bf0dfeefe0d29654a7d7f44a4fe0ad6787149ecdf4", "ref_doc_id": "b29ca7f3-9b62-44ac-805d-685f35879420"}, "14c62c2c-9c8a-42f7-b1f3-145675b17f32": {"doc_hash": "3a0fce8ad3c0dff68f3214b68849e4eb100432482d1ecf2667ecf331261b0ad6", "ref_doc_id": "b29ca7f3-9b62-44ac-805d-685f35879420"}, "123f5af3-dae1-475f-b140-0bbbcb349573": {"doc_hash": "f391dcbf22a59647ce65b6a658efd57dbfee3da434ada40abe8d4825dc6e734b", "ref_doc_id": "58bc9e7c-c56b-4dd4-9fe4-5405b0657f1f"}, "d8b5bae6-caa6-4daa-8dfd-e72004d92fd3": {"doc_hash": "438152572c526e932e92c4ab9acfb04bc5db9ac7979248a10ae77b2e462de1fb", "ref_doc_id": "58bc9e7c-c56b-4dd4-9fe4-5405b0657f1f"}}, "docstore/ref_doc_info": {"0c26d813-bbc5-4e75-ba6b-c5c360a91cc7": {"node_ids": ["608317b7-9505-4d1b-9167-5975acf1e1be", "4de40ce2-9fe8-44f8-9f66-55c0452e7f07"], "metadata": {"page_label": "1", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "d4af14a0-0a71-42f6-8301-453d0c3529d9": {"node_ids": ["13fe6094-04fe-4e3f-90d4-e216f709551b", "c90a1532-5fe5-4c33-ad05-8cbd77cdcfea", "a4e6c4ca-d583-4241-b718-fbe6e47507c4"], "metadata": {"page_label": "2", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "9afe1349-f332-4dc6-9d95-9fd3c6726e9b": {"node_ids": ["875dd254-e4e8-4016-9f29-66ab4503d607", "c9e9911f-8d4a-4ab1-bfe7-7444b430870d", "b67487c5-eaa4-4138-a10a-fadfe062d03a"], "metadata": {"page_label": "3", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "bc66c833-82ec-4329-a18b-1fdf2186f019": {"node_ids": ["73a6065a-ef36-4ec4-99e2-29ececf78f3b", "b2bd1f08-2841-4294-9fdb-e6d35c002ed5", "3540039d-3615-4adc-a89c-9396c99976cf"], "metadata": {"page_label": "4", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "d444b67c-e86a-4d03-9c58-c9fd359dbc0e": {"node_ids": ["b14d2b8a-abd4-4a58-8552-881abeffb17d", "18bbae4d-8841-4dd3-94ac-a902ec306596", "22d8f877-7329-4d6a-b2e3-1f52d57f8411"], "metadata": {"page_label": "5", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "91ce638d-2ed1-4339-9e6d-2bb69fe9f0ea": {"node_ids": ["49f5fdcc-f00d-48c1-bd72-3cd03cde09df", "372afef2-81cd-4bbe-9605-25ab658832d7", "ba7d0edd-44ec-48b0-9ebe-61124b8c959e", "f42ded87-0bdb-40b6-93f2-7c15c63752d8"], "metadata": {"page_label": "6", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "860e83ad-c889-4f8a-ad7d-58778c95e4fe": {"node_ids": ["2032e0e1-e63d-4425-b171-4fe678a4e34a", "4ac4705c-a1cd-4204-851d-7b6c7182ab48", "81776a8f-b57a-46fc-950b-bed973dcf3e8"], "metadata": {"page_label": "7", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "b29ca7f3-9b62-44ac-805d-685f35879420": {"node_ids": ["76971a2d-b1a6-4d88-b839-ed33a5105f1d", "4f8e04c7-4e4b-49e7-8f8c-e14fe9098b2f", "14c62c2c-9c8a-42f7-b1f3-145675b17f32"], "metadata": {"page_label": "8", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}, "58bc9e7c-c56b-4dd4-9fe4-5405b0657f1f": {"node_ids": ["123f5af3-dae1-475f-b140-0bbbcb349573", "d8b5bae6-caa6-4daa-8dfd-e72004d92fd3"], "metadata": {"page_label": "9", "file_name": "2401_03865v3.pdf", "Title of this paper": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "Authors": "Shiluo Huang, Zheng Liu, Ye Deng, Qing Li", "Date published": "01/08/2024", "URL": "http://arxiv.org/abs/2401.03865v3", "summary": "Forecasting the trend of stock prices is an enduring topic at the\nintersection of finance and computer science. Periodical updates to forecasters\nhave proven effective in handling concept drifts arising from non-stationary\nmarkets. However, the existing methods neglect either emerging patterns in\nrecent data or recurring patterns in historical data, both of which are\nempirically advantageous for future forecasting. To address this issue, we\npropose meta-learning with dynamic adaptation (MetaDA) for the incremental\nlearning of stock trends, which periodically performs dynamic model adaptation\nutilizing the emerging and recurring patterns simultaneously. We initially\norganize the stock trend forecasting into meta-learning tasks and train a\nforecasting model following meta-learning protocols. During model adaptation,\nMetaDA efficiently adapts the forecasting model with the latest data and a\nselected portion of historical data, which is dynamically identified by a task\ninference module. The task inference module first extracts task-level\nembeddings from the historical tasks, and then identifies the informative data\nwith a task inference network. MetaDA has been evaluated on real-world stock\ndatasets, achieving state-of-the-art performance with satisfactory efficiency."}}}}