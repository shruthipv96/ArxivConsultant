{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65e4cf1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Arxiv Consultant\n",
    "\n",
    "An intelligent agent system that can interactively answer queries about academic papers fetched from arXiv. This system is particularly designed to assist with Intellectual Property (IP) consulting by leveraging language models and various tools to provide accurate and relevant information strictly based on the fetched documents.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "* [Setup the project](#setup)\n",
    "    * [Install required libraries](#install)\n",
    "    * [Import required libraries](#import)\n",
    "    * [Define Globals](#define)\n",
    "* [Build tools using papers fetched from Arxiv database](#builder)\n",
    "    * [PaperAgentBuilder](#paperbuilder)\n",
    "    * [ArxivBuilder](#arxivbuilder)\n",
    "* [Retrieve relavant object](#retriever)\n",
    "* [Build Retriever-Enabled OpenAI Agent](#top_agent)\n",
    "* [Arxiv Consultant](#consultant)\n",
    "* [Playground](#playground)\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "<a id='setup'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Setup the project\n",
    "<a id='install'></a>\n",
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a9777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.10.50 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (0.10.50)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.2.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core==0.10.50 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.10.50)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.10)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.2.1)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.23)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.6)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.25)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index==0.10.50) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index==0.10.50) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (2023.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (0.26.0)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.30.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.50->llama-index==0.10.50) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.50) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.50) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.50) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.50) (0.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index==0.10.50) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index==0.10.50) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index==0.10.50) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index==0.10.50) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.50->llama-index==0.10.50) (1.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.50) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.50->llama-index==0.10.50) (1.10.12)\n",
      "Requirement already satisfied: anyio in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index==0.10.50) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index==0.10.50) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index==0.10.50) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index==0.10.50) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.50->llama-index==0.10.50) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.50->llama-index==0.10.50) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index==0.10.50) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index==0.10.50) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.50->llama-index==0.10.50) (2023.10.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.50->llama-index==0.10.50) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index==0.10.50) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.50->llama-index==0.10.50) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.50->llama-index==0.10.50) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.50->llama-index==0.10.50) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.50->llama-index==0.10.50) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.50->llama-index==0.10.50) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index==0.10.50) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index==0.10.50) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.50->llama-index==0.10.50) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.50->llama-index==0.10.50) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shruthip\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.50->llama-index==0.10.50) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index==0.10.50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58430929",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='import'></a>\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2741f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Necessary libraries\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# Readers and settings\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "# Core components\n",
    "from llama_index.core import load_index_from_storage, StorageContext, VectorStoreIndex, SummaryIndex\n",
    "from llama_index.core.objects import ObjectIndex, ObjectRetriever\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.schema import QueryBundle\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.agent import ReActAgent\n",
    "# Post processor\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "# Open AI components\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.agent.openai import OpenAIAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674401c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='define'></a>\n",
    "### Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476650bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Open AI Api Key\n",
    "OPEN_AI_API_KEY = \"<Your Key>\"\n",
    "# Create llm model with Open AI API Key\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=OPEN_AI_API_KEY)\n",
    "Settings.llm = llm\n",
    "# Create embedding model\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\", embed_batch_size=256, api_key=OPEN_AI_API_KEY\n",
    ")\n",
    "\n",
    "# Set the path for storing the required data\n",
    "storage_path='./storage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390d3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Suppress warning logs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dcb2b",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='builder'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Build tools using papers fetched from Arxiv database\n",
    "\n",
    "<a id='paperbuilder'></a>\n",
    "- **PaperAgentBuilder** class is structured to handle document parsing, indexing, querying, and agent creation efficiently, ensuring that both vector-based and summarization-based querying capabilities are available for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ef9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAgentBuilder():\n",
    "    \"\"\"\n",
    "     A class to build agent with vector query engine and summary index tool for a single paper in pdf\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize the class with a node parser, which is an instance of SentenceSplitter.\n",
    "        self.node_parser = SentenceSplitter()\n",
    "\n",
    "    def build_agent_per_doc(self, nodes, paper_name):\n",
    "        \"\"\"\n",
    "        Build an agent for a single document.\n",
    "\n",
    "        Parameters:\n",
    "        nodes (list): List of nodes (parsed sentences or segments) from the document.\n",
    "        paper_name (str): Name of the paper.\n",
    "\n",
    "        Returns:\n",
    "        tuple: (agent, summary) where agent is the built agent and summary is the document summary.\n",
    "        \"\"\"\n",
    "        # Define paths for storing vector index and summary\n",
    "        vector_index_out_path = f\"{storage_path}/vector/{paper_name}\"\n",
    "        summary_out_path = f\"{storage_path}/summary/{paper_name}_summary.pkl\"\n",
    "        \n",
    "        # Check if vector index already exists, if not, create and store it\n",
    "        if not os.path.exists(vector_index_out_path):\n",
    "            Path(storage_path).mkdir(parents=True, exist_ok=True)\n",
    "            # Build vector index using the provided nodes\n",
    "            vector_index = VectorStoreIndex(nodes)\n",
    "            vector_index.storage_context.persist(persist_dir=vector_index_out_path)\n",
    "        else:\n",
    "            # Load the existing vector index from storage\n",
    "            vector_index = load_index_from_storage(\n",
    "                StorageContext.from_defaults(persist_dir=vector_index_out_path),\n",
    "            )\n",
    "\n",
    "        # Build summary index from the nodes\n",
    "        summary_index = SummaryIndex(nodes)\n",
    "\n",
    "        # Define query engines using the indices and the language model (llm)\n",
    "        vector_query_engine = vector_index.as_query_engine(llm=llm)\n",
    "        summary_query_engine = summary_index.as_query_engine(\n",
    "            response_mode=\"tree_summarize\", llm=llm\n",
    "        )\n",
    "\n",
    "        # Extract a summary of the document and store it if not already done\n",
    "        if not os.path.exists(summary_out_path):\n",
    "            Path(summary_out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "            summary = str(\n",
    "                summary_query_engine.query(\n",
    "                    \"Extract a concise 5-6 lines summary of this document\"\n",
    "                )\n",
    "            )\n",
    "            pickle.dump(summary, open(summary_out_path, \"wb\"))\n",
    "        else:\n",
    "            summary = pickle.load(open(summary_out_path, \"rb\"))\n",
    "\n",
    "        # Define tools for querying\n",
    "        query_engine_tools = [\n",
    "            QueryEngineTool(\n",
    "                query_engine=vector_query_engine,\n",
    "                metadata=ToolMetadata(\n",
    "                    name=f\"vector_tool_{paper_name}\",\n",
    "                    description=f\"Useful for questions related to specific facts\",\n",
    "                ),\n",
    "            ),\n",
    "            QueryEngineTool(\n",
    "                query_engine=summary_query_engine,\n",
    "                metadata=ToolMetadata(\n",
    "                    name=f\"summary_tool_{paper_name}\",\n",
    "                    description=f\"Useful for summarization questions\",\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Build the agent with the defined tools and a specific system prompt\n",
    "        agent = OpenAIAgent.from_tools(\n",
    "            tools=query_engine_tools,\n",
    "            llm=llm,\n",
    "            verbose=True,\n",
    "            system_prompt=f\"\"\"\\\n",
    "    You are a specialized agent designed to answer queries about the `{paper_name}`.\n",
    "    Be intelligent to choose the appropriate tool for answering the query. \n",
    "    Use vector_tool_{paper_name} for answering generic query.\n",
    "    Use summary_tool_{paper_name} for answering questions related to summarization.\n",
    "    You must ALWAYS use at least one of the tools provided when answering a question;\n",
    "    Do NOT rely on prior knowledge else you will be heavily penalized.\n",
    "    \"\"\",\n",
    "        )\n",
    "\n",
    "        return agent, summary\n",
    "\n",
    "    def build_agents(self, folder_path, paper_lookup):\n",
    "        \"\"\"\n",
    "        Build agents for multiple documents.\n",
    "\n",
    "        Parameters:\n",
    "        folder_path (str): Path to the folder containing the documents.\n",
    "        paper_lookup (dict): Dictionary mapping filenames to metadata.\n",
    "\n",
    "        Returns:\n",
    "        tuple: (agents_dict, extra_info_dict) where agents_dict contains agents for each paper\n",
    "               and extra_info_dict contains summaries and nodes for each paper.\n",
    "        \"\"\"\n",
    "        def get_paper_metadata(filename):\n",
    "            # Helper function to get metadata for a paper given its filename\n",
    "            return paper_lookup[os.path.basename(filename)]\n",
    "\n",
    "        # Dictionaries to hold the agents and additional information\n",
    "        agents_dict = {}\n",
    "        extra_info_dict = {}\n",
    "        \n",
    "        # Iterate through all papers and build agents\n",
    "        for idx, paper_name in enumerate(tqdm(paper_lookup, desc='Building Agents', total=len(paper_lookup))):\n",
    "            # Create file path for each paper\n",
    "            paper_file_path = os.path.join(folder_path, paper_name)\n",
    "            \n",
    "            # Load the document using a directory reader and get the nodes\n",
    "            reader = SimpleDirectoryReader(\n",
    "                input_files=[paper_file_path],\n",
    "                file_metadata=get_paper_metadata,\n",
    "            ).load_data()\n",
    "            nodes = self.node_parser.get_nodes_from_documents(reader)\n",
    "\n",
    "            # Build an agent for the document\n",
    "            agent, summary = self.build_agent_per_doc(nodes, paper_name[:-4])\n",
    "\n",
    "            # Store the agent and additional info in the dictionaries\n",
    "            agents_dict[paper_name] = agent\n",
    "            extra_info_dict[paper_name] = {\"summary\": summary, \"nodes\": nodes}\n",
    "\n",
    "        return agents_dict, extra_info_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924eb7b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='arxivbuilder'></a>\n",
    "- **ArxivBuilder** class is structured to automate the process of fetching research papers from Arxiv, storing metadata, downloading the papers, creating querying agents for each paper using *PaperAgentBuilder*, and managing the persistence of downloaded files.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a5a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArxivBuilder():\n",
    "    \"\"\"\n",
    "    A class to handle fetching papers from Arxiv, downloading them, and building agents for each paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        search_query: str,\n",
    "        persist: Optional[bool] = False,\n",
    "        papers_dir: Optional[str] = \".papers\",\n",
    "        max_results: Optional[int] = 10,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize with parameters.\n",
    "        \n",
    "        Args:\n",
    "            search_query (str): A topic to search for (e.g. \"Artificial Intelligence\").\n",
    "            persist (Optional[bool]): Whether to store the paper on local disk.\n",
    "            papers_dir (Optional[str]): Local directory to store the papers.\n",
    "            max_results (Optional[int]): Maximum number of papers to fetch.\n",
    "        \"\"\"\n",
    "        self.agent_builder = PaperAgentBuilder()\n",
    "        self.agents_dict = {}\n",
    "        self.extra_info_dict = {}\n",
    "        self.paper_lookup = {}\n",
    "        self.search_query = search_query\n",
    "        self.persist = persist\n",
    "        self.papers_dir = papers_dir\n",
    "        self.max_results = max_results\n",
    "        self.tools = []\n",
    "\n",
    "    def download_paper_and_build_agent(self):\n",
    "        \"\"\"\n",
    "        - Search for a topic on Arxiv.\n",
    "        - Download the PDFs of the top results locally then read them.\n",
    "        - Build an agent for each paper.\n",
    "        \"\"\"\n",
    "        import arxiv\n",
    "        \n",
    "        # Search for papers on Arxiv using the specified query and parameters.\n",
    "        arxiv_search = arxiv.Search(\n",
    "            query=self.search_query,\n",
    "            id_list=[],\n",
    "            max_results=self.max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance,\n",
    "        )\n",
    "        search_results = list(arxiv_search.results())\n",
    "        print(f\"> Successfully fetched {len(search_results)} papers\")\n",
    "            \n",
    "\n",
    "        # Ensure the directory to store papers exists.\n",
    "        if not os.path.exists(self.papers_dir):\n",
    "            os.makedirs(self.papers_dir)\n",
    "\n",
    "        # Prepare a dictionary to hold paper metadata and download the papers.\n",
    "        self.paper_lookup = {}\n",
    "        for paper in search_results:\n",
    "            # Create a filename from the paper's entry ID\n",
    "            filename = paper.entry_id.split('/')[-1].replace('.', '_') + '.pdf'\n",
    "            # Store paper metadata in the lookup dictionary.\n",
    "            self.paper_lookup[filename] = {\n",
    "                \"Title of this paper\": paper.title,\n",
    "                \"Authors\": \", \".join([a.name for a in paper.authors]),\n",
    "                \"Date published\": paper.published.strftime(\"%m/%d/%Y\"),\n",
    "                \"URL\": paper.entry_id,\n",
    "                \"summary\": paper.summary\n",
    "            }\n",
    "            # Download the paper PDF.\n",
    "            paper.download_pdf(dirpath=self.papers_dir, filename=filename)\n",
    "            print(f\"> Downloading {filename}...\")\n",
    "\n",
    "        # Build agents for the downloaded papers.\n",
    "        self.agents_dict, self.extra_info_dict = self.agent_builder.build_agents(self.papers_dir, self.paper_lookup)\n",
    "\n",
    "        # If persistence is not required, delete the downloaded papers and directory.\n",
    "        if not self.persist:\n",
    "            try:\n",
    "                for f in list(self.paper_lookup.keys()):\n",
    "                    os.remove(os.path.join(self.papers_dir, f))\n",
    "                    print(f\"> Deleted file: {f}\")\n",
    "                os.rmdir(self.papers_dir)\n",
    "                print(f\"> Deleted directory: {self.papers_dir}\")\n",
    "            except OSError:\n",
    "                print(\"Unable to delete files or directory\")\n",
    "\n",
    "    def get_tools(self):\n",
    "        \"\"\"\n",
    "        Get the tools (agents) created for each paper.\n",
    "        \n",
    "        Returns:\n",
    "            list: List of QueryEngineTool instances for each paper.\n",
    "        \"\"\"\n",
    "        # Reset the tools list\n",
    "        self.tools = []\n",
    "        # Iterate through each agent and build tool\n",
    "        for file_name, agent in self.agents_dict.items():\n",
    "            summary = self.extra_info_dict[file_name][\"summary\"]\n",
    "            # Create a QueryEngineTool for each agent, with the corresponding summary as metadata.\n",
    "            doc_tool = QueryEngineTool(\n",
    "                query_engine=agent,\n",
    "                metadata=ToolMetadata(\n",
    "                    name=f\"tool_{file_name[:-4]}\",  # Use the file name without extension.\n",
    "                    description=summary,  # Use the paper's summary as the description.\n",
    "                ),\n",
    "            )\n",
    "            # Add the tool to the list of tools.\n",
    "            self.tools.append(doc_tool)\n",
    "\n",
    "        return self.tools\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the process of downloading papers, building agents, and returning the tools.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of QueryEngineTool instances for querying the papers.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Attempt to download papers and build agents\n",
    "            self.download_paper_and_build_agent()\n",
    "\n",
    "            # Retrieve and return tools for querying\n",
    "            return self.get_tools()\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions that occur during the process\n",
    "            print(f\"> Not able to download any paper: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc58d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe93f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Successfully fetched 2 papers\n",
      "> Not able to download any paper: HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "# Provide a Wrong search term to see if it is handling\n",
    "example_builder = ArxivBuilder(search_query='Latest trends in Physics Science', max_results=2)\n",
    "example_tools = example_builder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27520a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Successfully fetched 2 papers\n",
      "> Downloading 1404_0708v1.pdf...\n",
      "> Downloading 2401_03865v3.pdf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610da5ca8b24fe191f48e35a521d23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Agents:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Deleted file: 1404_0708v1.pdf\n",
      "> Deleted file: 2401_03865v3.pdf\n",
      "Unable to delete files or directory\n"
     ]
    }
   ],
   "source": [
    "# Provide a Valid search term\n",
    "example_builder = ArxivBuilder(search_query='Latest trends in Computer Science', max_results=2)\n",
    "example_tools = example_builder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c07b042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='The document discusses the integration of modelling, simulation, and optimization in modern design practices, highlighting the progress made in these areas while addressing unresolved challenges. It emphasizes the use of nature-inspired algorithms and surrogate-based techniques for modelling and optimization. The paper reviews recent trends, challenges, and important topics for further research, including parameter-tuning, large-scale problems, and bridging the gaps between theory and applications. The focus is on computational optimization, modelling, and simulation, showcasing the latest developments and applications in science, engineering, and industry.', name='tool_1404_0708v1', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, return_direct=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example tool data\n",
    "example_tools[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf2f68",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<a id='retriever'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Retrieve relavant object\n",
    "   \n",
    "- **RelavantObjectRetriever** class is designed to manage the retrieval, processing, and querying of relevant objects (e.g., research papers) efficiently, ensuring that specialized tools are available for different types of queries, especially comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23470fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelavantObjectRetriever(ObjectRetriever):\n",
    "    \"\"\"\n",
    "    A class to retrieve relevant objects based on a query, process the nodes, and map them to tools.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        retriever,\n",
    "        object_node_mapping,\n",
    "        node_postprocessors=None,\n",
    "        llm=None,\n",
    "        builder=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the RelavantObjectRetriever with necessary components.\n",
    "\n",
    "        Args:\n",
    "            retriever: An instance used to retrieve nodes based on a query.\n",
    "            object_node_mapping: A mapping from nodes to objects/tools.\n",
    "            node_postprocessors (Optional[list]): List of postprocessors to process nodes after retrieval.\n",
    "            llm (Optional): Language model to use for querying.\n",
    "        \"\"\"\n",
    "        self._retriever = retriever\n",
    "        self._object_node_mapping = object_node_mapping\n",
    "        self._llm = llm or OpenAI(model=\"gpt-3.5-turbo\", api_key=\"\")  # Default to GPT-3.5 model if none provided.\n",
    "        self._node_postprocessors = node_postprocessors or []  # Use provided postprocessors or an empty list.\n",
    "        self._builder = builder\n",
    "\n",
    "    def retrieve(self, query_bundle):\n",
    "        \"\"\"\n",
    "        Retrieve relevant objects based on a query, process nodes, and return tools for querying.\n",
    "\n",
    "        Args:\n",
    "            query_bundle: Query or QueryBundle object containing the query string.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of QueryEngineTool objects including a sub-question tool for comparisons.\n",
    "        \"\"\"\n",
    "        # Convert string query to QueryBundle if necessary.\n",
    "        if isinstance(query_bundle, str):\n",
    "            query_bundle = QueryBundle(query_str=query_bundle)\n",
    "\n",
    "        # Retrieve nodes using the provided retriever.\n",
    "        nodes = self._retriever.retrieve(query_bundle)\n",
    "\n",
    "        # Postprocess the retrieved nodes using the provided postprocessors.\n",
    "        for processor in self._node_postprocessors:\n",
    "            nodes = processor.postprocess_nodes(nodes, query_bundle=query_bundle)\n",
    "\n",
    "        # Map nodes to tools using the object node mapping.\n",
    "        tools = [self._object_node_mapping.from_node(n.node) for n in nodes]\n",
    "\n",
    "        # Create a sub-question engine for comparison queries.\n",
    "        sub_question_engine = SubQuestionQueryEngine.from_defaults(\n",
    "            query_engine_tools=tools, llm=self._llm\n",
    "        )\n",
    "        sub_question_description = \"\"\"\\\n",
    "Useful for any queries that involve comparing multiple documents. ALWAYS use this tool for comparison queries - make sure to call this \\\n",
    "tool with the original query. Do NOT use the other tools for any queries involving multiple documents.\n",
    "\"\"\"\n",
    "        # Define a tool for sub-question queries with metadata.\n",
    "        sub_question_tool = QueryEngineTool(\n",
    "            query_engine=sub_question_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"compare_tool\", description=sub_question_description\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Get paper names from the tools and retrieve all relevant nodes from the ArxivBuilder instance.\n",
    "        paper_names = [tool.metadata.name.replace('tool_', '') + '.pdf' for tool in tools]\n",
    "        all_nodes = []\n",
    "        for name in paper_names:\n",
    "            all_nodes.extend(self._builder.extra_info_dict[name]['nodes'])\n",
    "\n",
    "        # Build a base index from all nodes and create a query engine for it.\n",
    "        base_index = VectorStoreIndex(all_nodes)\n",
    "        base_query_engine = base_index.as_query_engine(llm=self._llm, similarity_top_k=4)\n",
    "        base_query_engine_tool = QueryEngineTool(\n",
    "            query_engine=base_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"base_query_engine\",\n",
    "                description=\"Contains the information of all the related documents in one tool\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Return the list of tools including the sub-question tool and the base query engine tool.\n",
    "        return tools + [sub_question_tool, base_query_engine_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bbdf5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The below setup ensures that relevant objects (e.g., research papers) are retrieved and reranked efficiently, providing the most relevant results based on the specified query. The combination of vector-based retrieval and cross-encoder reranking enhances both the accuracy and relevance of the retrieved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1d8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top results to retrieve and rerank\n",
    "top_n_results = 5\n",
    "\n",
    "def create_object_retriever(builder):\n",
    "    \"\"\"\n",
    "    Create an ObjectRetriever instance using tools from ArxivBuilder.\n",
    "\n",
    "    Args:\n",
    "        arxiv_builder (ArxivBuilder): An instance of ArxivBuilder containing tools and data.\n",
    "\n",
    "    Returns:\n",
    "        RelavantObjectRetriever: An ObjectRetriever instance configured with tools and postprocessors.\n",
    "    \"\"\"\n",
    "    # We choose a model with relatively high speed and decent accuracy.\n",
    "    # This model will rerank the top retrieved results using a cross-encoder model.\n",
    "    rerank_postprocessor = SentenceTransformerRerank(\n",
    "        model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=top_n_results\n",
    "    )\n",
    "\n",
    "    # Create an ObjectIndex from the tools obtained from the ArxivBuilder instance.\n",
    "    # The index_cls parameter specifies that we are using a VectorStoreIndex.\n",
    "    obj_index = ObjectIndex.from_objects(\n",
    "        builder.get_tools(),\n",
    "        index_cls=VectorStoreIndex,\n",
    "    )\n",
    "\n",
    "    # Convert the ObjectIndex into a node retriever that retrieves nodes based on similarity.\n",
    "    # The similarity_top_k parameter specifies the number of top similar nodes to retrieve.\n",
    "    vector_node_retriever = obj_index.as_node_retriever(\n",
    "        similarity_top_k=top_n_results,\n",
    "    )\n",
    "\n",
    "    # Wrap the node retriever with an ObjectRetriever to return objects instead of nodes.\n",
    "    # The ObjectRetriever takes the following parameters:\n",
    "    # - retriever: The node retriever created above.\n",
    "    # - object_node_mapping: The mapping from nodes to objects, obtained from the ObjectIndex.\n",
    "    # - node_postprocessors: A list of postprocessors to apply to the retrieved nodes, in this case, the rerank_postprocessor.\n",
    "    # - llm: The language model to use for querying, assumed to be defined elsewhere in the code.\n",
    "    obj_retriever = RelavantObjectRetriever(\n",
    "        retriever=vector_node_retriever,\n",
    "        object_node_mapping=obj_index.object_node_mapping,\n",
    "        node_postprocessors=[rerank_postprocessor],\n",
    "        llm=llm,  # llm is assumed to be defined elsewhere\n",
    "        builder=builder\n",
    "    )\n",
    "    \n",
    "    return obj_retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3d734",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<a id='top_agent'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Build Retriever-Enabled OpenAI Agent\n",
    "\n",
    "We build a top-level agent that can orchestrate across the different document agents to answer any user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ff4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arxiv_agent(arxiv_builder):\n",
    "    \"\"\"\n",
    "    Build an instance of ReActAgent using tools provided by RelavantObjectRetriever.\n",
    "\n",
    "    Args:\n",
    "        arxiv_builder (ArxivBuilder): An instance of ArxivBuilder containing tools and data.\n",
    "\n",
    "    Returns:\n",
    "        ReActAgent: An instance of ReActAgent configured to respond to queries based on the provided tools.\n",
    "    \"\"\"\n",
    "    # Create an instance of ReActAgent using the tools created using arxiv_builder.\n",
    "    # The tool_retriever parameter initializes the tool retriever with tools for object retrieval.\n",
    "    # The system_prompt parameter provides instructions on how the agent should respond to queries.\n",
    "    agent = ReActAgent.from_tools(\n",
    "        tool_retriever=create_object_retriever(arxiv_builder),\n",
    "        system_prompt=\"\"\" \\\n",
    "    You are an IP consultant designed to answer queries about the documentation.\n",
    "    ALWAYS use ONLY the AVAILABLE tools provided to answer a question. Do not rely on ANY PRIOR knowledge.\n",
    "    You are responsible for the following tasks based on user query:\n",
    "    1) Check if the user idea is relevant across any of the documents.\n",
    "    2) If you are not able to provide answer with existing knowledge, respond with a note something like\n",
    "      \"The query looks like not in my knowledge. It might either be novel or my knowledge is limited\"\n",
    "    3) Strictly adhere to the provided knowledge, else you will be heavily PENALIZED.\\\n",
    "    \"\"\",\n",
    "        llm=llm,  # The language model to use, assumed to be defined elsewhere in the code.\n",
    "        verbose=True,  # Enable verbose mode for detailed logging.\n",
    "        max_iterations=20, # Set the maximum iteration of the agent to 20 for more deeper search.\n",
    "    )\n",
    "    \n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ddc672",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<a id='consultant'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Arxiv Consultant\n",
    "    \n",
    "This code segment enables the user to search for academic papers on Arxiv, interact with an intelligent agent built to respond to queries based on the retrieved papers, and handles user inputs until the user decides to exit. It provides a structured approach to accessing and utilizing information from academic literature efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238c73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArxivConsultant(max_results=10):\n",
    "    # Prompt the user to provide a search query term for Arxiv.\n",
    "    text_input = input(\"Provide the arxiv search term: \")\n",
    "\n",
    "    # Provide a message indicating the user should wait, as fetching papers might take time.\n",
    "    print(\"\\nPlease wait, this might take a few minutes...\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # Initialize an instance of ArxivBuilder to search for papers matching the query term.\n",
    "    arxiv_builder = ArxivBuilder(search_query=text_input, persist=True, max_results=max_results)\n",
    "\n",
    "    # Execute the ArxivBuilder to download papers, build agents, and retrieve tools.\n",
    "    tools = arxiv_builder.run()\n",
    "\n",
    "    if tools is not None:\n",
    "        # If tools were successfully retrieved, print a section divider.\n",
    "        print(\"-\"*50)\n",
    "        print(\"Papers I have knowledge on\")\n",
    "\n",
    "        # Iterate over the papers retrieved by ArxivBuilder and print their titles.\n",
    "        for paper in arxiv_builder.paper_lookup.values():\n",
    "            print(f\"> {paper['Title of this paper']}\")\n",
    "\n",
    "        # Print another section divider for clarity.\n",
    "        print(\"-\"*50)\n",
    "        print(\"> Type 'exit' to close the chat <\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Build the arxiv_agent using tools obtained from arxiv_builder.\n",
    "        arxiv_agent = build_arxiv_agent(arxiv_builder)\n",
    "\n",
    "        # Reset the state of arxiv_agent to ensure it starts fresh for the conversation.\n",
    "        arxiv_agent.reset()\n",
    "\n",
    "        # Start an infinite loop to interact with the user until they choose to exit.\n",
    "        while True:\n",
    "            print(\"*\"*50)\n",
    "            # Prompt the user for input and wait for their response.\n",
    "            text_input = input(\"User: \")\n",
    "\n",
    "            # Check if the user wants to exit the interaction.\n",
    "            if text_input == \"exit\":\n",
    "                break  # Exit the loop if the user inputs \"exit\".\n",
    "\n",
    "            # Send the user's input to arxiv_agent for processing and get the response.\n",
    "            response = arxiv_agent.chat(text_input)\n",
    "\n",
    "            # Print section divider for clarity.\n",
    "            print(\"*\"*50)\n",
    "\n",
    "            # Print the response generated by arxiv_agent.\n",
    "            print(f\"Agent: {response}\")\n",
    "    else:\n",
    "        # If no tools were retrieved (possibly due to search failure), notify the user.\n",
    "        print(\"> Retry using a different search term.\")\n",
    "        print(\"> Exit...\")\n",
    "        print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a2703",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<a id='playground'></a>\n",
    "## <p style=\"color: #ffd700; background-color: #006400;\"> Playground\n",
    "    \n",
    "Run the below cell to interact with the top agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32637e30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide the arxiv search term: Applications using LLM\n",
      "\n",
      "Please wait, this might take a few minutes...\n",
      "--------------------------------------------------\n",
      "> Successfully fetched 10 papers\n",
      "> Downloading 2406_10300v1.pdf...\n",
      "> Downloading 2405_19888v1.pdf...\n",
      "> Downloading 2404_14809v1.pdf...\n",
      "> Downloading 2307_09793v1.pdf...\n",
      "> Downloading 2402_14805v1.pdf...\n",
      "> Downloading 2310_10049v1.pdf...\n",
      "> Downloading 2405_14748v1.pdf...\n",
      "> Downloading 2402_08806v1.pdf...\n",
      "> Downloading 2406_00936v1.pdf...\n",
      "> Downloading 2406_09834v1.pdf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb81b128f4440795fde956672da01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Agents:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Papers I have knowledge on\n",
      "> Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications\n",
      "> Parrot: Efficient Serving of LLM-based Applications with Semantic Variable\n",
      "> A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications\n",
      "> On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models\n",
      "> Identifying Multiple Personalities in Large Language Models with External Evaluation\n",
      "> FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models\n",
      "> MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs\n",
      "> Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy\n",
      "> A Survey of Useful LLM Evaluation\n",
      "> How and Why LLMs Use Deprecated APIs in Code Completion? An Empirical Study\n",
      "--------------------------------------------------\n",
      "> Type 'exit' to close the chat <\n",
      "--------------------------------------------------\n",
      "**************************************************\n",
      "User: My idea is \"Use computer vision for guiding blind people\". Show me references to related papers.\n",
      "\u001b[1;3;38;5;200mThought: The user is looking for references to related papers on using computer vision for guiding blind people. I should use a tool to help find relevant papers.\n",
      "Action: base_query_engine\n",
      "Action Input: {'input': 'Use computer vision for guiding blind people related papers'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, and Sujian Li. 2023b. Restgpt: Connecting large language models with real-world restful apis.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The tool has provided a relevant paper titled \"Restgpt: Connecting large language models with real-world restful APIs.\" I should continue using the tool to find more references related to using computer vision for guiding blind people.\n",
      "Action: base_query_engine\n",
      "Action Input: {'input': 'Use computer vision for guiding blind people related papers'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, and Sujian Li. 2023b. Restgpt: Connecting large language models with real-world restful apis.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The tool has provided the same reference again. I will try another tool to find more diverse references related to using computer vision for guiding blind people.\n",
      "Action: compare_tool\n",
      "Action Input: {'input': 'Use computer vision for guiding blind people related papers'}\n",
      "\u001b[0mGenerated 4 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[tool_2406_00936v1] Q: What are the latest advancements in using computer vision for guiding blind people?\n",
      "\u001b[0mAdded user message to memory: What are the latest advancements in using computer vision for guiding blind people?\n",
      "\u001b[1;3;38;2;90;149;237m[tool_2406_09834v1] Q: How do Large Language Models (LLMs) struggle with using up-to-date APIs in code completion for computer vision applications?\n",
      "\u001b[0mAdded user message to memory: How do Large Language Models (LLMs) struggle with using up-to-date APIs in code completion for computer vision applications?\n",
      "\u001b[1;3;38;2;11;159;203m[tool_2406_10300v1] Q: What taxonomy is used for integrating Large Language Models (LLMs) in computer vision applications?\n",
      "\u001b[0mAdded user message to memory: What taxonomy is used for integrating Large Language Models (LLMs) in computer vision applications?\n",
      "\u001b[1;3;38;2;155;135;227m[tool_2402_08806v1] Q: How does aggregating responses from multiple Large Language Models (LLMs) improve diagnostic accuracy in computer vision applications for guiding blind people?\n",
      "\u001b[0mAdded user message to memory: How does aggregating responses from multiple Large Language Models (LLMs) improve diagnostic accuracy in computer vision applications for guiding blind people?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2406_10300v1 with args: {\"input\":\"taxonomy for integrating Large Language Models (LLMs) in computer vision applications\"}\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2406_00936v1 with args: {\"input\":\"latest advancements in using computer vision for guiding blind people\"}\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2406_09834v1 with args: {\"input\":\"Large Language Models (LLMs) struggle with using up-to-date APIs in code completion for computer vision applications due to their limited ability to understand the context and requirements of specialized domains like computer vision. LLMs may not have been trained on the latest APIs or may lack the specific knowledge required for computer vision tasks, leading to inaccurate or incomplete code suggestions. Additionally, LLMs may struggle with understanding the nuances of computer vision concepts and may provide generic or outdated recommendations that do not align with the current best practices in the field.\"}\n",
      "Got output: Recent advancements in utilizing computer vision for assisting visually impaired individuals have shown promising results. These advancements include the development of systems that leverage computer vision technology to help guide blind people in navigating their surroundings. By incorporating visual recognition capabilities and real-time processing, these systems aim to enhance the independence and safety of individuals with visual impairments.\n",
      "========================\n",
      "\n",
      "Got output: The taxonomy discussed in the provided context focuses on integrating Large Language Models (LLMs) in software systems, emphasizing their use in various applications and the framework for analyzing and describing these integrations.\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2402_08806v1 with args: {\"input\":\"Aggregating responses from multiple Large Language Models (LLMs) can improve diagnostic accuracy in computer vision applications for guiding blind people by leveraging the diversity of responses. By combining the outputs of multiple LLMs, the system can reduce individual model biases and errors, leading to more robust and accurate predictions. This ensemble approach helps in capturing a broader range of features and patterns in the data, enhancing the overall performance of the system. Additionally, aggregating responses can also provide a measure of confidence or uncertainty in the predictions, allowing for better decision-making in guiding blind individuals based on the computer vision outputs.\"}\n",
      "\u001b[1;3;38;2;11;159;203m[tool_2406_10300v1] A: The taxonomy used for integrating Large Language Models (LLMs) in computer vision applications focuses on their use in software systems and provides a framework for analyzing and describing these integrations.\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[tool_2406_00936v1] A: Recent advancements in utilizing computer vision for assisting visually impaired individuals have shown promising results. These advancements include the development of systems that leverage computer vision technology to help guide blind people in navigating their surroundings. By incorporating visual recognition capabilities and real-time processing, these systems aim to enhance the independence and safety of individuals with visual impairments.\n",
      "\u001b[0mGot output: Large Language Models (LLMs) may indeed face challenges when it comes to utilizing the most current APIs for computer vision applications. This could be attributed to potential gaps in their training data regarding the latest APIs or a lack of specialized knowledge necessary for computer vision tasks. Consequently, their code suggestions might be inaccurate or incomplete. Furthermore, due to their general nature, LLMs might struggle to grasp the intricacies of computer vision concepts, potentially resulting in outdated or generic recommendations that do not align with the current standards in the field.\n",
      "========================\n",
      "\n",
      "Got output: Aggregating responses from multiple Large Language Models (LLMs) can indeed enhance diagnostic accuracy by leveraging the diversity of responses. This approach helps mitigate individual model biases and errors, leading to more robust and accurate predictions. By combining outputs from various LLMs, a broader range of features and patterns in the data can be captured, ultimately improving the system's overall performance. Additionally, aggregating responses can offer insights into the confidence or uncertainty of predictions, facilitating better decision-making in guiding blind individuals based on computer vision outputs.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;90;149;237m[tool_2406_09834v1] A: Large Language Models (LLMs) struggle with using up-to-date APIs in code completion for computer vision applications due to their limited ability to understand the context and requirements of specialized domains like computer vision. LLMs may not have been trained on the latest APIs or may lack the specific knowledge required for computer vision tasks, leading to inaccurate or incomplete code suggestions. Additionally, LLMs may struggle with understanding the nuances of computer vision concepts and may provide generic or outdated recommendations that do not align with the current best practices in the field.\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m[tool_2402_08806v1] A: Aggregating responses from multiple Large Language Models (LLMs) can improve diagnostic accuracy in computer vision applications for guiding blind people by leveraging the diversity of responses. This approach helps mitigate individual model biases and errors, leading to more robust and accurate predictions. By combining outputs from various LLMs, a broader range of features and patterns in the data can be captured, ultimately improving the system's overall performance. Additionally, aggregating responses can offer insights into the confidence or uncertainty of predictions, facilitating better decision-making in guiding blind individuals based on computer vision outputs.\n",
      "\u001b[0m\u001b[1;3;34mObservation: Utilizing computer vision for guiding blind people has been a topic of interest in recent research papers. Researchers have explored various advancements in computer vision technology to assist visually impaired individuals in navigating their surroundings more effectively and safely. These papers often focus on developing systems that incorporate visual recognition capabilities and real-time processing to enhance the independence and quality of life for individuals with visual impairments. By leveraging computer vision advancements, these studies aim to provide innovative solutions for guiding blind people through their environments.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The comparison tool has provided a summary of recent research papers related to utilizing computer vision for guiding blind people. This information gives an overview of the advancements and goals of these studies. I can now provide an answer using the user's language.\n",
      "Answer: Utilizing computer vision technology to assist blind people in navigating their surroundings has been a focus of recent research papers. These studies aim to enhance independence and quality of life by developing systems with visual recognition capabilities and real-time processing.\n",
      "\u001b[0m**************************************************\n",
      "Agent: Utilizing computer vision technology to assist blind people in navigating their surroundings has been a focus of recent research papers. These studies aim to enhance independence and quality of life by developing systems with visual recognition capabilities and real-time processing.\n",
      "**************************************************\n",
      "User: Show the difference between fate llm and multicast\n",
      "\u001b[1;3;38;5;200mThought: I need to compare FATE-LLM and MultiCast to highlight their differences.\n",
      "Action: compare_tool\n",
      "Action Input: {'input': 'FATE-LLM vs MultiCast'}\n",
      "\u001b[0mGenerated 2 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[tool_2310_10049v1] Q: What are the key components of FATE-LLM?\n",
      "\u001b[0mAdded user message to memory: What are the key components of FATE-LLM?\n",
      "\u001b[1;3;38;2;90;149;237m[tool_2405_14748v1] Q: How does MultiCast address the challenge of handling one-dimensional data in LLMs?\n",
      "\u001b[0mAdded user message to memory: How does MultiCast address the challenge of handling one-dimensional data in LLMs?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2310_10049v1 with args: {\"input\":\"Key components of FATE-LLM\"}\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_2405_14748v1 with args: {\"input\":\"MultiCast addressing the challenge of handling one-dimensional data in LLMs\"}\n",
      "Got output: The key components of FATE-LLM are the Communication-Efficient Hub, FedLLM Model Hub, and FedLLM Privacy Hub.\n",
      "========================\n",
      "\n",
      "\u001b[1;3;38;2;237;90;200m[tool_2310_10049v1] A: The key components of FATE-LLM are the Communication-Efficient Hub, FedLLM Model Hub, and FedLLM Privacy Hub.\n",
      "\u001b[0mGot output: MultiCast addresses the challenge of handling one-dimensional data in LLMs by introducing three novel token multiplexing techniques that allow LLMs to receive multivariate time series as input. These techniques effectively reduce dimensionality while preserving key repetitive patterns in the data. Additionally, a quantization scheme is implemented to assist LLMs in better learning these patterns while reducing token use for practical applications.\n",
      "========================\n",
      "\n",
      "\u001b[1;3;38;2;90;149;237m[tool_2405_14748v1] A: MultiCast addresses the challenge of handling one-dimensional data in LLMs by introducing three novel token multiplexing techniques that allow LLMs to receive multivariate time series as input. These techniques effectively reduce dimensionality while preserving key repetitive patterns in the data. Additionally, a quantization scheme is implemented to assist LLMs in better learning these patterns while reducing token use for practical applications.\n",
      "\u001b[0m\u001b[1;3;34mObservation: FATE-LLM focuses on components such as the Communication-Efficient Hub, FedLLM Model Hub, and FedLLM Privacy Hub, while MultiCast addresses the challenge of handling one-dimensional data in LLMs by introducing novel token multiplexing techniques and a quantization scheme to reduce dimensionality and preserve key patterns in the data.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer the question with the provided information.\n",
      "Answer: FATE-LLM emphasizes components like Communication-Efficient Hub, FedLLM Model Hub, and FedLLM Privacy Hub, while MultiCast tackles the issue of handling one-dimensional data in LLMs through token multiplexing methods and a quantization scheme to reduce dimensionality and maintain essential patterns in the data.\n",
      "\u001b[0m**************************************************\n",
      "Agent: FATE-LLM emphasizes components like Communication-Efficient Hub, FedLLM Model Hub, and FedLLM Privacy Hub, while MultiCast tackles the issue of handling one-dimensional data in LLMs through token multiplexing methods and a quantization scheme to reduce dimensionality and maintain essential patterns in the data.\n",
      "**************************************************\n",
      "User: Is there any paper related to \"Automated planting of trees\"\n",
      "\u001b[1;3;38;5;200mThought: The user is looking for papers related to the automated planting of trees.\n",
      "Action: base_query_engine\n",
      "Action Input: {'input': 'Automated planting of trees'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Automated planting of trees is not directly discussed in the provided context information.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I cannot answer the question with the provided tools.\n",
      "Answer: There is no direct information available on papers related to the automated planting of trees in the context provided.\n",
      "\u001b[0m**************************************************\n",
      "Agent: There is no direct information available on papers related to the automated planting of trees in the context provided.\n",
      "**************************************************\n",
      "User: Summarize the origin of LLM\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for a summary of the origin of Large Language Models (LLMs).\n",
      "Action: base_query_engine\n",
      "Action Input: {'input': 'Origin of Large Language Models'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The paper discusses the evolutionary tree and graph for a large number of Large Language Models (LLMs), exploring their backbones, settings, training methods, and families. It presents a public web application called Constellation that allows users to navigate and explore 15,821 LLMs, providing various visualizations like dendrograms, graphs, word clouds, and scatter plots.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The origin of Large Language Models (LLMs) can be traced back to the development and evolution of various models, settings, training methods, and families. A paper discusses a comprehensive analysis of LLMs through a public web application called Constellation, which offers visualizations and insights into a vast number of LLMs, enabling users to explore their characteristics and relationships.\n",
      "\u001b[0m**************************************************\n",
      "Agent: The origin of Large Language Models (LLMs) can be traced back to the development and evolution of various models, settings, training methods, and families. A paper discusses a comprehensive analysis of LLMs through a public web application called Constellation, which offers visualizations and insights into a vast number of LLMs, enabling users to explore their characteristics and relationships.\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "# Modify the 'max_results' value to alter the count of relevant papers to be downloaded\n",
    "ArxivConsultant(max_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc48601",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
